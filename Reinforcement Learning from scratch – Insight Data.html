<!DOCTYPE html>
<!-- saved from url=(0084)https://blog.insightdatascience.com/reinforcement-learning-from-scratch-819b65f074d8 -->
<html xmlns:cc="http://creativecommons.org/ns#"><style type="text/css" id="night-mode-pro-style"></style><link type="text/css" rel="stylesheet" id="night-mode-pro-link"><head prefix="og: http://ogp.me/ns# fb: http://ogp.me/ns/fb# medium-com: http://ogp.me/ns/fb/medium-com#"><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"><script src="./Reinforcement Learning from scratch – Insight Data_files/ptrack-v1.1.0-engagedtime-slots.js"></script><script src="./Reinforcement Learning from scratch – Insight Data_files/medium.com"></script><meta name="viewport" content="width=device-width, initial-scale=1.0, viewport-fit=contain"><title>Reinforcement Learning from scratch – Insight Data</title><link rel="canonical" href="https://blog.insightdatascience.com/reinforcement-learning-from-scratch-819b65f074d8"><meta name="title" content="Reinforcement Learning from scratch – Insight Data"><meta name="referrer" content="always"><meta name="description" content="Want to learn about applied Artificial Intelligence from leading practitioners in Silicon Valley, New York, or Toronto? Learn more about the Insight Artificial Intelligence Fellows Program. Are you a…"><meta name="theme-color" content="#000000"><meta property="og:title" content="Reinforcement Learning from scratch – Insight Data"><meta property="og:url" content="https://blog.insightdatascience.com/reinforcement-learning-from-scratch-819b65f074d8"><meta property="og:image" content="https://cdn-images-1.medium.com/max/1200/1*sf4ZeTwBq1O61U4W49NBdQ.png"><meta property="fb:app_id" content="542599432471018"><meta property="og:description" content="Inspired by a great tutorial at O’Reilly AI"><meta name="twitter:description" content="Inspired by a great tutorial at O’Reilly AI"><meta name="twitter:image:src" content="https://cdn-images-1.medium.com/max/1200/1*sf4ZeTwBq1O61U4W49NBdQ.png"><link rel="publisher" href="https://plus.google.com/103654360130207659246"><link rel="author" href="https://blog.insightdatascience.com/@emmanuelameisen"><meta property="author" content="Emmanuel Ameisen"><meta property="og:type" content="article"><meta name="twitter:card" content="summary_large_image"><meta property="article:publisher" content="https://www.facebook.com/InsightDataScience"><meta property="article:author" content="10203282016947013"><meta name="robots" content="index, follow"><meta property="article:published_time" content="2018-06-07T16:02:46.751Z"><meta name="twitter:creator" content="@EmmanuelAmeisen"><meta name="twitter:site" content="@InsightDataSci"><meta property="og:site_name" content="Insight Data"><meta name="twitter:label1" value="Reading time"><meta name="twitter:data1" value="11 min read"><meta name="twitter:app:name:iphone" content="Medium"><meta name="twitter:app:id:iphone" content="828256236"><meta name="twitter:app:url:iphone" content="medium://p/819b65f074d8"><meta property="al:ios:app_name" content="Medium"><meta property="al:ios:app_store_id" content="828256236"><meta property="al:android:package" content="com.medium.reader"><meta property="al:android:app_name" content="Medium"><meta property="al:ios:url" content="medium://p/819b65f074d8"><meta property="al:android:url" content="medium://p/819b65f074d8"><meta property="al:web:url" content="https://blog.insightdatascience.com/reinforcement-learning-from-scratch-819b65f074d8"><link rel="search" type="application/opensearchdescription+xml" title="Medium" href="https://blog.insightdatascience.com/osd.xml"><link rel="alternate" href="android-app://com.medium.reader/https/medium.com/p/819b65f074d8"><script type="application/ld+json">{"@context":"http://schema.org","@type":"NewsArticle","image":{"@type":"ImageObject","width":1200,"height":630,"url":"https://cdn-images-1.medium.com/max/1200/1*sf4ZeTwBq1O61U4W49NBdQ.png"},"url":"https://blog.insightdatascience.com/reinforcement-learning-from-scratch-819b65f074d8","dateCreated":"2018-06-07T16:02:46.751Z","datePublished":"2018-06-07T16:02:46.751Z","dateModified":"2018-06-21T09:51:08.238Z","headline":"Reinforcement Learning from scratch","name":"Reinforcement Learning from scratch","thumbnailUrl":"https://cdn-images-1.medium.com/max/1200/1*sf4ZeTwBq1O61U4W49NBdQ.png","keywords":["Tag:Machine Learning","Tag:Insight Ai","Tag:Deep Learning","Tag:Artificial Intelligence","Tag:Research","Topic:Artificial intelligence","Publication:insight-data","LockedPostSource:0","Elevated:false","LayerCake:3"],"author":{"@type":"Person","name":"Emmanuel Ameisen","url":"https://blog.insightdatascience.com/@emmanuelameisen"},"creator":["Emmanuel Ameisen"],"publisher":{"@type":"Organization","name":"Insight Data","url":"https://blog.insightdatascience.com","logo":{"@type":"ImageObject","width":152,"height":60,"url":"https://cdn-images-1.medium.com/max/152/1*QBd0FwuD-7reNUpsp4YFjg.png"}},"mainEntityOfPage":"https://blog.insightdatascience.com/reinforcement-learning-from-scratch-819b65f074d8"}</script><link rel="stylesheet" type="text/css" class="js-glyph-" id="glyph-8" href="./Reinforcement Learning from scratch – Insight Data_files/m2.css"><link rel="stylesheet" href="./Reinforcement Learning from scratch – Insight Data_files/main-branding-base.JRYmM9hSxI_DawfiPjxqbQ.css"><script>if (window.top !== window.self) window.top.location = window.self.location.href;var OB_startTime = new Date().getTime(); var OB_loadErrors = []; function _onerror(e) { OB_loadErrors.push(e) }; if (document.addEventListener) document.addEventListener("error", _onerror, true); else if (document.attachEvent) document.attachEvent("onerror", _onerror); function _asyncScript(u) {var d = document, f = d.getElementsByTagName("script")[0], s = d.createElement("script"); s.type = "text/javascript"; s.async = true; s.src = u; f.parentNode.insertBefore(s, f);}function _asyncStyles(u) {var d = document, f = d.getElementsByTagName("script")[0], s = d.createElement("link"); s.rel = "stylesheet"; s.href = u; f.parentNode.insertBefore(s, f); return s}(new Image()).src = "/_/stat?event=pixel.load&origin=" + encodeURIComponent(location.origin);</script><script>window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date; ga("create", "UA-24232453-2", "auto", {"allowLinker": true, "legacyCookieDomain": window.location.hostname}); ga("send", "pageview");ga("create", "UA-29720873-1", "auto", 'tracker0'); ga("tracker0.send", "pageview");</script><script async="" src="./Reinforcement Learning from scratch – Insight Data_files/analytics.js"></script><!--[if lt IE 9]><script charset="UTF-8" src="https://cdn-static-1.medium.com/_/fp/js/shiv.RI2ePTZ5gFmMgLzG5bEVAA.js"></script><![endif]--><link rel="icon" href="https://cdn-images-1.medium.com/fit/c/128/128/1*LH1Ab6OAbS03JhOUvBlg9A.png" class="js-favicon"><link rel="apple-touch-icon" sizes="152x152" href="https://cdn-images-1.medium.com/fit/c/304/304/1*bVN8Kd_RsjRN8JuKIc6U0w.png"><link rel="apple-touch-icon" sizes="120x120" href="https://cdn-images-1.medium.com/fit/c/240/240/1*bVN8Kd_RsjRN8JuKIc6U0w.png"><link rel="apple-touch-icon" sizes="76x76" href="https://cdn-images-1.medium.com/fit/c/152/152/1*bVN8Kd_RsjRN8JuKIc6U0w.png"><link rel="apple-touch-icon" sizes="60x60" href="./Reinforcement Learning from scratch – Insight Data_files/1_bVN8Kd_RsjRN8JuKIc6U0w.png"><link rel="mask-icon" href="https://cdn-static-1.medium.com/_/fp/icons/monogram-mask.KPLCSFEZviQN0jQ7veN2RQ.svg" color="#171717"></head><body itemscope="" class="postShowScreen browser-chrome is-withMagicUnderlinesv-glyph v-glyph--m2 is-js is-withMagicUnderlines" data-action-scope="_actionscope_0"><script>document.body.className = document.body.className.replace(/(^|\s)is-noJs(\s|$)/, "$1is-js$2")</script><div class="site-main surface-container" id="container"><div class="butterBar butterBar--error" data-action-scope="_actionscope_1"></div><div class="surface" id="_obv.shell._surface_1532089558988" style="display: block; visibility: visible;"><div class="screenContent surface-content is-supplementalPostContentLoaded" data-used="true" data-action-scope="_actionscope_2"><canvas class="canvas-renderer" width="1304" height="629"></canvas><div class="container u-maxWidth740 u-xs-margin0 notesPositionContainer js-notesPositionContainer"><div class="notesMarkers" data-action-scope="_actionscope_4"><div class="paragraphControls js-paragraphControl js-paragraphControl-91d7 u-noUserSelect is-visible" style="top: 2212px;"><span class="paragraphControls-itemText"><button class="button button--chromeless" data-action="select-anchor" data-action-value="91d7">Top highlight</button></span></div></div></div><div class="metabar u-clearfix js-metabar u-textColorTransparentWhiteDarker u-fixed u-backgroundTransparentWhiteDarkest u-xs-sizeFullViewportWidth u-tintBgColor u-tintSpectrum"><div class="js-metabarMiddle metabar-inner u-marginAuto u-maxWidth1000 u-flexCenter u-justifyContentSpaceBetween u-height65 u-xs-height56 u-paddingLeft20 u-paddingRight20"><div class="metabar-block u-flex1  u-flexCenter"><div class="js-metabarLogoLeft"><a href="https://medium.com/" data-log-event="home" class="siteNav-logo u-flexCenter u-paddingTop0"><span class="svgIcon svgIcon--logoMonogram svgIcon--45px is-flushLeft u-textColorDarker"><svg class="svgIcon-use" width="45" height="45" viewBox="0 0 45 45"><path d="M5 40V5h35v35H5zm8.56-12.627c0 .555-.027.687-.318 1.03l-2.457 2.985v.396h6.974v-.396l-2.456-2.985c-.291-.343-.344-.502-.344-1.03V18.42l6.127 13.364h.714l5.256-13.364v10.644c0 .29 0 .342-.185.528l-1.848 1.796v.396h9.19v-.396l-1.822-1.796c-.184-.186-.21-.238-.21-.528V15.937c0-.291.026-.344.21-.528l1.823-1.797v-.396h-6.471l-4.622 11.542-5.203-11.542h-6.79v.396l2.14 2.64c.239.292.291.37.291.768v10.353z"></path></svg></span><span class="u-textScreenReader">Homepage</span></a></div><div class="u-flexCenter u-height65 u-xs-height56"><span class="u-inlineBlock u-height28 u-xs-height24 u-verticalAlignTop u-marginRight20 u-marginLeft15 u-borderRightTransparentWhiteLighter"></span></div><div class="u-flexCenter u-height65 u-xs-height56 u-marginRight18"><a class="js-collectionLogoOrName u-uiTextBold u-fontSize18 u-lineHeightTightest u-xs-fontSize22" href="https://blog.insightdatascience.com/?source=logo-lo_6eca48311aab---d02e65779d7b"><img height="36" width="92" class="u-paddingTop5" src="./Reinforcement Learning from scratch – Insight Data_files/1_QBd0FwuD-7reNUpsp4YFjg.png" alt="Insight Data"></a></div><div class="u-flexCenter u-height65 u-xs-height56 u-xs-hide"><div class="buttonSet"><button class="button button--primary button--smallest u-noUserSelect button--withChrome u-accentColor--buttonNormal js-relationshipButton is-smallPill" data-action="sign-up-prompt" data-sign-in-action="toggle-follow-collection" data-requires-token="true" data-redirect="https://medium.com/_/subscribe/collection/insight-data" data-action-source="----d02e65779d7b----------------------follow_header" data-collection-id="d02e65779d7b"><span class="button-label  js-buttonLabel">Follow</span></button><a class="button button--light button--chromeless is-touchIconBlackPulse u-baseColor--buttonLight button--withIcon button--withSvgIcon" href="https://twitter.com/InsightDataSci" title="Visit “Insight Data” on Twitter" aria-label="Visit “Insight Data” on Twitter" rel="me" target="_blank"><span class="button-defaultState"><span class="svgIcon svgIcon--twitterFilled svgIcon--25px"><svg class="svgIcon-use" width="25" height="25" viewBox="0 0 25 25"><path d="M21.725 5.338c-.744.47-1.605.804-2.513 1.006a3.978 3.978 0 0 0-2.942-1.293c-2.22 0-4.02 1.81-4.02 4.02 0 .32.034.63.07.94-3.31-.18-6.27-1.78-8.255-4.23a4.544 4.544 0 0 0-.574 2.01c.04 1.43.74 2.66 1.8 3.38-.63-.01-1.25-.19-1.79-.5v.08c0 1.93 1.38 3.56 3.23 3.95-.34.07-.7.12-1.07.14-.25-.02-.5-.04-.72-.07.49 1.58 1.97 2.74 3.74 2.8a8.49 8.49 0 0 1-5.02 1.72c-.3-.03-.62-.04-.93-.07A11.447 11.447 0 0 0 8.88 21c7.386 0 11.43-6.13 11.414-11.414.015-.21.01-.38 0-.578a7.604 7.604 0 0 0 2.01-2.08 7.27 7.27 0 0 1-2.297.645 3.856 3.856 0 0 0 1.72-2.23"></path></svg></span></span></a><a class="button button--light button--chromeless is-touchIconBlackPulse u-baseColor--buttonLight button--withIcon button--withSvgIcon u-paddingLeft0" href="https://facebook.com/InsightDataScience" title="Visit “Insight Data” on Facebook" aria-label="Visit “Insight Data” on Facebook" rel="me" target="_blank"><span class="button-defaultState"><span class="svgIcon svgIcon--facebookFilled svgIcon--25px"><svg class="svgIcon-use" width="25" height="25" viewBox="0 0 25 25"><path d="M21 12.646C21 7.65 16.97 3.6 12 3.6s-9 4.05-9 9.046a9.026 9.026 0 0 0 7.59 8.924v-6.376H8.395V12.64h2.193v-1.88c0-2.186 1.328-3.375 3.267-3.375.93 0 1.728.07 1.96.1V9.77H14.47c-1.055 0-1.26.503-1.26 1.242v1.63h2.517l-.33 2.554H13.21V21.6c4.398-.597 7.79-4.373 7.79-8.954"></path></svg></span></span></a></div></div></div><div class="metabar-block u-flex0 u-flexCenter"><div class="u-flexCenter u-height65 u-xs-height56"><div class="buttonSet buttonSet--wide u-lineHeightInherit"><a class="button button--primary button--light button--chromeless u-accentColor--buttonNormal is-inSiteNavBar u-xs-hide js-signInButton" href="https://medium.com/m/signin?redirect=https%3A%2F%2Fblog.insightdatascience.com%2Freinforcement-learning-from-scratch-819b65f074d8%3Fsource%3Dsearch_post---------6&amp;source=--------------------------nav_reg&amp;operation=login" data-action="sign-in-prompt" data-redirect="https://blog.insightdatascience.com/reinforcement-learning-from-scratch-819b65f074d8?source=search_post---------6" data-action-source="--------------------------nav_reg">Sign in</a><a class="button button--primary button--light button--withChrome u-accentColor--buttonNormal is-inSiteNavBar js-signUpButton" href="https://medium.com/m/signin?redirect=https%3A%2F%2Fblog.insightdatascience.com%2Freinforcement-learning-from-scratch-819b65f074d8%3Fsource%3Dsearch_post---------6&amp;source=--------------------------nav_reg&amp;operation=register" data-action="sign-up-prompt" data-redirect="https://blog.insightdatascience.com/reinforcement-learning-from-scratch-819b65f074d8?source=search_post---------6" data-action-source="--------------------------nav_reg">Get started</a></div></div></div></div><div class="metabar-inner u-marginAuto u-maxWidth1000 js-metabarBottom"><nav role="navigation" class="metabar-block metabar-block--below u-overflowHidden u-height44"><ul class="u-textAlignLeft u-noWrap u-overflowX u-paddingBottom100 u-sm-paddingLeft20 u-sm-paddingRight20 js-collectionNavItems"><li class="metabar-navItem js-collectionNavItem u-uiTextMedium u-fontSize14 u-inlineBlock u-textUppercase u-letterSpacing003 u-textColorNormal u-xs-paddingRight12 u-xs-marginRight0 u-paddingTop5 u-xs-paddingTop10"><a class="link link--darken u-accentColor--textDarken u-baseColor--link js-homeNav" href="https://blog.insightdatascience.com/">Home</a></li><li class="metabar-navItem js-collectionNavItem  u-uiTextMedium u-fontSize14 u-inlineBlock u-textUppercase u-letterSpacing003 u-textColorNormal u-xs-paddingRight12 u-xs-marginRight0 u-paddingTop5 u-xs-paddingTop10"><a class="link link--darken u-accentColor--textDarken link--noUnderline u-baseColor--link js-navItemLink" href="https://blog.insightdatascience.com/tagged/about-insight">About Insight</a></li><li class="metabar-navItem js-collectionNavItem  u-uiTextMedium u-fontSize14 u-inlineBlock u-textUppercase u-letterSpacing003 u-textColorNormal u-xs-paddingRight12 u-xs-marginRight0 u-paddingTop5 u-xs-paddingTop10"><a class="link link--darken u-accentColor--textDarken link--noUnderline u-baseColor--link js-navItemLink" href="https://blog.insightdatascience.com/tagged/insight-data-science">Data Science</a></li><li class="metabar-navItem js-collectionNavItem  u-uiTextMedium u-fontSize14 u-inlineBlock u-textUppercase u-letterSpacing003 u-textColorNormal u-xs-paddingRight12 u-xs-marginRight0 u-paddingTop5 u-xs-paddingTop10"><a class="link link--darken u-accentColor--textDarken link--noUnderline u-baseColor--link js-navItemLink" href="https://blog.insightdatascience.com/tagged/insight-data-engineering">Data Engineering</a></li><li class="metabar-navItem js-collectionNavItem  u-uiTextMedium u-fontSize14 u-inlineBlock u-textUppercase u-letterSpacing003 u-textColorNormal u-xs-paddingRight12 u-xs-marginRight0 u-paddingTop5 u-xs-paddingTop10"><a class="link link--darken u-accentColor--textDarken link--noUnderline u-baseColor--link js-navItemLink" href="https://blog.insightdatascience.com/tagged/insight-health-data">Health Data</a></li><li class="metabar-navItem js-collectionNavItem  u-uiTextMedium u-fontSize14 u-inlineBlock u-textUppercase u-letterSpacing003 u-textColorNormal u-xs-paddingRight12 u-xs-marginRight0 u-paddingTop5 u-xs-paddingTop10"><a class="link link--darken u-accentColor--textDarken link--noUnderline u-baseColor--link js-navItemLink" href="https://blog.insightdatascience.com/tagged/insight-ai">AI</a></li><li class="metabar-navItem js-collectionNavItem  u-uiTextMedium u-fontSize14 u-inlineBlock u-textUppercase u-letterSpacing003 u-textColorNormal u-xs-paddingRight12 u-xs-marginRight0 u-paddingTop5 u-xs-paddingTop10"><a class="link link--darken u-accentColor--textDarken link--noUnderline u-baseColor--link js-navItemLink" href="https://blog.insightdatascience.com/tagged/insight-data-pm">Data PM</a></li><li class="metabar-navItem js-collectionNavItem  u-uiTextMedium u-fontSize14 u-inlineBlock u-textUppercase u-letterSpacing003 u-textColorNormal u-xs-paddingRight12 u-xs-marginRight0 u-paddingTop5 u-xs-paddingTop10"><a class="link link--darken u-accentColor--textDarken link--noUnderline u-baseColor--link js-navItemLink" href="https://blog.insightdatascience.com/tagged/insight-devops">DevOps</a></li><li class="metabar-navItem js-collectionNavItem u-uiTextMedium u-fontSize14 u-inlineBlock u-textUppercase u-letterSpacing003 u-textColorNormal u-xs-paddingRight12 u-xs-marginRight0 u-paddingTop5 u-xs-paddingTop10"><a class="button button--chromeless u-baseColor--buttonNormal button--withIcon button--withSvgIcon u-top1" href="https://blog.insightdatascience.com/search" title="Search" aria-label="Search"><span class="button-defaultState"><span class="svgIcon svgIcon--search svgIcon--25px"><svg class="svgIcon-use" width="25" height="25" viewBox="0 0 25 25"><path d="M20.067 18.933l-4.157-4.157a6 6 0 1 0-.884.884l4.157 4.157a.624.624 0 1 0 .884-.884zM6.5 11c0-2.62 2.13-4.75 4.75-4.75S16 8.38 16 11s-2.13 4.75-4.75 4.75S6.5 13.62 6.5 11z"></path></svg></span></span></a></li></ul></nav></div></div><div class="metabar metabar--spacer js-metabarSpacer u-tintBgColor  u-height105 u-xs-height95"></div><main role="main"><article class=" u-minHeight100vhOffset65 u-overflowHidden postArticle postArticle--full is-withAccentColors u-marginBottom40" lang="en"><header class="container u-maxWidth740"><div class="uiScale uiScale-ui--regular uiScale-caption--regular postMetaHeader u-paddingBottom10 row"><div class="col u-size12of12 js-postMetaLockup"><div class="uiScale uiScale-ui--regular uiScale-caption--regular postMetaLockup postMetaLockup--authorWithBio u-flexCenter js-postMetaLockup"><div class="u-flex0"><a class="link u-baseColor--link avatar" href="https://blog.insightdatascience.com/@emmanuelameisen?source=post_header_lockup" data-action="show-user-card" data-action-source="post_header_lockup" data-action-value="45cca2d4999f" data-action-type="hover" data-user-id="45cca2d4999f" data-collection-slug="insight-data" dir="auto"><img src="./Reinforcement Learning from scratch – Insight Data_files/1_u2FiBL9mzFPx7pj87aWxgw.jpeg" class="avatar-image avatar-image--small" alt="Go to the profile of Emmanuel Ameisen"></a></div><div class="u-flex1 u-paddingLeft15 u-overflowHidden"><div class="u-lineHeightTightest"><a class="ds-link ds-link--styleSubtle ui-captionStrong u-inlineBlock link link--darken link--darker" href="https://blog.insightdatascience.com/@emmanuelameisen?source=post_header_lockup" data-action="show-user-card" data-action-source="post_header_lockup" data-action-value="45cca2d4999f" data-action-type="hover" data-user-id="45cca2d4999f" data-collection-slug="insight-data" dir="auto">Emmanuel Ameisen</a><span class="followState js-followState" data-user-id="45cca2d4999f"><button class="button button--smallest u-noUserSelect button--withChrome u-baseColor--buttonNormal button--withHover button--unblock js-unblockButton u-marginLeft10 u-xs-hide" data-action="sign-up-prompt" data-sign-in-action="toggle-block-user" data-requires-token="true" data-redirect="https://blog.insightdatascience.com/reinforcement-learning-from-scratch-819b65f074d8?source=search_post---------6" data-action-source="post_header_lockup"><span class="button-label  button-defaultState">Blocked</span><span class="button-label button-hoverState">Unblock</span></button><button class="button button--primary button--smallest u-noUserSelect button--withChrome u-accentColor--buttonNormal button--follow js-followButton u-marginLeft10 u-xs-hide" data-action="sign-up-prompt" data-sign-in-action="toggle-subscribe-user" data-requires-token="true" data-redirect="https://medium.com/_/subscribe/user/45cca2d4999f" data-action-source="post_header_lockup-45cca2d4999f-------------------------follow_byline"><span class="button-label  button-defaultState js-buttonLabel">Follow</span><span class="button-label button-activeState">Following</span></button></span></div><div class="ui-caption ui-xs-clamp2 postMetaInline">AI Lead at Insight AI @EmmanuelAmeisen</div><div class="ui-caption postMetaInline js-testPostMetaInlineSupplemental"><time datetime="2018-06-07T16:02:46.751Z">Jun 7</time><span class="middotDivider u-fontSize12"></span><span class="readingTime" title="11 min read"></span></div></div></div></div></div></header><div class="postArticle-content js-postField js-notesSource js-trackedPost" data-post-id="819b65f074d8" data-source="post_page" data-collection-id="d02e65779d7b" data-tracking-context="postPage" data-scroll="native"><section name="8df0" class="section section--body section--first"><div class="section-divider"><hr class="section-divider"></div><div class="section-content"><div class="section-inner sectionLayout--insetColumn"><h1 name="10a5" id="10a5" class="graf graf--h3 graf--leading graf--title">Reinforcement Learning from&nbsp;scratch</h1><h2 name="aafa" id="aafa" class="graf graf--h4 graf-after--h3 graf--subtitle">Inspired by a great tutorial at O’Reilly&nbsp;AI</h2><figure name="f9ad" id="f9ad" class="graf graf--figure graf-after--h4"><div class="aspectRatioPlaceholder is-locked" style="max-width: 700px; max-height: 368px;"><div class="aspectRatioPlaceholder-fill" style="padding-bottom: 52.5%;"></div><div class="progressiveMedia js-progressiveMedia graf-image is-canvasLoaded is-imageLoaded" data-image-id="1*sf4ZeTwBq1O61U4W49NBdQ.png" data-width="1200" data-height="630" data-is-featured="true" data-action="zoom" data-action-value="1*sf4ZeTwBq1O61U4W49NBdQ.png" data-scroll="native"><img src="./Reinforcement Learning from scratch – Insight Data_files/1_sf4ZeTwBq1O61U4W49NBdQ.png" crossorigin="anonymous" class="progressiveMedia-thumbnail js-progressiveMedia-thumbnail"><canvas class="progressiveMedia-canvas js-progressiveMedia-canvas" width="75" height="38"></canvas><img class="progressiveMedia-image js-progressiveMedia-image" data-src="https://cdn-images-1.medium.com/max/1600/1*sf4ZeTwBq1O61U4W49NBdQ.png" src="./Reinforcement Learning from scratch – Insight Data_files/1_sf4ZeTwBq1O61U4W49NBdQ(1).png"><noscript class="js-progressiveMedia-inner">&lt;img class="progressiveMedia-noscript js-progressiveMedia-inner" src="https://cdn-images-1.medium.com/max/1600/1*sf4ZeTwBq1O61U4W49NBdQ.png"&gt;</noscript></div></div><figcaption class="imageCaption">A movie about one of the most famous applications of Deep&nbsp;RL</figcaption></figure><p name="dbe8" id="dbe8" class="graf graf--p graf-after--figure"><strong class="markup--strong markup--p-strong"><em class="markup--em markup--p-em">Want to learn about applied Artificial Intelligence from leading practitioners in Silicon Valley, New York, or Toronto?</em></strong><em class="markup--em markup--p-em"> </em>Learn more about the <a href="http://insightdata.ai/?utm_source=deep_rl&amp;utm_medium=blog&amp;utm_content=top" data-href="http://insightdata.ai?utm_source=deep_rl&amp;utm_medium=blog&amp;utm_content=top" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank">Insight Artificial Intelligence Fellows Program</a>.</p><p name="26ad" id="26ad" class="graf graf--p graf-after--p graf--trailing"><strong class="markup--strong markup--p-strong"><em class="markup--em markup--p-em">Are you a company working in AI and would like to get involved in the Insight AI Fellows Program?</em></strong><em class="markup--em markup--p-em"> Feel free to </em><a href="http://insightdatascience.com/partnerships?utm_source=deep_rl&amp;utm_medium=blog&amp;utm_content=top" data-href="http://insightdatascience.com/partnerships?utm_source=deep_rl&amp;utm_medium=blog&amp;utm_content=top" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank"><em class="markup--em markup--p-em">get in touch</em></a><em class="markup--em markup--p-em">.</em></p></div></div></section><section name="978c" class="section section--body"><div class="section-divider"><hr class="section-divider"></div><div class="section-content"><div class="section-inner sectionLayout--insetColumn"><p name="1da2" id="1da2" class="graf graf--p graf--leading">Recently, I gave a talk at the O’Reilly AI conference in Beijing about some of the interesting <a href="https://blog.insightdatascience.com/how-to-solve-90-of-nlp-problems-a-step-by-step-guide-fda605278e4e" data-href="https://blog.insightdatascience.com/how-to-solve-90-of-nlp-problems-a-step-by-step-guide-fda605278e4e" class="markup--anchor markup--p-anchor" target="_blank">lessons</a> we’ve learned in the world of NLP. While there, I was lucky enough to attend a tutorial on Deep Reinforcement Learning (Deep RL) from scratch by Unity Technologies. I thought that the session, led by <a href="https://medium.com/@awjuliani" data-href="https://medium.com/@awjuliani" data-anchor-type="2" data-user-id="18dfe63fa7f0" data-action-value="18dfe63fa7f0" data-action="show-user-card" data-action-type="hover" class="markup--user markup--p-user" target="_blank">Arthur Juliani</a>, was extremely informative and wanted to share some big takeaways below.</p><p name="3c9c" id="3c9c" class="graf graf--p graf-after--p">In our conversations with companies, we’ve seen a rise of interesting Deep RL applications, tools and results. In parallel, the inner workings and applications of Deep RL, such as AlphaGo pictured above, can often seem esoteric and hard to understand. In this post, I will give an overview of core aspects of the field that can be <strong class="markup--strong markup--p-strong">understood by anyone</strong>.</p><p name="141f" id="141f" class="graf graf--p graf-after--p">Many of the visuals are from the slides of the talk, and some are new. The explanations and opinions are mine. If anything is unclear, reach out to me <a href="https://twitter.com/EmmanuelAmeisen" data-href="https://twitter.com/EmmanuelAmeisen" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank">here</a>!</p><h3 name="33c2" id="33c2" class="graf graf--h3 graf-after--p">The rise of Deep Reinforcement Learning</h3><p name="68be" id="68be" class="graf graf--p graf-after--h3">Deep RL is a field that has seen vast amounts of research interest, including learning to play Atari games, <a href="https://blog.openai.com/dota-2/" data-href="https://blog.openai.com/dota-2/" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank">beating</a> pro players at Dota 2, and <a href="https://deepmind.com/research/alphago/" data-href="https://deepmind.com/research/alphago/" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank">defeating</a> Go champions. Contrary to many classical Deep Learning problems that often focus on <strong class="markup--strong markup--p-strong">perception</strong> (does this image contain a stop sign?), Deep RL adds the dimension of <strong class="markup--strong markup--p-strong">actions</strong> that influence the environment (what is the goal, and how do I get there?). In dialog systems for example, classical Deep Learning aims to learn the right response for a given query. On the other hand, Deep Reinforcement Learning focuses on the right sequences of sentences that will lead to a positive outcome, for example a happy customer.</p><p name="91d7" id="91d7" class="graf graf--p graf-after--p">This makes Deep RL particularly attractive for tasks that require planning and adaptation, such as manufacturing or self-driving. However, industry applications have trailed behind the rapidly advancing results coming out of the research community. A major reason is that Deep RL often requires an agent to experiment millions of times before learning anything useful. The best way to do this rapidly is by using a <strong class="markup--strong markup--p-strong">simulation environment</strong>. <span class="markup--quote markup--p-quote is-other" name="anon_482ce08c9917" data-creator-ids="anon">This tutorial will be using <a href="https://unity3d.com/unity" data-href="https://unity3d.com/unity" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank">Unity</a> to create environments to train agents in.</span></p><p name="8ebc" id="8ebc" class="graf graf--p graf-after--p">For this workshop led by <a href="https://www.linkedin.com/in/arthur-juliani-50a38a21/" data-href="https://www.linkedin.com/in/arthur-juliani-50a38a21/" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank">Arthur Juliani</a> and <a href="https://www.linkedin.com/in/zhongyuechen/" data-href="https://www.linkedin.com/in/zhongyuechen/" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank">Leon Chen</a>, their goal was to get every participants to successfully train multiple Deep RL algorithms in 4 hours. A tall order! Below, is a <strong class="markup--strong markup--p-strong">comprehensive overview</strong> of many of the main algorithms that power Deep RL today. For a more complete set of tutorials, <a href="https://medium.com/@awjuliani" data-href="https://medium.com/@awjuliani" data-anchor-type="2" data-user-id="18dfe63fa7f0" data-action-value="18dfe63fa7f0" data-action="show-user-card" data-action-type="hover" class="markup--user markup--p-user" target="_blank">Arthur Juliani</a> wrote an 8-part series starting <a href="https://medium.com/emergent-future/simple-reinforcement-learning-with-tensorflow-part-0-q-learning-with-tables-and-neural-networks-d195264329d0" data-href="https://medium.com/emergent-future/simple-reinforcement-learning-with-tensorflow-part-0-q-learning-with-tables-and-neural-networks-d195264329d0" class="markup--anchor markup--p-anchor" target="_blank">here</a>.</p><h4 name="99db" id="99db" class="graf graf--h4 graf-after--p">From slot machines to video games, an overview of&nbsp;RL</h4><p name="fcee" id="fcee" class="graf graf--p graf-after--h4">Deep RL can be used to best the top human players at Go, but to understand how that’s done, you first need to understand a few <strong class="markup--strong markup--p-strong">simple concepts</strong>, starting with much easier problems.</p><p name="9391" id="9391" class="graf graf--p graf-after--p"><strong class="markup--strong markup--p-strong">1/It all starts with slot machines</strong></p><figure name="dec4" id="dec4" class="graf graf--figure graf-after--p"><div class="aspectRatioPlaceholder is-locked" style="max-width: 700px; max-height: 396px;"><div class="aspectRatioPlaceholder-fill" style="padding-bottom: 56.49999999999999%;"></div><div class="progressiveMedia js-progressiveMedia graf-image is-canvasLoaded is-imageLoaded" data-image-id="1*2A9ZhECO8zbQiJUFI3abNA.png" data-width="1924" data-height="1088" data-action="zoom" data-action-value="1*2A9ZhECO8zbQiJUFI3abNA.png" data-scroll="native"><img src="./Reinforcement Learning from scratch – Insight Data_files/1_2A9ZhECO8zbQiJUFI3abNA.png" crossorigin="anonymous" class="progressiveMedia-thumbnail js-progressiveMedia-thumbnail"><canvas class="progressiveMedia-canvas js-progressiveMedia-canvas" width="75" height="41"></canvas><img class="progressiveMedia-image js-progressiveMedia-image" data-src="https://cdn-images-1.medium.com/max/1600/1*2A9ZhECO8zbQiJUFI3abNA.png" src="./Reinforcement Learning from scratch – Insight Data_files/1_2A9ZhECO8zbQiJUFI3abNA(1).png"><noscript class="js-progressiveMedia-inner">&lt;img class="progressiveMedia-noscript js-progressiveMedia-inner" src="https://cdn-images-1.medium.com/max/1600/1*2A9ZhECO8zbQiJUFI3abNA.png"&gt;</noscript></div></div><figcaption class="imageCaption">As a first toy problem, can we learn which of these chests has the biggest chance of containing a&nbsp;reward</figcaption></figure><p name="b7bd" id="b7bd" class="graf graf--p graf-after--figure">Let’s imagine you are faced with 4 chests that you can pick from at each turn. Each of them have a different average payout, and your goal is to maximize the total payout you receive after a fixed number of turns. This is a classic problem called <a href="https://en.wikipedia.org/wiki/Multi-armed_bandit" data-href="https://en.wikipedia.org/wiki/Multi-armed_bandit" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank">Multi-armed bandits</a> and is where we will start. The crux of the problem is to balance <strong class="markup--strong markup--p-strong">exploration</strong>, which helps us learn about which states are good, and <strong class="markup--strong markup--p-strong">exploitation</strong>, where we now use what we know to pick the best slot machine.</p><p name="75cf" id="75cf" class="graf graf--p graf-after--p">Here, we will utilize a <strong class="markup--strong markup--p-strong">value function</strong> that maps our actions to an estimated reward, called the <a href="https://en.wikipedia.org/wiki/Q-learning" data-href="https://en.wikipedia.org/wiki/Q-learning" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank">Q function</a>. First, we’ll initialize all Q values at equal values. Then, we’ll update the Q value of each action (picking each chest) based on how good the payout was after choosing this action. This allows us to <strong class="markup--strong markup--p-strong">learn a good value function</strong>. We will approximate our Q function using a neural network (starting with a very shallow one) that learns a probability distribution (by using a <a href="https://en.wikipedia.org/wiki/Softmax_function" data-href="https://en.wikipedia.org/wiki/Softmax_function" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank">softmax</a>) over the 4 potential chests.</p><p name="bfdc" id="bfdc" class="graf graf--p graf-after--p">While the value function tells us how good we estimate each action to be, the <strong class="markup--strong markup--p-strong">policy</strong> is the function that determines <strong class="markup--strong markup--p-strong">which actions we end up taking</strong>. Intuitively, we might want to use a policy that picks the action with the highest Q value. This performs poorly in practice, as our Q estimates will be very wrong at the start before we gather enough <strong class="markup--strong markup--p-strong">experience through trial and error</strong>. This is why we need to add a mechanism to our policy to <strong class="markup--strong markup--p-strong">encourage exploration</strong>. One way to do that is to use <a href="https://en.wikipedia.org/wiki/Multi-armed_bandit#Semi-uniform_strategies" data-href="https://en.wikipedia.org/wiki/Multi-armed_bandit#Semi-uniform_strategies" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank">epsilon greedy</a>, which consists of taking a <strong class="markup--strong markup--p-strong">random action</strong> with probability epsilon. We start with epsilon being close to 1, always choosing random actions, and lower epsilon as we go along and learn more about which chests are good. Eventually, we learn which chests are best.</p><p name="63a8" id="63a8" class="graf graf--p graf-after--p">In practice, we might want to take a more subtle approach than either taking the action we think is the best, or a random action. A popular method is Boltzmann Exploration, which adjust probabilities based on our current estimate of how good each chest is, adding in a randomness factor.</p><p name="00c9" id="00c9" class="graf graf--p graf-after--p"><strong class="markup--strong markup--p-strong">2/Adding different states</strong></p><figure name="be8a" id="be8a" class="graf graf--figure graf-after--p"><div class="aspectRatioPlaceholder is-locked" style="max-width: 700px; max-height: 337px;"><div class="aspectRatioPlaceholder-fill" style="padding-bottom: 48.199999999999996%;"></div><div class="progressiveMedia js-progressiveMedia graf-image is-canvasLoaded is-imageLoaded" data-image-id="1*TSPMNQ4SF0r2ypRP8GFtGA.png" data-width="2208" data-height="1064" data-action="zoom" data-action-value="1*TSPMNQ4SF0r2ypRP8GFtGA.png" data-scroll="native"><img src="./Reinforcement Learning from scratch – Insight Data_files/1_TSPMNQ4SF0r2ypRP8GFtGA.png" crossorigin="anonymous" class="progressiveMedia-thumbnail js-progressiveMedia-thumbnail"><canvas class="progressiveMedia-canvas js-progressiveMedia-canvas" width="75" height="35"></canvas><img class="progressiveMedia-image js-progressiveMedia-image" data-src="https://cdn-images-1.medium.com/max/1600/1*TSPMNQ4SF0r2ypRP8GFtGA.png" src="./Reinforcement Learning from scratch – Insight Data_files/1_TSPMNQ4SF0r2ypRP8GFtGA(1).png"><noscript class="js-progressiveMedia-inner">&lt;img class="progressiveMedia-noscript js-progressiveMedia-inner" src="https://cdn-images-1.medium.com/max/1600/1*TSPMNQ4SF0r2ypRP8GFtGA.png"&gt;</noscript></div></div><figcaption class="imageCaption">Here, different background colors mean different average chest&nbsp;rewards</figcaption></figure><p name="3589" id="3589" class="graf graf--p graf-after--figure">The previous example was a world in which we were always in the same state, waiting to pick from the same 4 chests in front of us. Most real-word problems consist of many different states. That is what we will add to our environment next. Now, the background behind chests alternates between 3 colors at each turn, <strong class="markup--strong markup--p-strong">changing the average values</strong> of the chests. This means we need to learn a Q function that depends not only on the <strong class="markup--strong markup--p-strong">action</strong> (the chest we pick), but the <strong class="markup--strong markup--p-strong">state</strong> (what the color of the background is). This version of the problem is called Contextual Multi-armed Bandits.</p><p name="8f0a" id="8f0a" class="graf graf--p graf-after--p">Surprisingly, <strong class="markup--strong markup--p-strong">we can use the same approach as before</strong>. The only thing we need to add is an extra dense layer to our neural network, that will take in as input a vector representing the current state of the world.</p><p name="f3a9" id="f3a9" class="graf graf--p graf-after--p"><strong class="markup--strong markup--p-strong">3/Learning about the consequences of our actions</strong></p><figure name="88e9" id="88e9" class="graf graf--figure graf-after--p"><div class="aspectRatioPlaceholder is-locked" style="max-width: 700px; max-height: 678px;"><div class="aspectRatioPlaceholder-fill" style="padding-bottom: 96.89999999999999%;"></div><div class="progressiveMedia js-progressiveMedia graf-image is-canvasLoaded is-imageLoaded" data-image-id="1*2JOhvWzYAOQ5MMX4e3fxlg.png" data-width="1606" data-height="1556" data-action="zoom" data-action-value="1*2JOhvWzYAOQ5MMX4e3fxlg.png" data-scroll="native"><img src="./Reinforcement Learning from scratch – Insight Data_files/1_2JOhvWzYAOQ5MMX4e3fxlg.png" crossorigin="anonymous" class="progressiveMedia-thumbnail js-progressiveMedia-thumbnail"><canvas class="progressiveMedia-canvas js-progressiveMedia-canvas" width="75" height="72"></canvas><img class="progressiveMedia-image js-progressiveMedia-image" data-src="https://cdn-images-1.medium.com/max/1600/1*2JOhvWzYAOQ5MMX4e3fxlg.png" src="./Reinforcement Learning from scratch – Insight Data_files/1_2JOhvWzYAOQ5MMX4e3fxlg(1).png"><noscript class="js-progressiveMedia-inner">&lt;img class="progressiveMedia-noscript js-progressiveMedia-inner" src="https://cdn-images-1.medium.com/max/1600/1*2JOhvWzYAOQ5MMX4e3fxlg.png"&gt;</noscript></div></div><figcaption class="imageCaption">Here, we are the blue square trying to learn how to get to the green square without touching the red&nbsp;ones</figcaption></figure><p name="55d2" id="55d2" class="graf graf--p graf-after--figure">There is another key factor that makes our current problem simpler than mosts. In most environments, such as in the maze depicted above, the <strong class="markup--strong markup--p-strong">actions that we take have an impact on the state of the world</strong>. If we move up on this grid, we might receive a reward or we might receive nothing, but the next turn we will be in a different state. This is where we finally introduce a need for <strong class="markup--strong markup--p-strong">planning</strong>.</p><p name="5e6e" id="5e6e" class="graf graf--p graf-after--p">First, we will define our Q function as the <strong class="markup--strong markup--p-strong">immediate reward</strong> in our current state, plus the discounted <strong class="markup--strong markup--p-strong">reward we are expecting</strong> by taking all of our future actions. This solution works if our Q estimate of states is accurate, so how can we learn a good estimate?</p><p name="3bac" id="3bac" class="graf graf--p graf-after--p">We will use a method called <strong class="markup--strong markup--p-strong">Temporal Difference (TD) learning</strong> to learn a good Q function. The idea is to only look at a limited number of steps in the future. TD(1) for example, only uses the next 2 states to evaluate the reward.</p><p name="1ab0" id="1ab0" class="graf graf--p graf-after--p">Surprisingly, we can use TD(0), which looks at the current state, and our estimate of the reward the next turn, and get great results. The structure of the network is the same, but we need to go through one forward step before receiving the error. We then use this error to <a href="https://en.wikipedia.org/wiki/Backpropagation" data-href="https://en.wikipedia.org/wiki/Backpropagation" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank">back propagate</a> gradients, like in traditional Deep Learning, and update our value estimates.</p><p name="f7de" id="f7de" class="graf graf--p graf-after--p"><strong class="markup--strong markup--p-strong">3+/Introducing Monte Carlo</strong></p><p name="43dc" id="43dc" class="graf graf--p graf-after--p">Another method to estimate the eventual success of our actions is Monte Carlo Estimates. This consists of playing out <strong class="markup--strong markup--p-strong">the entire episode</strong> with our current policy until we reach an end (success by reaching a green block or failure by reaching a red block in the image above) and use that result to update our value estimates <strong class="markup--strong markup--p-strong">for each traversed state</strong>. This allows us to <strong class="markup--strong markup--p-strong">propagate values efficiently</strong> in one batch at the end of an episode, instead of every time we make a move. The cost is that we are introducing noise to our estimates, since we attribute very distant rewards to them.</p><p name="732d" id="732d" class="graf graf--p graf-after--p"><strong class="markup--strong markup--p-strong">4/The world is rarely discrete</strong></p><figure name="9939" id="9939" class="graf graf--figure graf-after--p"><div class="aspectRatioPlaceholder is-locked" style="max-width: 700px; max-height: 397px;"><div class="aspectRatioPlaceholder-fill" style="padding-bottom: 56.699999999999996%;"></div><div class="progressiveMedia js-progressiveMedia graf-image is-canvasLoaded is-imageLoaded" data-image-id="1*ZgPdKglJ8ioqzVF-4c3Nqg.png" data-width="1784" data-height="1012" data-action="zoom" data-action-value="1*ZgPdKglJ8ioqzVF-4c3Nqg.png" data-scroll="native"><img src="./Reinforcement Learning from scratch – Insight Data_files/1_ZgPdKglJ8ioqzVF-4c3Nqg.png" crossorigin="anonymous" class="progressiveMedia-thumbnail js-progressiveMedia-thumbnail"><canvas class="progressiveMedia-canvas js-progressiveMedia-canvas" width="75" height="42"></canvas><img class="progressiveMedia-image js-progressiveMedia-image" data-src="https://cdn-images-1.medium.com/max/1600/1*ZgPdKglJ8ioqzVF-4c3Nqg.png" src="./Reinforcement Learning from scratch – Insight Data_files/1_ZgPdKglJ8ioqzVF-4c3Nqg(1).png"><noscript class="js-progressiveMedia-inner">&lt;img class="progressiveMedia-noscript js-progressiveMedia-inner" src="https://cdn-images-1.medium.com/max/1600/1*ZgPdKglJ8ioqzVF-4c3Nqg.png"&gt;</noscript></div></div></figure><p name="7e93" id="7e93" class="graf graf--p graf-after--figure">The previous methods were using neural networks to approximate our value estimates by mapping from a <strong class="markup--strong markup--p-strong">discrete number of states and actions</strong> to a value. In the maze for example, there were 49 states (squares) and 4 actions (move in each adjacent direction). In this environment, we are trying to learn how to balance a ball on a 2 dimensional paddle, by deciding at each time step whether we want to tilt the paddle left or right. Here, <strong class="markup--strong markup--p-strong">the state space becomes continuous</strong> (the angle of the paddle, and the position of the ball). The good news is, we can still use Neural Networks to approximate this function!</p><p name="5220" id="5220" class="graf graf--p graf-after--p">A note about <strong class="markup--strong markup--p-strong">off-policy vs on-policy learning</strong>: The methods we used previously, are off-policy methods, meaning we can generate data <strong class="markup--strong markup--p-strong">with any strategy</strong>(using epsilon greedy for example) and learn from it. On-policy methods can only learn <strong class="markup--strong markup--p-strong">from actions that were taken following our policy</strong> (remember, a policy is the method we use to determine which actions to take). This constrains our learning process, as we have to have an exploration strategy that is built in to the policy itself, but allows us to <strong class="markup--strong markup--p-strong">tie results directly to our reasoning</strong>, and enables us to learn more efficiently.</p><p name="2962" id="2962" class="graf graf--p graf-after--p">The approach we will use here is called <strong class="markup--strong markup--p-strong">Policy Gradients</strong>, and is an on-policy method. Previously, we were first learning a value function Q for each action in each state and then building a policy on top. In <strong class="markup--strong markup--p-strong">Vanilla Policy Gradient</strong>, we still use Monte Carlo Estimates, but we <strong class="markup--strong markup--p-strong">learn our policy directly</strong> through a loss function that <strong class="markup--strong markup--p-strong">increases the probability of choosing rewarding actions</strong>. Since we are learning on policy, we cannot use methods such as epsilon greedy (which includes random choices), to get our agent to explore the environment. The way that we encourage exploration is by using a method called <strong class="markup--strong markup--p-strong">entropy regularization</strong>, which pushes our probability estimates to be wider, and thus will encourage us to <strong class="markup--strong markup--p-strong">make riskier choices</strong> to explore the space.</p><p name="db1e" id="db1e" class="graf graf--p graf-after--p"><strong class="markup--strong markup--p-strong">4+/Leveraging deep learning for representations</strong></p><p name="a27a" id="a27a" class="graf graf--p graf-after--p">In practice, many state of the art RL methods require learning <strong class="markup--strong markup--p-strong">both a policy and value estimates</strong>. The way we do this with deep learning is by having both be two separate outputs of the same backbone neural network, which will make it easier for our neural network to learn good representations.</p><p name="ec98" id="ec98" class="graf graf--p graf-after--p">One method to do this is <strong class="markup--strong markup--p-strong">Advantage Actor Critic</strong> (A2C). We learn our policy directly with policy gradients (defined above), and learn a value function using something called <strong class="markup--strong markup--p-strong">Advantage. </strong>Instead of updating our value function based on rewards, we update it based on our advantage, which measures how much better or worse an action was than our previous value function estimated it to be. This helps make learning more stable compared to simple Q Learning and Vanilla Policy Gradients.</p><p name="2cb2" id="2cb2" class="graf graf--p graf-after--p"><strong class="markup--strong markup--p-strong">5/Learning directly from the screen</strong></p><figure name="4d92" id="4d92" class="graf graf--figure graf-after--p"><div class="aspectRatioPlaceholder is-locked" style="max-width: 700px; max-height: 574px;"><div class="aspectRatioPlaceholder-fill" style="padding-bottom: 81.89999999999999%;"></div><div class="progressiveMedia js-progressiveMedia graf-image is-canvasLoaded is-imageLoaded" data-image-id="1*mz7YKHaKS590RlBpKyuy-A.png" data-width="1562" data-height="1280" data-action="zoom" data-action-value="1*mz7YKHaKS590RlBpKyuy-A.png" data-scroll="native"><img src="./Reinforcement Learning from scratch – Insight Data_files/1_mz7YKHaKS590RlBpKyuy-A.png" crossorigin="anonymous" class="progressiveMedia-thumbnail js-progressiveMedia-thumbnail"><canvas class="progressiveMedia-canvas js-progressiveMedia-canvas" width="75" height="61"></canvas><img class="progressiveMedia-image js-progressiveMedia-image" data-src="https://cdn-images-1.medium.com/max/1600/1*mz7YKHaKS590RlBpKyuy-A.png" src="./Reinforcement Learning from scratch – Insight Data_files/1_mz7YKHaKS590RlBpKyuy-A(1).png"><noscript class="js-progressiveMedia-inner">&lt;img class="progressiveMedia-noscript js-progressiveMedia-inner" src="https://cdn-images-1.medium.com/max/1600/1*mz7YKHaKS590RlBpKyuy-A.png"&gt;</noscript></div></div><figcaption class="imageCaption">The inputs to the model are the pixels in the image&nbsp;above!</figcaption></figure><p name="c100" id="c100" class="graf graf--p graf-after--figure">There is an additional advantage to using Deep Learning for these methods, which is that Deep Neural Networks excel at <strong class="markup--strong markup--p-strong">perceptive tasks</strong>. When a human plays a game, the information received is not a list of states, but an image (usually of a screen, or a board, or the surrounding environment).</p><p name="0680" id="0680" class="graf graf--p graf-after--p">Image-based Learning <strong class="markup--strong markup--p-strong">combines a Convolutional Neural Network (CNN) with RL</strong>. In this environment, we pass in a <strong class="markup--strong markup--p-strong">raw image</strong> instead of features, and add a 2 layer CNN to our architecture without changing anything else! We can even <strong class="markup--strong markup--p-strong">inspect activations</strong> to see what the network picks up on to determine value, and policy. In the example below, we can see that the network uses the <strong class="markup--strong markup--p-strong">current score and distant obstacles</strong> to estimate the value of the <strong class="markup--strong markup--p-strong">current state</strong>, while focusing on <strong class="markup--strong markup--p-strong">nearby obstacles</strong> for determining <strong class="markup--strong markup--p-strong">actions</strong>. Neat!</p><figure name="67ad" id="67ad" class="graf graf--figure graf-after--p"><div class="aspectRatioPlaceholder is-locked" style="max-width: 700px; max-height: 455px;"><div class="aspectRatioPlaceholder-fill" style="padding-bottom: 65%;"></div><div class="progressiveMedia js-progressiveMedia graf-image is-canvasLoaded is-imageLoaded" data-image-id="1*QrXNFXqOYRQ7msBlq6RaEg.png" data-width="1354" data-height="880" data-action="zoom" data-action-value="1*QrXNFXqOYRQ7msBlq6RaEg.png" data-scroll="native"><img src="./Reinforcement Learning from scratch – Insight Data_files/1_QrXNFXqOYRQ7msBlq6RaEg.png" crossorigin="anonymous" class="progressiveMedia-thumbnail js-progressiveMedia-thumbnail"><canvas class="progressiveMedia-canvas js-progressiveMedia-canvas" width="75" height="47"></canvas><img class="progressiveMedia-image js-progressiveMedia-image" data-src="https://cdn-images-1.medium.com/max/1600/1*QrXNFXqOYRQ7msBlq6RaEg.png" src="./Reinforcement Learning from scratch – Insight Data_files/1_QrXNFXqOYRQ7msBlq6RaEg(1).png"><noscript class="js-progressiveMedia-inner">&lt;img class="progressiveMedia-noscript js-progressiveMedia-inner" src="https://cdn-images-1.medium.com/max/1600/1*QrXNFXqOYRQ7msBlq6RaEg.png"&gt;</noscript></div></div><figcaption class="imageCaption">Inspecting a CNN’s activations to see what is important to the value estimate (left) and the policy estimate&nbsp;(right).</figcaption></figure><p name="adcc" id="adcc" class="graf graf--p graf-after--figure">As a side note, while toying around with the provided implementation, I’ve found that visual learning is very sensitive to hyperparameters. Changing the discount rate slightly for example, completely prevented the neural network from learning even on a toy application. This is a widely known <a href="https://www.alexirpan.com/2018/02/14/rl-hard.html" data-href="https://www.alexirpan.com/2018/02/14/rl-hard.html" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank">problem</a>, but it is interesting to see it first hand.</p><p name="42d7" id="42d7" class="graf graf--p graf-after--p"><strong class="markup--strong markup--p-strong">6/Nuanced actions</strong></p><figure name="52e7" id="52e7" class="graf graf--figure graf-after--p"><div class="aspectRatioPlaceholder is-locked" style="max-width: 700px; max-height: 389px;"><div class="aspectRatioPlaceholder-fill" style="padding-bottom: 55.50000000000001%;"></div><div class="progressiveMedia js-progressiveMedia graf-image is-canvasLoaded is-imageLoaded" data-image-id="1*ZpXpbubGccgLQ6ppRmrVDQ.png" data-width="1642" data-height="912" data-action="zoom" data-action-value="1*ZpXpbubGccgLQ6ppRmrVDQ.png" data-scroll="native"><img src="./Reinforcement Learning from scratch – Insight Data_files/1_ZpXpbubGccgLQ6ppRmrVDQ.png" crossorigin="anonymous" class="progressiveMedia-thumbnail js-progressiveMedia-thumbnail"><canvas class="progressiveMedia-canvas js-progressiveMedia-canvas" width="75" height="41"></canvas><img class="progressiveMedia-image js-progressiveMedia-image" data-src="https://cdn-images-1.medium.com/max/1600/1*ZpXpbubGccgLQ6ppRmrVDQ.png" src="./Reinforcement Learning from scratch – Insight Data_files/1_ZpXpbubGccgLQ6ppRmrVDQ(1).png"><noscript class="js-progressiveMedia-inner">&lt;img class="progressiveMedia-noscript js-progressiveMedia-inner" src="https://cdn-images-1.medium.com/max/1600/1*ZpXpbubGccgLQ6ppRmrVDQ.png"&gt;</noscript></div></div></figure><p name="0484" id="0484" class="graf graf--p graf-after--figure">So far, we’ve played with environments with continuous and discrete <strong class="markup--strong markup--p-strong">state spaces</strong>. However, every environment we studied had a discrete <strong class="markup--strong markup--p-strong">action space</strong>: we could move in one of four directions, or tilt the paddle to the left or right. Ideally, for applications such as self-driving cars, we would like to learn continuous actions, such as <strong class="markup--strong markup--p-strong">turning the steering wheel</strong> between 0 and 360 degrees. In this environment called 3D ball world, we can choose to tilt the paddle to any value on each of its axes. This gives us <strong class="markup--strong markup--p-strong">more control</strong> as to how we perform actions, but <strong class="markup--strong markup--p-strong">makes the action space much larger</strong>.</p><p name="1104" id="1104" class="graf graf--p graf-after--p">We can approach this by approximating our potential choices with Gaussian distributions. We learn a probability distribution over potential actions by learning the mean and variance of a Gaussian distribution, and our policy we sample from that distribution. Simple, in theory&nbsp;:).</p><p name="fcd8" id="fcd8" class="graf graf--p graf-after--p"><strong class="markup--strong markup--p-strong">7/Next steps for the brave</strong></p><p name="9cac" id="9cac" class="graf graf--p graf-after--p">There are a few concepts that separate the algorithms described above from state of the art approaches. It’s interesting to see that conceptually, the best robotics and game-playing algorithms are not that far away from the ones we just explored:</p><ul class="postList"><li name="1916" id="1916" class="graf graf--li graf-after--p"><strong class="markup--strong markup--li-strong">Parallelizing</strong>: A3C is one of the most common approaches out there. It adds an asynchronous step to actor critic, allowing the algorithm to run in a parallelized way. This allows it to solve more interesting problems in a reasonable amount of time. Evolutionary methods can be parallelized even more, and are showing very <a href="https://eng.uber.com/deep-neuroevolution/" data-href="https://eng.uber.com/deep-neuroevolution/" class="markup--anchor markup--li-anchor" rel="noopener" target="_blank">encouraging</a> performance.</li><li name="599f" id="599f" class="graf graf--li graf-after--li"><strong class="markup--strong markup--li-strong">Curriculum Learning</strong>: in many cases, it is extremely unlikely to get to any reward by acting randomly. This makes the exploration phase extremely tricky, as we will never learn anything valuable. In that case we can simplify the problem and solve a trivial version first, then use the basic model on increasingly more complex environments.</li><li name="e87f" id="e87f" class="graf graf--li graf-after--li"><strong class="markup--strong markup--li-strong">Memory</strong>: Using LSTMs, for example, we can remember what happened in the past, and make decisions in a sequential way within a game playing session.</li><li name="1f8a" id="1f8a" class="graf graf--li graf-after--li"><strong class="markup--strong markup--li-strong">Model based RL</strong>: Various approach exist for algorithms to build a model of the world while they learn, so that they can infer rules about how the world works, on top of simply performing actions with high rewards. AlphaZero combines an explicit model with planning. <a href="http://worldmodels.github.io/" data-href="http://worldmodels.github.io" class="markup--anchor markup--li-anchor" rel="noopener" target="_blank">This</a> is a paper I found particularly exciting in the space.</li></ul><p name="a292" id="a292" class="graf graf--p graf-after--li graf--trailing">That’s it for this overview, I hope this has been informative and fun! If you are looking to dive deeper into the theory of RL, give Arthur’s posts a <a href="https://medium.com/emergent-future/simple-reinforcement-learning-with-tensorflow-part-0-q-learning-with-tables-and-neural-networks-d195264329d0" data-href="https://medium.com/emergent-future/simple-reinforcement-learning-with-tensorflow-part-0-q-learning-with-tables-and-neural-networks-d195264329d0" class="markup--anchor markup--p-anchor" target="_blank">read</a>, or diving deeper by following David Silver’s UCL <a href="http://www0.cs.ucl.ac.uk/staff/d.silver/web/Teaching.html" data-href="http://www0.cs.ucl.ac.uk/staff/d.silver/web/Teaching.html" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank">course</a>. If you are looking to learn more about the projects we do at Insight, or how we work with companies, please check us out below, or reach out to me <a href="https://twitter.com/EmmanuelAmeisen" data-href="https://twitter.com/EmmanuelAmeisen" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank">here</a>.</p></div></div></section><section name="5524" class="section section--body section--last"><div class="section-divider"><hr class="section-divider"></div><div class="section-content"><div class="section-inner sectionLayout--insetColumn"><p name="e9bd" id="e9bd" class="graf graf--p graf--leading"><strong class="markup--strong markup--p-strong"><em class="markup--em markup--p-em">Want to learn about applied Artificial Intelligence from leading practitioners in Silicon Valley, New York, or Toronto?</em></strong><em class="markup--em markup--p-em"> </em>Learn more about the <a href="http://insightdata.ai/?utm_source=deep_rl&amp;utm_medium=blog&amp;utm_content=top" data-href="http://insightdata.ai?utm_source=deep_rl&amp;utm_medium=blog&amp;utm_content=top" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank">Insight Artificial Intelligence Fellows Program</a>.</p><p name="748c" id="748c" class="graf graf--p graf-after--p graf--trailing"><strong class="markup--strong markup--p-strong"><em class="markup--em markup--p-em">Are you a company working in AI and would like to get involved in the Insight AI Fellows Program?</em></strong><em class="markup--em markup--p-em"> Feel free to </em><a href="http://insightdatascience.com/partnerships?utm_source=deep_rl&amp;utm_medium=blog&amp;utm_content=top" data-href="http://insightdatascience.com/partnerships?utm_source=deep_rl&amp;utm_medium=blog&amp;utm_content=top" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank"><em class="markup--em markup--p-em">get in touch</em></a><em class="markup--em markup--p-em">.</em></p></div></div></section></div><footer class="u-paddingTop10"><div class="container u-maxWidth740"><div class="row"><div class="col u-size12of12"><div class="postMetaInline postMetaInline--acknowledgments u-paddingTop5 u-paddingBottom20 js-postMetaAcknowledgments"><span data-tooltip="The following people helped the author by providing feedback before the story was published.">Thanks to</span> <span><a class="link u-baseColor--link" href="https://medium.com/@genevieve_56490?source=post_page" data-action="show-user-card" data-action-source="post_page" data-action-value="180b8130f02d" data-action-type="hover" data-user-id="180b8130f02d" dir="auto">Geneviève Smith</a>, </span><span><a class="link u-baseColor--link" href="https://medium.com/@ben_71772?source=post_page" data-action="show-user-card" data-action-source="post_page" data-action-value="53978067b293" data-action-type="hover" data-user-id="53978067b293" dir="auto">Ben Regner</a>, </span><span><a class="link u-baseColor--link" href="https://medium.com/@nerdoid?source=post_page" data-action="show-user-card" data-action-source="post_page" data-action-value="da71795f0a67" data-action-type="hover" data-user-id="da71795f0a67" dir="auto">Andy Mullenix</a>, and </span><span><a class="link u-baseColor--link" href="https://medium.com/@mkong?source=post_page" data-action="show-user-card" data-action-source="post_page" data-action-value="ab3a129da53d" data-action-type="hover" data-user-id="ab3a129da53d" dir="auto">Mari Kong</a></span>. </div></div></div><div class="row"><div class="col u-size12of12 js-postTags"><div class="u-paddingBottom10"><ul class="tags tags--postTags tags--borderless"><li><a class="link u-baseColor--link" href="https://blog.insightdatascience.com/tagged/machine-learning?source=post" data-action-source="post" data-collection-slug="insight-data">Machine Learning</a></li><li><a class="link u-baseColor--link" href="https://blog.insightdatascience.com/tagged/insight-ai?source=post" data-action-source="post" data-collection-slug="insight-data">Insight Ai</a></li><li><a class="link u-baseColor--link" href="https://blog.insightdatascience.com/tagged/deep-learning?source=post" data-action-source="post" data-collection-slug="insight-data">Deep Learning</a></li><li><a class="link u-baseColor--link" href="https://blog.insightdatascience.com/tagged/artificial-intelligence?source=post" data-action-source="post" data-collection-slug="insight-data">Artificial Intelligence</a></li><li><a class="link u-baseColor--link" href="https://blog.insightdatascience.com/tagged/research?source=post" data-action-source="post" data-collection-slug="insight-data">Research</a></li></ul></div></div></div><section class="uiScale uiScale-ui--small uiScale-caption--regular u-borderTopLightest u-marginTop10 u-paddingTop20"><div class="ui-h3 u-textColorDarker u-fontSize22">Like what you read? Give Emmanuel Ameisen a round of applause.</div><p class="ui-body u-marginBottom20 u-textColorDark u-fontSize16">From a quick cheer to a standing ovation, clap to show how much you enjoyed this story.</p></section><div class="postActions js-postActionsFooter"><div class="u-flexCenter"><div class="u-flex1"><div class="multirecommend js-actionMultirecommend u-flexCenter u-width60" data-post-id="819b65f074d8" data-is-icon-29px="true" data-is-circle="true" data-has-recommend-list="true" data-source="post_actions_footer-----819b65f074d8---------------------clap_footer"><div class="u-relative u-foreground"><button class="button button--large button--circle button--withChrome u-baseColor--buttonNormal button--withIcon button--withSvgIcon clapButton js-actionMultirecommendButton clapButton--largePill u-relative u-foreground u-xs-paddingLeft13 u-width60 u-height60 u-accentColor--textNormal u-accentColor--buttonNormal clap-onboardingcollection" data-action="sign-up-prompt" data-sign-in-action="multivote" data-requires-token="true" data-redirect="https://medium.com/_/vote/p/819b65f074d8" data-action-source="post_actions_footer-----819b65f074d8---------------------clap_footer" aria-label="Clap"><span class="button-defaultState"><span class="svgIcon svgIcon--clap svgIcon--33px u-relative u-topNegative2 u-xs-top0"><svg class="svgIcon-use" width="33" height="33" viewBox="0 0 33 33"><path d="M28.86 17.342l-3.64-6.402c-.292-.433-.712-.729-1.163-.8a1.124 1.124 0 0 0-.889.213c-.63.488-.742 1.181-.33 2.061l1.222 2.587 1.4 2.46c2.234 4.085 1.511 8.007-2.145 11.663-.26.26-.526.49-.797.707 1.42-.084 2.881-.683 4.292-2.094 3.822-3.823 3.565-7.876 2.05-10.395zm-6.252 11.075c3.352-3.35 3.998-6.775 1.978-10.469l-3.378-5.945c-.292-.432-.712-.728-1.163-.8a1.122 1.122 0 0 0-.89.213c-.63.49-.742 1.182-.33 2.061l1.72 3.638a.502.502 0 0 1-.806.568l-8.91-8.91a1.335 1.335 0 0 0-1.887 1.886l5.292 5.292a.5.5 0 0 1-.707.707l-5.292-5.292-1.492-1.492c-.503-.503-1.382-.505-1.887 0a1.337 1.337 0 0 0 0 1.886l1.493 1.492 5.292 5.292a.499.499 0 0 1-.353.854.5.5 0 0 1-.354-.147L5.642 13.96a1.338 1.338 0 0 0-1.887 0 1.338 1.338 0 0 0 0 1.887l2.23 2.228 3.322 3.324a.499.499 0 0 1-.353.853.502.502 0 0 1-.354-.146l-3.323-3.324a1.333 1.333 0 0 0-1.886 0 1.325 1.325 0 0 0-.39.943c0 .356.138.691.39.943l6.396 6.397c3.528 3.53 8.86 5.313 12.821 1.353zM12.73 9.26l5.68 5.68-.49-1.037c-.518-1.107-.426-2.13.224-2.89l-3.303-3.304a1.337 1.337 0 0 0-1.886 0 1.326 1.326 0 0 0-.39.944c0 .217.067.42.165.607zm14.787 19.184c-1.599 1.6-3.417 2.392-5.353 2.392-.349 0-.7-.03-1.058-.082a7.922 7.922 0 0 1-3.667.887c-3.049 0-6.115-1.626-8.359-3.87l-6.396-6.397A2.315 2.315 0 0 1 2 19.724a2.327 2.327 0 0 1 1.923-2.296l-.875-.875a2.339 2.339 0 0 1 0-3.3 2.33 2.33 0 0 1 1.24-.647l-.139-.139c-.91-.91-.91-2.39 0-3.3.884-.884 2.421-.882 3.301 0l.138.14a2.335 2.335 0 0 1 3.948-1.24l.093.092c.091-.423.291-.828.62-1.157a2.336 2.336 0 0 1 3.3 0l3.384 3.386a2.167 2.167 0 0 1 1.271-.173c.534.086 1.03.354 1.441.765.11-.549.415-1.034.911-1.418a2.12 2.12 0 0 1 1.661-.41c.727.117 1.385.565 1.853 1.262l3.652 6.423c1.704 2.832 2.025 7.377-2.205 11.607zM13.217.484l-1.917.882 2.37 2.837-.454-3.719zm8.487.877l-1.928-.86-.44 3.697 2.368-2.837zM16.5 3.293L15.478-.005h2.044L16.5 3.293z" fill-rule="evenodd"></path></svg></span></span><span class="button-activeState"><span class="svgIcon svgIcon--clapFilled svgIcon--33px u-relative u-topNegative2 u-xs-top0"><svg class="svgIcon-use" width="33" height="33" viewBox="0 0 33 33"><g fill-rule="evenodd"><path d="M29.58 17.1l-3.854-6.78c-.365-.543-.876-.899-1.431-.989a1.491 1.491 0 0 0-1.16.281c-.42.327-.65.736-.7 1.207v.001l3.623 6.367c2.46 4.498 1.67 8.802-2.333 12.807-.265.265-.536.505-.81.728 1.973-.222 3.474-1.286 4.45-2.263 4.166-4.165 3.875-8.6 2.215-11.36zm-4.831.82l-3.581-6.3c-.296-.439-.725-.742-1.183-.815a1.105 1.105 0 0 0-.89.213c-.647.502-.755 1.188-.33 2.098l1.825 3.858a.601.601 0 0 1-.197.747.596.596 0 0 1-.77-.067L10.178 8.21c-.508-.506-1.393-.506-1.901 0a1.335 1.335 0 0 0-.393.95c0 .36.139.698.393.95v.001l5.61 5.61a.599.599 0 1 1-.848.847l-5.606-5.606c-.001 0-.002 0-.003-.002L5.848 9.375a1.349 1.349 0 0 0-1.902 0 1.348 1.348 0 0 0 0 1.901l1.582 1.582 5.61 5.61a.6.6 0 0 1-.848.848l-5.61-5.61c-.51-.508-1.393-.508-1.9 0a1.332 1.332 0 0 0-.394.95c0 .36.139.697.393.952l2.363 2.362c.002.001.002.002.002.003l3.52 3.52a.6.6 0 0 1-.848.847l-3.522-3.523h-.001a1.336 1.336 0 0 0-.95-.393 1.345 1.345 0 0 0-.949 2.295l6.779 6.78c3.715 3.713 9.327 5.598 13.49 1.434 3.527-3.528 4.21-7.13 2.086-11.015zM11.817 7.727c.06-.328.213-.64.466-.893.64-.64 1.755-.64 2.396 0l3.232 3.232c-.82.783-1.09 1.833-.764 2.992l-5.33-5.33z"></path><path d="M13.285.48l-1.916.881 2.37 2.837z"></path><path d="M21.719 1.361L19.79.501l-.44 3.697z"></path><path d="M16.502 3.298L15.481 0h2.043z"></path></g></svg></span></span></button><div class="clapUndo u-width60 u-round u-height32 u-absolute u-borderBox u-paddingRight5 u-transition--transform200Spring u-background--brandSageLighter js-clapUndo" style="top: 14px; padding: 2px;"><button class="button button--chromeless u-baseColor--buttonNormal button--withIcon button--withSvgIcon u-floatRight" data-action="multivote-undo" data-action-value="819b65f074d8"><span class="svgIcon svgIcon--removeThin svgIcon--29px"><svg class="svgIcon-use" width="29" height="29" viewBox="0 0 29 29"><path d="M20.13 8.11l-5.61 5.61-5.609-5.61-.801.801 5.61 5.61-5.61 5.61.801.8 5.61-5.609 5.61 5.61.8-.801-5.609-5.61 5.61-5.61" fill-rule="evenodd"></path></svg></span></button></div></div><span class="u-textAlignCenter u-relative u-background js-actionMultirecommendCount u-marginLeft10"><button class="button button--chromeless u-baseColor--buttonNormal js-multirecommendCountButton" data-action="show-recommends" data-action-value="819b65f074d8">2.5K</button></span></div></div><div class="buttonSet u-flex0"><button class="button button--large button--dark button--chromeless is-touchIconBlackPulse u-baseColor--buttonDark button--withIcon button--withSvgIcon" data-action="scroll-to-responses" data-action-source="post_actions_footer"><span class="svgIcon svgIcon--response svgIcon--29px"><svg class="svgIcon-use" width="29" height="29" viewBox="0 0 29 29"><path d="M21.27 20.058c1.89-1.826 2.754-4.17 2.754-6.674C24.024 8.21 19.67 4 14.1 4 8.53 4 4 8.21 4 13.384c0 5.175 4.53 9.385 10.1 9.385 1.007 0 2-.14 2.95-.41.285.25.592.49.918.7 1.306.87 2.716 1.31 4.19 1.31.276-.01.494-.14.6-.36a.625.625 0 0 0-.052-.65c-.61-.84-1.042-1.71-1.282-2.58a5.417 5.417 0 0 1-.154-.75zm-3.85 1.324l-.083-.28-.388.12a9.72 9.72 0 0 1-2.85.424c-4.96 0-8.99-3.706-8.99-8.262 0-4.556 4.03-8.263 8.99-8.263 4.95 0 8.77 3.71 8.77 8.27 0 2.25-.75 4.35-2.5 5.92l-.24.21v.32c0 .07 0 .19.02.37.03.29.1.6.19.92.19.7.49 1.4.89 2.08-.93-.14-1.83-.49-2.67-1.06-.34-.22-.88-.48-1.16-.74z"></path></svg></span></button><button class="button button--chromeless u-baseColor--buttonNormal" data-action="scroll-to-responses">8</button><button class="button button--large button--dark button--chromeless is-touchIconBlackPulse u-baseColor--buttonDark button--withIcon button--withSvgIcon u-xs-hide" title="Share on Twitter" aria-label="Share on Twitter" data-action="share-on-twitter" data-action-source="post_actions_footer"><span class="svgIcon svgIcon--twitter svgIcon--29px"><svg class="svgIcon-use" width="29" height="29" viewBox="0 0 29 29"><path d="M21.967 11.8c.018 5.93-4.607 11.18-11.177 11.18-2.172 0-4.25-.62-6.047-1.76l-.268.422-.038.5.186.013.168.012c.3.02.44.032.6.046 2.06-.026 3.95-.686 5.49-1.86l1.12-.85-1.4-.048c-1.57-.055-2.92-1.08-3.36-2.51l-.48.146-.05.5c.22.03.48.05.75.08.48-.02.87-.07 1.25-.15l2.33-.49-2.32-.49c-1.68-.35-2.91-1.83-2.91-3.55 0-.05 0-.01-.01.03l-.49-.1-.25.44c.63.36 1.35.57 2.07.58l1.7.04L7.4 13c-.978-.662-1.59-1.79-1.618-3.047a4.08 4.08 0 0 1 .524-1.8l-.825.07a12.188 12.188 0 0 0 8.81 4.515l.59.033-.06-.59v-.02c-.05-.43-.06-.63-.06-.87a3.617 3.617 0 0 1 6.27-2.45l.2.21.28-.06c1.01-.22 1.94-.59 2.73-1.09l-.75-.56c-.1.36-.04.89.12 1.36.23.68.58 1.13 1.17.85l-.21-.45-.42-.27c-.52.8-1.17 1.48-1.92 2L22 11l.016.28c.013.2.014.35 0 .52v.04zm.998.038c.018-.22.017-.417 0-.66l-.498.034.284.41a8.183 8.183 0 0 0 2.2-2.267l.97-1.48-1.6.755c.17-.08.3-.02.34.03a.914.914 0 0 1-.13-.292c-.1-.297-.13-.64-.1-.766l.36-1.254-1.1.695c-.69.438-1.51.764-2.41.963l.48.15a4.574 4.574 0 0 0-3.38-1.484 4.616 4.616 0 0 0-4.61 4.613c0 .29.02.51.08.984l.01.02.5-.06.03-.5c-3.17-.18-6.1-1.7-8.08-4.15l-.48-.56-.36.64c-.39.69-.62 1.48-.65 2.28.04 1.61.81 3.04 2.06 3.88l.3-.92c-.55-.02-1.11-.17-1.6-.45l-.59-.34-.14.67c-.02.08-.02.16 0 .24-.01 2.12 1.55 4.01 3.69 4.46l.1-.49-.1-.49c-.33.07-.67.12-1.03.14-.18-.02-.43-.05-.64-.07l-.76-.09.23.73c.57 1.84 2.29 3.14 4.28 3.21l-.28-.89a8.252 8.252 0 0 1-4.85 1.66c-.12-.01-.26-.02-.56-.05l-.17-.01-.18-.01L2.53 21l1.694 1.07a12.233 12.233 0 0 0 6.58 1.917c7.156 0 12.2-5.73 12.18-12.18l-.002.04z"></path></svg></span></button><button class="button button--large button--dark button--chromeless is-touchIconBlackPulse u-baseColor--buttonDark button--withIcon button--withSvgIcon u-xs-hide" title="Share on Facebook" aria-label="Share on Facebook" data-action="share-on-facebook" data-action-source="post_actions_footer"><span class="svgIcon svgIcon--facebook svgIcon--29px"><svg class="svgIcon-use" width="29" height="29" viewBox="0 0 29 29"><path d="M16.39 23.61v-5.808h1.846a.55.55 0 0 0 .546-.48l.36-2.797a.551.551 0 0 0-.547-.62H16.39V12.67c0-.67.12-.813.828-.813h1.474a.55.55 0 0 0 .55-.55V8.803a.55.55 0 0 0-.477-.545c-.436-.06-1.36-.116-2.22-.116-2.5 0-4.13 1.62-4.13 4.248v1.513H10.56a.551.551 0 0 0-.55.55v2.797c0 .304.248.55.55.55h1.855v5.76c-4.172-.96-7.215-4.7-7.215-9.1 0-5.17 4.17-9.36 9.31-9.36 5.14 0 9.31 4.19 9.31 9.36 0 4.48-3.155 8.27-7.43 9.15M14.51 4C8.76 4 4.1 8.684 4.1 14.46c0 5.162 3.75 9.523 8.778 10.32a.55.55 0 0 0 .637-.543v-6.985a.551.551 0 0 0-.55-.55H11.11v-1.697h1.855a.55.55 0 0 0 .55-.55v-2.063c0-2.02 1.136-3.148 3.03-3.148.567 0 1.156.027 1.597.06v1.453h-.924c-1.363 0-1.93.675-1.93 1.912v1.78c0 .3.247.55.55.55h2.132l-.218 1.69H15.84c-.305 0-.55.24-.55.55v7.02c0 .33.293.59.623.54 5.135-.7 9.007-5.11 9.007-10.36C24.92 8.68 20.26 4 14.51 4"></path></svg></span></button><button class="button button--large button--dark button--chromeless u-baseColor--buttonDark button--withIcon button--withSvgIcon u-xs-show" title="Share this story on Twitter or Facebook" aria-label="Share this story on Twitter or Facebook" data-action="show-share-popover" data-action-source="post_actions_footer"><span class="svgIcon svgIcon--share svgIcon--29px"><svg class="svgIcon-use" width="29" height="29" viewBox="0 0 29 29"><path d="M20.385 8H19a.5.5 0 1 0 .011 1h1.39c.43 0 .84.168 1.14.473.31.305.48.71.48 1.142v10.77c0 .43-.17.837-.47 1.142-.3.305-.71.473-1.14.473H8.62c-.43 0-.84-.168-1.144-.473a1.603 1.603 0 0 1-.473-1.142v-10.77c0-.43.17-.837.48-1.142A1.599 1.599 0 0 1 8.62 9H10a.502.502 0 0 0 0-1H8.615c-.67 0-1.338.255-1.85.766-.51.51-.765 1.18-.765 1.85v10.77c0 .668.255 1.337.766 1.848.51.51 1.18.766 1.85.766h11.77c.668 0 1.337-.255 1.848-.766.51-.51.766-1.18.766-1.85v-10.77c0-.668-.255-1.337-.766-1.848A2.61 2.61 0 0 0 20.384 8zm-8.67-2.508L14 3.207v8.362c0 .27.224.5.5.5s.5-.23.5-.5V3.2l2.285 2.285a.49.49 0 0 0 .704-.001.511.511 0 0 0 0-.708l-3.14-3.14a.504.504 0 0 0-.71 0L11 4.776a.501.501 0 0 0 .71.706" fill-rule="evenodd"></path></svg></span></button></div></div></div></div><div class="u-maxWidth740 u-paddingTop20 u-marginTop20 u-borderTopLightest container u-paddingBottom20 u-xs-paddingBottom10 js-postAttributionFooterContainer"><div class="row js-postFooterInfo"><div class="col u-size6of12 u-xs-size12of12"><li class="uiScale uiScale-ui--small uiScale-caption--regular u-block u-paddingBottom18 js-cardUser"><div class="u-marginLeft20 u-floatRight"><span class="followState js-followState" data-user-id="45cca2d4999f"><button class="button button--small u-noUserSelect button--withChrome u-baseColor--buttonNormal button--withHover button--unblock js-unblockButton" data-action="sign-up-prompt" data-sign-in-action="toggle-block-user" data-requires-token="true" data-redirect="https://blog.insightdatascience.com/reinforcement-learning-from-scratch-819b65f074d8?source=search_post---------6" data-action-source="footer_card"><span class="button-label  button-defaultState">Blocked</span><span class="button-label button-hoverState">Unblock</span></button><button class="button button--primary button--small u-noUserSelect button--withChrome u-accentColor--buttonNormal button--follow js-followButton" data-action="sign-up-prompt" data-sign-in-action="toggle-subscribe-user" data-requires-token="true" data-redirect="https://medium.com/_/subscribe/user/45cca2d4999f" data-action-source="footer_card-45cca2d4999f-------------------------follow_footer"><span class="button-label  button-defaultState js-buttonLabel">Follow</span><span class="button-label button-activeState">Following</span></button></span></div><div class="u-tableCell"><a class="link u-baseColor--link avatar" href="https://blog.insightdatascience.com/@emmanuelameisen?source=footer_card" title="Go to the profile of Emmanuel Ameisen" aria-label="Go to the profile of Emmanuel Ameisen" data-action-source="footer_card" data-user-id="45cca2d4999f" data-collection-slug="insight-data" dir="auto"><img src="./Reinforcement Learning from scratch – Insight Data_files/1_u2FiBL9mzFPx7pj87aWxgw.jpeg" class="avatar-image avatar-image--small" alt="Go to the profile of Emmanuel Ameisen"></a></div><div class="u-tableCell u-verticalAlignMiddle u-breakWord u-paddingLeft15"><h3 class="ui-h3 u-fontSize18 u-lineHeightTighter u-marginBottom4"><a class="link link--primary u-accentColor--hoverTextNormal" href="https://blog.insightdatascience.com/@emmanuelameisen" property="cc:attributionName" title="Go to the profile of Emmanuel Ameisen" aria-label="Go to the profile of Emmanuel Ameisen" rel="author cc:attributionUrl" data-user-id="45cca2d4999f" data-collection-slug="insight-data" dir="auto">Emmanuel Ameisen</a></h3><p class="ui-body u-fontSize14 u-lineHeightBaseSans u-textColorDark u-marginBottom4">AI Lead at Insight AI <a href="http://twitter.com/EmmanuelAmeisen" target="_blank" title="Twitter profile for @EmmanuelAmeisen">@EmmanuelAmeisen</a></p></div></li></div><div class="col u-size6of12 u-xs-size12of12 u-xs-marginTop30"><li class="uiScale uiScale-ui--small uiScale-caption--regular u-block u-paddingBottom18 js-cardCollection"><div class="u-marginLeft20 u-floatRight"><button class="button button--primary button--small u-noUserSelect button--withChrome u-accentColor--buttonNormal js-relationshipButton" data-action="sign-up-prompt" data-sign-in-action="toggle-follow-collection" data-requires-token="true" data-redirect="https://medium.com/_/subscribe/collection/insight-data" data-action-source="----d02e65779d7b----------------------follow_footer" data-collection-id="d02e65779d7b"><span class="button-label  js-buttonLabel">Follow</span></button></div><div class="u-tableCell "><a class="link u-baseColor--link avatar avatar--roundedRectangle" href="https://blog.insightdatascience.com/?source=footer_card" title="Go to Insight Data" aria-label="Go to Insight Data" data-action-source="footer_card" data-collection-slug="insight-data"><img src="./Reinforcement Learning from scratch – Insight Data_files/1_bVN8Kd_RsjRN8JuKIc6U0w.png" class="avatar-image u-size60x60" alt="Insight Data"></a></div><div class="u-tableCell u-verticalAlignMiddle u-breakWord u-paddingLeft15"><h3 class="ui-h3 u-fontSize18 u-lineHeightTighter u-marginBottom4"><a class="link link--primary u-accentColor--hoverTextNormal" href="https://blog.insightdatascience.com/?source=footer_card" rel="collection" data-action-source="footer_card" data-collection-slug="insight-data">Insight Data</a></h3><p class="ui-body u-fontSize14 u-lineHeightBaseSans u-textColorDark u-marginBottom4">Insight Fellows Program - Your bridge to a career in data</p><div class="buttonSet"></div></div></li></div></div></div><div class="js-postFooterPlacements"><div class="streamItem streamItem--placementCardGrid js-streamItem"><div class="u-clearfix u-backgroundGrayLightest"><div class="row u-marginAuto u-maxWidth1000 u-paddingTop30 u-paddingBottom40"><div class="col u-padding8 u-xs-size12of12 u-size4of12"><div class="uiScale uiScale-ui--small uiScale-caption--regular u-height280 u-sizeFullWidth u-backgroundWhite u-borderCardBorder u-boxShadow u-borderBox u-borderRadius4 js-trackedPost" data-post-id="dd14d673ed6d" data-source="placement_card_footer_grid---------0-41" data-tracking-context="placement" data-scroll="native"><a class="link link--noUnderline u-baseColor--link" href="https://blog.insightdatascience.com/gefilter-fish-finding-concise-topics-from-amazons-customer-reviews-dd14d673ed6d?source=placement_card_footer_grid---------0-41" data-action-source="placement_card_footer_grid---------0-41"><div class="u-backgroundCover u-backgroundColorGrayLight u-height100 u-sizeFullWidth u-borderBottomLight u-borderRadiusTop4" style="background-image: url(&quot;https://cdn-images-1.medium.com/fit/c/400/120/1*VYu9YKqE7gKNNRmY2qtwYQ.png&quot;); background-position: 50% 50% !important;"></div></a><div class="u-padding15 u-borderBox u-flexColumn u-height180"><a class="link link--noUnderline u-baseColor--link u-flex1" href="https://blog.insightdatascience.com/gefilter-fish-finding-concise-topics-from-amazons-customer-reviews-dd14d673ed6d?source=placement_card_footer_grid---------0-41" data-action-source="placement_card_footer_grid---------0-41"><div class="uiScale uiScale-ui--regular uiScale-caption--small u-textColorNormal u-marginBottom7">More from Insight Data</div><div class="ui-h3 ui-clamp2 u-textColorDarkest u-contentSansBold u-fontSize24 u-maxHeight2LineHeightTighter u-lineClamp2 u-textOverflowEllipsis u-letterSpacingTight u-paddingBottom2">Gefilter Fish: Finding concise topics from Amazon’s customer reviews</div></a><div class="u-paddingBottom10 u-flex0 u-flexCenter"><div class="u-flex1 u-minWidth0 u-marginRight10"><div class="u-flexCenter"><div class="postMetaInline-avatar u-flex0"><a class="link u-baseColor--link avatar" href="https://blog.insightdatascience.com/@patricklestrange" data-action="show-user-card" data-action-value="c285e6a4d25f" data-action-type="hover" data-user-id="c285e6a4d25f" data-collection-slug="insight-data" dir="auto"><img src="./Reinforcement Learning from scratch – Insight Data_files/1_gf3mz0AC9u6mzubUEFgpkw.jpeg" class="avatar-image u-size36x36 u-xs-size32x32" alt="Go to the profile of Patrick Lestrange"></a></div><div class="postMetaInline postMetaInline-authorLockup ui-captionStrong u-flex1 u-noWrapWithEllipsis"><a class="ds-link ds-link--styleSubtle link link--darken link--darker" href="https://blog.insightdatascience.com/@patricklestrange?source=placement_card_footer_grid---------0-41" data-action="show-user-card" data-action-source="placement_card_footer_grid---------0-41" data-action-value="c285e6a4d25f" data-action-type="hover" data-user-id="c285e6a4d25f" data-collection-slug="insight-data" dir="auto">Patrick Lestrange</a><div class="ui-caption u-fontSize12 u-baseColor--textNormal u-textColorNormal js-postMetaInlineSupplemental"><span class="readingTime u-textColorNormal" title="9 min read"></span></div></div></div></div><div class="u-flex0 u-flexCenter"><div class="buttonSet"><div class="multirecommend js-actionMultirecommend u-flexCenter" data-post-id="dd14d673ed6d" data-is-label-padded="true" data-source="placement_card_footer_grid-----dd14d673ed6d----0-41----------------clap_preview"><div class="u-relative u-foreground"><button class="button button--primary button--chromeless u-accentColor--buttonNormal button--withIcon button--withSvgIcon clapButton js-actionMultirecommendButton" data-action="sign-up-prompt" data-sign-in-action="multivote" data-requires-token="true" data-redirect="https://medium.com/_/vote/p/dd14d673ed6d" data-action-source="placement_card_footer_grid-----dd14d673ed6d----0-41----------------clap_preview" aria-label="Clap"><span class="button-defaultState"><span class="svgIcon svgIcon--clap svgIcon--25px"><svg class="svgIcon-use" width="25" height="25" viewBox="0 0 25 25"><g fill-rule="evenodd"><path d="M11.739 0l.761 2.966L13.261 0z"></path><path d="M14.815 3.776l1.84-2.551-1.43-.471z"></path><path d="M8.378 1.224l1.84 2.551L9.81.753z"></path><path d="M20.382 21.622c-1.04 1.04-2.115 1.507-3.166 1.608.168-.14.332-.29.492-.45 2.885-2.886 3.456-5.982 1.69-9.211l-1.101-1.937-.955-2.02c-.315-.676-.235-1.185.245-1.556a.836.836 0 0 1 .66-.16c.342.056.66.28.879.605l2.856 5.023c1.179 1.962 1.379 5.119-1.6 8.098m-13.29-.528l-5.02-5.02a1 1 0 0 1 .707-1.701c.255 0 .512.098.707.292l2.607 2.607a.442.442 0 0 0 .624-.624L4.11 14.04l-1.75-1.75a.998.998 0 1 1 1.41-1.413l4.154 4.156a.44.44 0 0 0 .624 0 .44.44 0 0 0 0-.624l-4.152-4.153-1.172-1.171a.998.998 0 0 1 0-1.41 1.018 1.018 0 0 1 1.41 0l1.172 1.17 4.153 4.152a.437.437 0 0 0 .624 0 .442.442 0 0 0 0-.624L6.43 8.222a.988.988 0 0 1-.291-.705.99.99 0 0 1 .29-.706 1 1 0 0 1 1.412 0l6.992 6.993a.443.443 0 0 0 .71-.501l-1.35-2.856c-.315-.676-.235-1.185.246-1.557a.85.85 0 0 1 .66-.16c.342.056.659.28.879.606L18.628 14c1.573 2.876 1.067 5.545-1.544 8.156-1.396 1.397-3.144 1.966-5.063 1.652-1.713-.286-3.463-1.248-4.928-2.714zM10.99 5.976l2.562 2.562c-.497.607-.563 1.414-.155 2.284l.265.562-4.257-4.257a.98.98 0 0 1-.117-.445c0-.267.104-.517.292-.706a1.023 1.023 0 0 1 1.41 0zm8.887 2.06c-.375-.557-.902-.916-1.486-1.011a1.738 1.738 0 0 0-1.342.332c-.376.29-.61.656-.712 1.065a2.1 2.1 0 0 0-1.095-.562 1.776 1.776 0 0 0-.992.128l-2.636-2.636a1.883 1.883 0 0 0-2.658 0 1.862 1.862 0 0 0-.478.847 1.886 1.886 0 0 0-2.671-.012 1.867 1.867 0 0 0-.503.909c-.754-.754-1.992-.754-2.703-.044a1.881 1.881 0 0 0 0 2.658c-.288.12-.605.288-.864.547a1.884 1.884 0 0 0 0 2.659l.624.622a1.879 1.879 0 0 0-.91 3.16l5.019 5.02c1.595 1.594 3.515 2.645 5.408 2.959a7.16 7.16 0 0 0 1.173.098c1.026 0 1.997-.24 2.892-.7.279.04.555.065.828.065 1.53 0 2.969-.628 4.236-1.894 3.338-3.338 3.083-6.928 1.738-9.166l-2.868-5.043z"></path></g></svg></span></span><span class="button-activeState"><span class="svgIcon svgIcon--clapFilled svgIcon--25px"><svg class="svgIcon-use" width="25" height="25" viewBox="0 0 25 25"><g fill-rule="evenodd"><path d="M11.738 0l.762 2.966L13.262 0z"></path><path d="M16.634 1.224l-1.432-.47-.408 3.022z"></path><path d="M9.79.754l-1.431.47 1.84 2.552z"></path><path d="M22.472 13.307l-3.023-5.32c-.287-.426-.689-.705-1.123-.776a1.16 1.16 0 0 0-.911.221c-.297.231-.474.515-.535.84.017.022.036.04.053.063l2.843 5.001c1.95 3.564 1.328 6.973-1.843 10.144a8.46 8.46 0 0 1-.549.501c1.205-.156 2.328-.737 3.351-1.76 3.268-3.268 3.041-6.749 1.737-8.914"></path><path d="M12.58 9.887c-.156-.83.096-1.569.692-2.142L10.78 5.252c-.5-.504-1.378-.504-1.879 0-.178.18-.273.4-.329.63l4.008 4.005z"></path><path d="M15.812 9.04c-.218-.323-.539-.55-.88-.606a.814.814 0 0 0-.644.153c-.176.137-.713.553-.24 1.566l1.43 3.025a.539.539 0 1 1-.868.612L7.2 6.378a.986.986 0 1 0-1.395 1.395l4.401 4.403a.538.538 0 1 1-.762.762L5.046 8.54 3.802 7.295a.99.99 0 0 0-1.396 0 .981.981 0 0 0 0 1.394L3.647 9.93l4.402 4.403a.537.537 0 0 1 0 .761.535.535 0 0 1-.762 0L2.89 10.696a.992.992 0 0 0-1.399-.003.983.983 0 0 0 0 1.395l1.855 1.854 2.763 2.765a.538.538 0 0 1-.76.761l-2.765-2.764a.982.982 0 0 0-1.395 0 .989.989 0 0 0 0 1.395l5.32 5.32c3.371 3.372 6.64 4.977 10.49 1.126C19.74 19.8 20.271 17 18.62 13.982L15.812 9.04z"></path></g></svg></span></span></button></div><span class="u-textAlignCenter u-relative u-background js-actionMultirecommendCount u-marginLeft5"><button class="button button--chromeless u-baseColor--buttonNormal js-multirecommendCountButton u-disablePointerEvents u-marginLeft4" data-action="show-recommends" data-action-value="dd14d673ed6d">323</button></span></div></div><div class="u-height20 u-borderRightLighter u-inlineBlock u-relative u-marginRight10 u-marginLeft12"></div><div class="buttonSet"><button class="button button--chromeless is-touchIconFadeInPulse u-baseColor--buttonNormal button--withIcon button--withSvgIcon button--bookmark js-bookmarkButton" title="Bookmark this story to read later" aria-label="Bookmark this story to read later" data-action="sign-up-prompt" data-sign-in-action="add-to-bookmarks" data-requires-token="true" data-redirect="https://medium.com/_/bookmark/p/dd14d673ed6d" data-action-source="placement_card_footer_grid-----dd14d673ed6d----0-41----------------bookmark_preview"><span class="button-defaultState"><span class="svgIcon svgIcon--bookmark svgIcon--25px"><svg class="svgIcon-use" width="25" height="25" viewBox="0 0 25 25"><path d="M19 6c0-1.1-.9-2-2-2H8c-1.1 0-2 .9-2 2v14.66h.012c.01.103.045.204.12.285a.5.5 0 0 0 .706.03L12.5 16.85l5.662 4.126a.508.508 0 0 0 .708-.03.5.5 0 0 0 .118-.285H19V6zm-6.838 9.97L7 19.636V6c0-.55.45-1 1-1h9c.55 0 1 .45 1 1v13.637l-5.162-3.668a.49.49 0 0 0-.676 0z" fill-rule="evenodd"></path></svg></span></span><span class="button-activeState"><span class="svgIcon svgIcon--bookmarkFilled svgIcon--25px"><svg class="svgIcon-use" width="25" height="25" viewBox="0 0 25 25"><path d="M19 6c0-1.1-.9-2-2-2H8c-1.1 0-2 .9-2 2v14.66h.012c.01.103.045.204.12.285a.5.5 0 0 0 .706.03L12.5 16.85l5.662 4.126c.205.183.52.17.708-.03a.5.5 0 0 0 .118-.285H19V6z"></path></svg></span></span></button></div></div></div></div></div></div><div class="col u-padding8 u-xs-size12of12 u-size4of12"><div class="uiScale uiScale-ui--small uiScale-caption--regular u-height280 u-sizeFullWidth u-backgroundWhite u-borderCardBorder u-boxShadow u-borderBox u-borderRadius4 js-trackedPost" data-post-id="fda605278e4e" data-source="placement_card_footer_grid---------1-41" data-tracking-context="placement" data-scroll="native"><a class="link link--noUnderline u-baseColor--link" href="https://blog.insightdatascience.com/how-to-solve-90-of-nlp-problems-a-step-by-step-guide-fda605278e4e?source=placement_card_footer_grid---------1-41" data-action-source="placement_card_footer_grid---------1-41"><div class="u-backgroundCover u-backgroundColorGrayLight u-height100 u-sizeFullWidth u-borderBottomLight u-borderRadiusTop4" style="background-image: url(&quot;https://cdn-images-1.medium.com/fit/c/400/120/1*J8-5VgoWtMsIJhyHAuljSw.png&quot;); background-position: 50% 50% !important;"></div></a><div class="u-padding15 u-borderBox u-flexColumn u-height180"><a class="link link--noUnderline u-baseColor--link u-flex1" href="https://blog.insightdatascience.com/how-to-solve-90-of-nlp-problems-a-step-by-step-guide-fda605278e4e?source=placement_card_footer_grid---------1-41" data-action-source="placement_card_footer_grid---------1-41"><div class="uiScale uiScale-ui--regular uiScale-caption--small u-textColorNormal u-marginBottom7">More from Insight Data</div><div class="ui-h3 ui-clamp2 u-textColorDarkest u-contentSansBold u-fontSize24 u-maxHeight2LineHeightTighter u-lineClamp2 u-textOverflowEllipsis u-letterSpacingTight u-paddingBottom2">How to solve 90% of NLP problems: a step-by-step guide</div></a><div class="u-paddingBottom10 u-flex0 u-flexCenter"><div class="u-flex1 u-minWidth0 u-marginRight10"><div class="u-flexCenter"><div class="postMetaInline-avatar u-flex0"><a class="link u-baseColor--link avatar" href="https://blog.insightdatascience.com/@emmanuelameisen" data-action="show-user-card" data-action-value="45cca2d4999f" data-action-type="hover" data-user-id="45cca2d4999f" data-collection-slug="insight-data" dir="auto"><img src="./Reinforcement Learning from scratch – Insight Data_files/1_u2FiBL9mzFPx7pj87aWxgw(1).jpeg" class="avatar-image u-size36x36 u-xs-size32x32" alt="Go to the profile of Emmanuel Ameisen"></a></div><div class="postMetaInline postMetaInline-authorLockup ui-captionStrong u-flex1 u-noWrapWithEllipsis"><a class="ds-link ds-link--styleSubtle link link--darken link--darker" href="https://blog.insightdatascience.com/@emmanuelameisen?source=placement_card_footer_grid---------1-41" data-action="show-user-card" data-action-source="placement_card_footer_grid---------1-41" data-action-value="45cca2d4999f" data-action-type="hover" data-user-id="45cca2d4999f" data-collection-slug="insight-data" dir="auto">Emmanuel Ameisen</a><div class="ui-caption u-fontSize12 u-baseColor--textNormal u-textColorNormal js-postMetaInlineSupplemental"><span class="readingTime u-textColorNormal" title="13 min read"></span></div></div></div></div><div class="u-flex0 u-flexCenter"><div class="buttonSet"><div class="multirecommend js-actionMultirecommend u-flexCenter" data-post-id="fda605278e4e" data-is-label-padded="true" data-source="placement_card_footer_grid-----fda605278e4e----1-41----------------clap_preview"><div class="u-relative u-foreground"><button class="button button--primary button--chromeless u-accentColor--buttonNormal button--withIcon button--withSvgIcon clapButton js-actionMultirecommendButton" data-action="sign-up-prompt" data-sign-in-action="multivote" data-requires-token="true" data-redirect="https://medium.com/_/vote/p/fda605278e4e" data-action-source="placement_card_footer_grid-----fda605278e4e----1-41----------------clap_preview" aria-label="Clap"><span class="button-defaultState"><span class="svgIcon svgIcon--clap svgIcon--25px"><svg class="svgIcon-use" width="25" height="25" viewBox="0 0 25 25"><g fill-rule="evenodd"><path d="M11.739 0l.761 2.966L13.261 0z"></path><path d="M14.815 3.776l1.84-2.551-1.43-.471z"></path><path d="M8.378 1.224l1.84 2.551L9.81.753z"></path><path d="M20.382 21.622c-1.04 1.04-2.115 1.507-3.166 1.608.168-.14.332-.29.492-.45 2.885-2.886 3.456-5.982 1.69-9.211l-1.101-1.937-.955-2.02c-.315-.676-.235-1.185.245-1.556a.836.836 0 0 1 .66-.16c.342.056.66.28.879.605l2.856 5.023c1.179 1.962 1.379 5.119-1.6 8.098m-13.29-.528l-5.02-5.02a1 1 0 0 1 .707-1.701c.255 0 .512.098.707.292l2.607 2.607a.442.442 0 0 0 .624-.624L4.11 14.04l-1.75-1.75a.998.998 0 1 1 1.41-1.413l4.154 4.156a.44.44 0 0 0 .624 0 .44.44 0 0 0 0-.624l-4.152-4.153-1.172-1.171a.998.998 0 0 1 0-1.41 1.018 1.018 0 0 1 1.41 0l1.172 1.17 4.153 4.152a.437.437 0 0 0 .624 0 .442.442 0 0 0 0-.624L6.43 8.222a.988.988 0 0 1-.291-.705.99.99 0 0 1 .29-.706 1 1 0 0 1 1.412 0l6.992 6.993a.443.443 0 0 0 .71-.501l-1.35-2.856c-.315-.676-.235-1.185.246-1.557a.85.85 0 0 1 .66-.16c.342.056.659.28.879.606L18.628 14c1.573 2.876 1.067 5.545-1.544 8.156-1.396 1.397-3.144 1.966-5.063 1.652-1.713-.286-3.463-1.248-4.928-2.714zM10.99 5.976l2.562 2.562c-.497.607-.563 1.414-.155 2.284l.265.562-4.257-4.257a.98.98 0 0 1-.117-.445c0-.267.104-.517.292-.706a1.023 1.023 0 0 1 1.41 0zm8.887 2.06c-.375-.557-.902-.916-1.486-1.011a1.738 1.738 0 0 0-1.342.332c-.376.29-.61.656-.712 1.065a2.1 2.1 0 0 0-1.095-.562 1.776 1.776 0 0 0-.992.128l-2.636-2.636a1.883 1.883 0 0 0-2.658 0 1.862 1.862 0 0 0-.478.847 1.886 1.886 0 0 0-2.671-.012 1.867 1.867 0 0 0-.503.909c-.754-.754-1.992-.754-2.703-.044a1.881 1.881 0 0 0 0 2.658c-.288.12-.605.288-.864.547a1.884 1.884 0 0 0 0 2.659l.624.622a1.879 1.879 0 0 0-.91 3.16l5.019 5.02c1.595 1.594 3.515 2.645 5.408 2.959a7.16 7.16 0 0 0 1.173.098c1.026 0 1.997-.24 2.892-.7.279.04.555.065.828.065 1.53 0 2.969-.628 4.236-1.894 3.338-3.338 3.083-6.928 1.738-9.166l-2.868-5.043z"></path></g></svg></span></span><span class="button-activeState"><span class="svgIcon svgIcon--clapFilled svgIcon--25px"><svg class="svgIcon-use" width="25" height="25" viewBox="0 0 25 25"><g fill-rule="evenodd"><path d="M11.738 0l.762 2.966L13.262 0z"></path><path d="M16.634 1.224l-1.432-.47-.408 3.022z"></path><path d="M9.79.754l-1.431.47 1.84 2.552z"></path><path d="M22.472 13.307l-3.023-5.32c-.287-.426-.689-.705-1.123-.776a1.16 1.16 0 0 0-.911.221c-.297.231-.474.515-.535.84.017.022.036.04.053.063l2.843 5.001c1.95 3.564 1.328 6.973-1.843 10.144a8.46 8.46 0 0 1-.549.501c1.205-.156 2.328-.737 3.351-1.76 3.268-3.268 3.041-6.749 1.737-8.914"></path><path d="M12.58 9.887c-.156-.83.096-1.569.692-2.142L10.78 5.252c-.5-.504-1.378-.504-1.879 0-.178.18-.273.4-.329.63l4.008 4.005z"></path><path d="M15.812 9.04c-.218-.323-.539-.55-.88-.606a.814.814 0 0 0-.644.153c-.176.137-.713.553-.24 1.566l1.43 3.025a.539.539 0 1 1-.868.612L7.2 6.378a.986.986 0 1 0-1.395 1.395l4.401 4.403a.538.538 0 1 1-.762.762L5.046 8.54 3.802 7.295a.99.99 0 0 0-1.396 0 .981.981 0 0 0 0 1.394L3.647 9.93l4.402 4.403a.537.537 0 0 1 0 .761.535.535 0 0 1-.762 0L2.89 10.696a.992.992 0 0 0-1.399-.003.983.983 0 0 0 0 1.395l1.855 1.854 2.763 2.765a.538.538 0 0 1-.76.761l-2.765-2.764a.982.982 0 0 0-1.395 0 .989.989 0 0 0 0 1.395l5.32 5.32c3.371 3.372 6.64 4.977 10.49 1.126C19.74 19.8 20.271 17 18.62 13.982L15.812 9.04z"></path></g></svg></span></span></button></div><span class="u-textAlignCenter u-relative u-background js-actionMultirecommendCount u-marginLeft5"><button class="button button--chromeless u-baseColor--buttonNormal js-multirecommendCountButton u-disablePointerEvents u-marginLeft4" data-action="show-recommends" data-action-value="fda605278e4e">13.8K</button></span></div></div><div class="u-height20 u-borderRightLighter u-inlineBlock u-relative u-marginRight10 u-marginLeft12"></div><div class="buttonSet"><button class="button button--chromeless is-touchIconFadeInPulse u-baseColor--buttonNormal button--withIcon button--withSvgIcon button--bookmark js-bookmarkButton" title="Bookmark this story to read later" aria-label="Bookmark this story to read later" data-action="sign-up-prompt" data-sign-in-action="add-to-bookmarks" data-requires-token="true" data-redirect="https://medium.com/_/bookmark/p/fda605278e4e" data-action-source="placement_card_footer_grid-----fda605278e4e----1-41----------------bookmark_preview"><span class="button-defaultState"><span class="svgIcon svgIcon--bookmark svgIcon--25px"><svg class="svgIcon-use" width="25" height="25" viewBox="0 0 25 25"><path d="M19 6c0-1.1-.9-2-2-2H8c-1.1 0-2 .9-2 2v14.66h.012c.01.103.045.204.12.285a.5.5 0 0 0 .706.03L12.5 16.85l5.662 4.126a.508.508 0 0 0 .708-.03.5.5 0 0 0 .118-.285H19V6zm-6.838 9.97L7 19.636V6c0-.55.45-1 1-1h9c.55 0 1 .45 1 1v13.637l-5.162-3.668a.49.49 0 0 0-.676 0z" fill-rule="evenodd"></path></svg></span></span><span class="button-activeState"><span class="svgIcon svgIcon--bookmarkFilled svgIcon--25px"><svg class="svgIcon-use" width="25" height="25" viewBox="0 0 25 25"><path d="M19 6c0-1.1-.9-2-2-2H8c-1.1 0-2 .9-2 2v14.66h.012c.01.103.045.204.12.285a.5.5 0 0 0 .706.03L12.5 16.85l5.662 4.126c.205.183.52.17.708-.03a.5.5 0 0 0 .118-.285H19V6z"></path></svg></span></span></button></div></div></div></div></div></div><div class="col u-padding8 u-xs-size12of12 u-size4of12"><div class="uiScale uiScale-ui--small uiScale-caption--regular u-height280 u-sizeFullWidth u-backgroundWhite u-borderCardBorder u-boxShadow u-borderBox u-borderRadius4 js-trackedPost" data-post-id="765b93b88296" data-source="placement_card_footer_grid---------2-41" data-tracking-context="placement" data-scroll="native"><a class="link link--noUnderline u-baseColor--link" href="https://blog.insightdatascience.com/from-law-to-data-science-765b93b88296?source=placement_card_footer_grid---------2-41" data-action-source="placement_card_footer_grid---------2-41"><div class="u-backgroundCover u-backgroundColorGrayLight u-height100 u-sizeFullWidth u-borderBottomLight u-borderRadiusTop4" style="background-image: url(&quot;https://cdn-images-1.medium.com/fit/c/400/120/1*rvzdo_McCm86VKv06YgjPw.jpeg&quot;); background-position: 50% 50% !important;"></div></a><div class="u-padding15 u-borderBox u-flexColumn u-height180"><a class="link link--noUnderline u-baseColor--link u-flex1" href="https://blog.insightdatascience.com/from-law-to-data-science-765b93b88296?source=placement_card_footer_grid---------2-41" data-action-source="placement_card_footer_grid---------2-41"><div class="uiScale uiScale-ui--regular uiScale-caption--small u-textColorNormal u-marginBottom7">More from Insight Data</div><div class="ui-h3 ui-clamp2 u-textColorDarkest u-contentSansBold u-fontSize24 u-maxHeight2LineHeightTighter u-lineClamp2 u-textOverflowEllipsis u-letterSpacingTight u-paddingBottom2">From Law to Data Science</div></a><div class="u-paddingBottom10 u-flex0 u-flexCenter"><div class="u-flex1 u-minWidth0 u-marginRight10"><div class="u-flexCenter"><div class="postMetaInline-avatar u-flex0"><a class="link u-baseColor--link avatar" href="https://blog.insightdatascience.com/@InsightData" data-action="show-user-card" data-action-value="7b169ef2b4c1" data-action-type="hover" data-user-id="7b169ef2b4c1" data-collection-slug="insight-data" dir="auto"><img src="./Reinforcement Learning from scratch – Insight Data_files/1_YPfMhzi8uuY-Mc2WkeY5yw.png" class="avatar-image u-size36x36 u-xs-size32x32" alt="Go to the profile of Insight Data"></a></div><div class="postMetaInline postMetaInline-authorLockup ui-captionStrong u-flex1 u-noWrapWithEllipsis"><a class="ds-link ds-link--styleSubtle link link--darken link--darker" href="https://blog.insightdatascience.com/@InsightData?source=placement_card_footer_grid---------2-41" data-action="show-user-card" data-action-source="placement_card_footer_grid---------2-41" data-action-value="7b169ef2b4c1" data-action-type="hover" data-user-id="7b169ef2b4c1" data-collection-slug="insight-data" dir="auto">Insight Data</a><div class="ui-caption u-fontSize12 u-baseColor--textNormal u-textColorNormal js-postMetaInlineSupplemental"><span class="readingTime u-textColorNormal" title="7 min read"></span></div></div></div></div><div class="u-flex0 u-flexCenter"><div class="buttonSet"><div class="multirecommend js-actionMultirecommend u-flexCenter" data-post-id="765b93b88296" data-is-label-padded="true" data-source="placement_card_footer_grid-----765b93b88296----2-41----------------clap_preview"><div class="u-relative u-foreground"><button class="button button--primary button--chromeless u-accentColor--buttonNormal button--withIcon button--withSvgIcon clapButton js-actionMultirecommendButton" data-action="sign-up-prompt" data-sign-in-action="multivote" data-requires-token="true" data-redirect="https://medium.com/_/vote/p/765b93b88296" data-action-source="placement_card_footer_grid-----765b93b88296----2-41----------------clap_preview" aria-label="Clap"><span class="button-defaultState"><span class="svgIcon svgIcon--clap svgIcon--25px"><svg class="svgIcon-use" width="25" height="25" viewBox="0 0 25 25"><g fill-rule="evenodd"><path d="M11.739 0l.761 2.966L13.261 0z"></path><path d="M14.815 3.776l1.84-2.551-1.43-.471z"></path><path d="M8.378 1.224l1.84 2.551L9.81.753z"></path><path d="M20.382 21.622c-1.04 1.04-2.115 1.507-3.166 1.608.168-.14.332-.29.492-.45 2.885-2.886 3.456-5.982 1.69-9.211l-1.101-1.937-.955-2.02c-.315-.676-.235-1.185.245-1.556a.836.836 0 0 1 .66-.16c.342.056.66.28.879.605l2.856 5.023c1.179 1.962 1.379 5.119-1.6 8.098m-13.29-.528l-5.02-5.02a1 1 0 0 1 .707-1.701c.255 0 .512.098.707.292l2.607 2.607a.442.442 0 0 0 .624-.624L4.11 14.04l-1.75-1.75a.998.998 0 1 1 1.41-1.413l4.154 4.156a.44.44 0 0 0 .624 0 .44.44 0 0 0 0-.624l-4.152-4.153-1.172-1.171a.998.998 0 0 1 0-1.41 1.018 1.018 0 0 1 1.41 0l1.172 1.17 4.153 4.152a.437.437 0 0 0 .624 0 .442.442 0 0 0 0-.624L6.43 8.222a.988.988 0 0 1-.291-.705.99.99 0 0 1 .29-.706 1 1 0 0 1 1.412 0l6.992 6.993a.443.443 0 0 0 .71-.501l-1.35-2.856c-.315-.676-.235-1.185.246-1.557a.85.85 0 0 1 .66-.16c.342.056.659.28.879.606L18.628 14c1.573 2.876 1.067 5.545-1.544 8.156-1.396 1.397-3.144 1.966-5.063 1.652-1.713-.286-3.463-1.248-4.928-2.714zM10.99 5.976l2.562 2.562c-.497.607-.563 1.414-.155 2.284l.265.562-4.257-4.257a.98.98 0 0 1-.117-.445c0-.267.104-.517.292-.706a1.023 1.023 0 0 1 1.41 0zm8.887 2.06c-.375-.557-.902-.916-1.486-1.011a1.738 1.738 0 0 0-1.342.332c-.376.29-.61.656-.712 1.065a2.1 2.1 0 0 0-1.095-.562 1.776 1.776 0 0 0-.992.128l-2.636-2.636a1.883 1.883 0 0 0-2.658 0 1.862 1.862 0 0 0-.478.847 1.886 1.886 0 0 0-2.671-.012 1.867 1.867 0 0 0-.503.909c-.754-.754-1.992-.754-2.703-.044a1.881 1.881 0 0 0 0 2.658c-.288.12-.605.288-.864.547a1.884 1.884 0 0 0 0 2.659l.624.622a1.879 1.879 0 0 0-.91 3.16l5.019 5.02c1.595 1.594 3.515 2.645 5.408 2.959a7.16 7.16 0 0 0 1.173.098c1.026 0 1.997-.24 2.892-.7.279.04.555.065.828.065 1.53 0 2.969-.628 4.236-1.894 3.338-3.338 3.083-6.928 1.738-9.166l-2.868-5.043z"></path></g></svg></span></span><span class="button-activeState"><span class="svgIcon svgIcon--clapFilled svgIcon--25px"><svg class="svgIcon-use" width="25" height="25" viewBox="0 0 25 25"><g fill-rule="evenodd"><path d="M11.738 0l.762 2.966L13.262 0z"></path><path d="M16.634 1.224l-1.432-.47-.408 3.022z"></path><path d="M9.79.754l-1.431.47 1.84 2.552z"></path><path d="M22.472 13.307l-3.023-5.32c-.287-.426-.689-.705-1.123-.776a1.16 1.16 0 0 0-.911.221c-.297.231-.474.515-.535.84.017.022.036.04.053.063l2.843 5.001c1.95 3.564 1.328 6.973-1.843 10.144a8.46 8.46 0 0 1-.549.501c1.205-.156 2.328-.737 3.351-1.76 3.268-3.268 3.041-6.749 1.737-8.914"></path><path d="M12.58 9.887c-.156-.83.096-1.569.692-2.142L10.78 5.252c-.5-.504-1.378-.504-1.879 0-.178.18-.273.4-.329.63l4.008 4.005z"></path><path d="M15.812 9.04c-.218-.323-.539-.55-.88-.606a.814.814 0 0 0-.644.153c-.176.137-.713.553-.24 1.566l1.43 3.025a.539.539 0 1 1-.868.612L7.2 6.378a.986.986 0 1 0-1.395 1.395l4.401 4.403a.538.538 0 1 1-.762.762L5.046 8.54 3.802 7.295a.99.99 0 0 0-1.396 0 .981.981 0 0 0 0 1.394L3.647 9.93l4.402 4.403a.537.537 0 0 1 0 .761.535.535 0 0 1-.762 0L2.89 10.696a.992.992 0 0 0-1.399-.003.983.983 0 0 0 0 1.395l1.855 1.854 2.763 2.765a.538.538 0 0 1-.76.761l-2.765-2.764a.982.982 0 0 0-1.395 0 .989.989 0 0 0 0 1.395l5.32 5.32c3.371 3.372 6.64 4.977 10.49 1.126C19.74 19.8 20.271 17 18.62 13.982L15.812 9.04z"></path></g></svg></span></span></button></div><span class="u-textAlignCenter u-relative u-background js-actionMultirecommendCount u-marginLeft5"><button class="button button--chromeless u-baseColor--buttonNormal js-multirecommendCountButton u-disablePointerEvents u-marginLeft4" data-action="show-recommends" data-action-value="765b93b88296">130</button></span></div></div><div class="u-height20 u-borderRightLighter u-inlineBlock u-relative u-marginRight10 u-marginLeft12"></div><div class="buttonSet"><button class="button button--chromeless is-touchIconFadeInPulse u-baseColor--buttonNormal button--withIcon button--withSvgIcon button--bookmark js-bookmarkButton" title="Bookmark this story to read later" aria-label="Bookmark this story to read later" data-action="sign-up-prompt" data-sign-in-action="add-to-bookmarks" data-requires-token="true" data-redirect="https://medium.com/_/bookmark/p/765b93b88296" data-action-source="placement_card_footer_grid-----765b93b88296----2-41----------------bookmark_preview"><span class="button-defaultState"><span class="svgIcon svgIcon--bookmark svgIcon--25px"><svg class="svgIcon-use" width="25" height="25" viewBox="0 0 25 25"><path d="M19 6c0-1.1-.9-2-2-2H8c-1.1 0-2 .9-2 2v14.66h.012c.01.103.045.204.12.285a.5.5 0 0 0 .706.03L12.5 16.85l5.662 4.126a.508.508 0 0 0 .708-.03.5.5 0 0 0 .118-.285H19V6zm-6.838 9.97L7 19.636V6c0-.55.45-1 1-1h9c.55 0 1 .45 1 1v13.637l-5.162-3.668a.49.49 0 0 0-.676 0z" fill-rule="evenodd"></path></svg></span></span><span class="button-activeState"><span class="svgIcon svgIcon--bookmarkFilled svgIcon--25px"><svg class="svgIcon-use" width="25" height="25" viewBox="0 0 25 25"><path d="M19 6c0-1.1-.9-2-2-2H8c-1.1 0-2 .9-2 2v14.66h.012c.01.103.045.204.12.285a.5.5 0 0 0 .706.03L12.5 16.85l5.662 4.126c.205.183.52.17.708-.03a.5.5 0 0 0 .118-.285H19V6z"></path></svg></span></span></button></div></div></div></div></div></div></div></div></div></div><div class="u-padding0 u-clearfix u-backgroundGrayLightest u-print-hide supplementalPostContent js-responsesWrapper" data-action-scope="_actionscope_5"><div class="container u-maxWidth740"><div class="responsesStreamWrapper u-maxWidth640 js-responsesStreamWrapper"><div class="container responsesStream-title u-paddingTop15"><div class="row"><header class="heading"><div class="u-clearfix"><div class="heading-content u-floatLeft"><span class="heading-title heading-title--semibold">Responses</span></div></div></header></div></div><div class="responsesStream-editor cardChromeless u-marginBottom20 u-paddingLeft20 u-paddingRight20 js-responsesStreamEditor"><div class="u-paddingTop30 u-paddingBottom30 u-paddingLeft0 u-paddingRight0 u-borderBottomLightest js-responsesLoggedOutPrompt"><button class="button button--chromeless is-touchIconBlackPulse u-baseColor--buttonNormal button--withIcon button--withSvgIcon button--withIconAndLabel button--loggedOutPrompt" data-action="sign-up-prompt" data-redirect="https://blog.insightdatascience.com/reinforcement-learning-from-scratch-819b65f074d8#--respond" data-skip-onboarding="true" data-action-source="logged_out_response_prompt--------------------------respond_box"><span class="svgIcon svgIcon--response svgIcon--29px"><svg class="svgIcon-use" width="29" height="29" viewBox="0 0 29 29"><path d="M21.27 20.058c1.89-1.826 2.754-4.17 2.754-6.674C24.024 8.21 19.67 4 14.1 4 8.53 4 4 8.21 4 13.384c0 5.175 4.53 9.385 10.1 9.385 1.007 0 2-.14 2.95-.41.285.25.592.49.918.7 1.306.87 2.716 1.31 4.19 1.31.276-.01.494-.14.6-.36a.625.625 0 0 0-.052-.65c-.61-.84-1.042-1.71-1.282-2.58a5.417 5.417 0 0 1-.154-.75zm-3.85 1.324l-.083-.28-.388.12a9.72 9.72 0 0 1-2.85.424c-4.96 0-8.99-3.706-8.99-8.262 0-4.556 4.03-8.263 8.99-8.263 4.95 0 8.77 3.71 8.77 8.27 0 2.25-.75 4.35-2.5 5.92l-.24.21v.32c0 .07 0 .19.02.37.03.29.1.6.19.92.19.7.49 1.4.89 2.08-.93-.14-1.83-.49-2.67-1.06-.34-.22-.88-.48-1.16-.74z"></path></svg></span><span class="button-label  js-buttonLabel">Write a response…</span></button></div></div><div class="responsesStream js-responsesStream"></div><div class="container js-showOtherResponses"><div class="row"><button class="button button--primary button--withChrome u-accentColor--buttonNormal responsesStream-showOtherResponses cardChromeless u-sizeFullWidth u-marginVertical20 u-heightAuto" data-action="show-other-responses">Show all responses</button></div></div><div class="responsesStream js-responsesStreamOther"></div></div></div></div><div class="supplementalPostContent js-heroPromo"></div></footer></article></main><aside class="u-marginAuto u-maxWidth1000 js-postLeftSidebar"><div class="u-foreground u-top0 u-sm-hide u-marginLeftNegative12 js-postShareWidget u-transition--fadeIn300 u-fixed" data-scroll="fixed" style="transform: translateY(150px);"><ul><li class="u-textAlignCenter u-marginVertical10"><div class="multirecommend js-actionMultirecommend u-flexColumn u-marginBottom10 u-width60" data-post-id="819b65f074d8" data-is-icon-29px="true" data-is-vertical="true" data-is-circle="true" data-has-recommend-list="true" data-source="post_share_widget-----819b65f074d8---------------------clap_sidebar"><div class="u-relative u-foreground"><button class="button button--large button--circle button--withChrome u-baseColor--buttonNormal button--withIcon button--withSvgIcon clapButton js-actionMultirecommendButton clapButton--largePill u-relative u-foreground u-xs-paddingLeft13 u-width60 u-height60 u-accentColor--textNormal u-accentColor--buttonNormal" data-action="sign-up-prompt" data-sign-in-action="multivote" data-requires-token="true" data-redirect="https://medium.com/_/vote/p/819b65f074d8" data-action-source="post_share_widget-----819b65f074d8---------------------clap_sidebar" aria-label="Clap"><span class="button-defaultState"><span class="svgIcon svgIcon--clap svgIcon--33px u-relative u-topNegative2 u-xs-top0"><svg class="svgIcon-use" width="33" height="33" viewBox="0 0 33 33"><path d="M28.86 17.342l-3.64-6.402c-.292-.433-.712-.729-1.163-.8a1.124 1.124 0 0 0-.889.213c-.63.488-.742 1.181-.33 2.061l1.222 2.587 1.4 2.46c2.234 4.085 1.511 8.007-2.145 11.663-.26.26-.526.49-.797.707 1.42-.084 2.881-.683 4.292-2.094 3.822-3.823 3.565-7.876 2.05-10.395zm-6.252 11.075c3.352-3.35 3.998-6.775 1.978-10.469l-3.378-5.945c-.292-.432-.712-.728-1.163-.8a1.122 1.122 0 0 0-.89.213c-.63.49-.742 1.182-.33 2.061l1.72 3.638a.502.502 0 0 1-.806.568l-8.91-8.91a1.335 1.335 0 0 0-1.887 1.886l5.292 5.292a.5.5 0 0 1-.707.707l-5.292-5.292-1.492-1.492c-.503-.503-1.382-.505-1.887 0a1.337 1.337 0 0 0 0 1.886l1.493 1.492 5.292 5.292a.499.499 0 0 1-.353.854.5.5 0 0 1-.354-.147L5.642 13.96a1.338 1.338 0 0 0-1.887 0 1.338 1.338 0 0 0 0 1.887l2.23 2.228 3.322 3.324a.499.499 0 0 1-.353.853.502.502 0 0 1-.354-.146l-3.323-3.324a1.333 1.333 0 0 0-1.886 0 1.325 1.325 0 0 0-.39.943c0 .356.138.691.39.943l6.396 6.397c3.528 3.53 8.86 5.313 12.821 1.353zM12.73 9.26l5.68 5.68-.49-1.037c-.518-1.107-.426-2.13.224-2.89l-3.303-3.304a1.337 1.337 0 0 0-1.886 0 1.326 1.326 0 0 0-.39.944c0 .217.067.42.165.607zm14.787 19.184c-1.599 1.6-3.417 2.392-5.353 2.392-.349 0-.7-.03-1.058-.082a7.922 7.922 0 0 1-3.667.887c-3.049 0-6.115-1.626-8.359-3.87l-6.396-6.397A2.315 2.315 0 0 1 2 19.724a2.327 2.327 0 0 1 1.923-2.296l-.875-.875a2.339 2.339 0 0 1 0-3.3 2.33 2.33 0 0 1 1.24-.647l-.139-.139c-.91-.91-.91-2.39 0-3.3.884-.884 2.421-.882 3.301 0l.138.14a2.335 2.335 0 0 1 3.948-1.24l.093.092c.091-.423.291-.828.62-1.157a2.336 2.336 0 0 1 3.3 0l3.384 3.386a2.167 2.167 0 0 1 1.271-.173c.534.086 1.03.354 1.441.765.11-.549.415-1.034.911-1.418a2.12 2.12 0 0 1 1.661-.41c.727.117 1.385.565 1.853 1.262l3.652 6.423c1.704 2.832 2.025 7.377-2.205 11.607zM13.217.484l-1.917.882 2.37 2.837-.454-3.719zm8.487.877l-1.928-.86-.44 3.697 2.368-2.837zM16.5 3.293L15.478-.005h2.044L16.5 3.293z" fill-rule="evenodd"></path></svg></span></span><span class="button-activeState"><span class="svgIcon svgIcon--clapFilled svgIcon--33px u-relative u-topNegative2 u-xs-top0"><svg class="svgIcon-use" width="33" height="33" viewBox="0 0 33 33"><g fill-rule="evenodd"><path d="M29.58 17.1l-3.854-6.78c-.365-.543-.876-.899-1.431-.989a1.491 1.491 0 0 0-1.16.281c-.42.327-.65.736-.7 1.207v.001l3.623 6.367c2.46 4.498 1.67 8.802-2.333 12.807-.265.265-.536.505-.81.728 1.973-.222 3.474-1.286 4.45-2.263 4.166-4.165 3.875-8.6 2.215-11.36zm-4.831.82l-3.581-6.3c-.296-.439-.725-.742-1.183-.815a1.105 1.105 0 0 0-.89.213c-.647.502-.755 1.188-.33 2.098l1.825 3.858a.601.601 0 0 1-.197.747.596.596 0 0 1-.77-.067L10.178 8.21c-.508-.506-1.393-.506-1.901 0a1.335 1.335 0 0 0-.393.95c0 .36.139.698.393.95v.001l5.61 5.61a.599.599 0 1 1-.848.847l-5.606-5.606c-.001 0-.002 0-.003-.002L5.848 9.375a1.349 1.349 0 0 0-1.902 0 1.348 1.348 0 0 0 0 1.901l1.582 1.582 5.61 5.61a.6.6 0 0 1-.848.848l-5.61-5.61c-.51-.508-1.393-.508-1.9 0a1.332 1.332 0 0 0-.394.95c0 .36.139.697.393.952l2.363 2.362c.002.001.002.002.002.003l3.52 3.52a.6.6 0 0 1-.848.847l-3.522-3.523h-.001a1.336 1.336 0 0 0-.95-.393 1.345 1.345 0 0 0-.949 2.295l6.779 6.78c3.715 3.713 9.327 5.598 13.49 1.434 3.527-3.528 4.21-7.13 2.086-11.015zM11.817 7.727c.06-.328.213-.64.466-.893.64-.64 1.755-.64 2.396 0l3.232 3.232c-.82.783-1.09 1.833-.764 2.992l-5.33-5.33z"></path><path d="M13.285.48l-1.916.881 2.37 2.837z"></path><path d="M21.719 1.361L19.79.501l-.44 3.697z"></path><path d="M16.502 3.298L15.481 0h2.043z"></path></g></svg></span></span></button><div class="clapUndo u-width60 u-round u-height32 u-absolute u-borderBox u-paddingRight5 u-transition--transform200Spring u-background--brandSageLighter js-clapUndo" style="top: 14px; padding: 2px;"><button class="button button--chromeless u-baseColor--buttonNormal button--withIcon button--withSvgIcon u-floatRight" data-action="multivote-undo" data-action-value="819b65f074d8"><span class="svgIcon svgIcon--removeThin svgIcon--29px"><svg class="svgIcon-use" width="29" height="29" viewBox="0 0 29 29"><path d="M20.13 8.11l-5.61 5.61-5.609-5.61-.801.801 5.61 5.61-5.61 5.61.801.8 5.61-5.609 5.61 5.61.8-.801-5.609-5.61 5.61-5.61" fill-rule="evenodd"></path></svg></span></button></div></div><span class="u-textAlignCenter u-relative u-background js-actionMultirecommendCount u-flexOrderNegative1 u-height20 u-marginBottom7"><button class="button button--chromeless u-baseColor--buttonNormal js-multirecommendCountButton u-block u-marginAuto" data-action="show-recommends" data-action-value="819b65f074d8">2.5K</button></span></div></li><li class="u-textAlignCenter u-marginVertical10"><button class="button button--large button--dark button--chromeless is-touchIconBlackPulse u-baseColor--buttonDark button--withIcon button--withSvgIcon" title="Share on Twitter" aria-label="Share on Twitter" data-action="share-on-twitter" data-action-source="post_share_widget"><span class="svgIcon svgIcon--twitter svgIcon--29px"><svg class="svgIcon-use" width="29" height="29" viewBox="0 0 29 29"><path d="M21.967 11.8c.018 5.93-4.607 11.18-11.177 11.18-2.172 0-4.25-.62-6.047-1.76l-.268.422-.038.5.186.013.168.012c.3.02.44.032.6.046 2.06-.026 3.95-.686 5.49-1.86l1.12-.85-1.4-.048c-1.57-.055-2.92-1.08-3.36-2.51l-.48.146-.05.5c.22.03.48.05.75.08.48-.02.87-.07 1.25-.15l2.33-.49-2.32-.49c-1.68-.35-2.91-1.83-2.91-3.55 0-.05 0-.01-.01.03l-.49-.1-.25.44c.63.36 1.35.57 2.07.58l1.7.04L7.4 13c-.978-.662-1.59-1.79-1.618-3.047a4.08 4.08 0 0 1 .524-1.8l-.825.07a12.188 12.188 0 0 0 8.81 4.515l.59.033-.06-.59v-.02c-.05-.43-.06-.63-.06-.87a3.617 3.617 0 0 1 6.27-2.45l.2.21.28-.06c1.01-.22 1.94-.59 2.73-1.09l-.75-.56c-.1.36-.04.89.12 1.36.23.68.58 1.13 1.17.85l-.21-.45-.42-.27c-.52.8-1.17 1.48-1.92 2L22 11l.016.28c.013.2.014.35 0 .52v.04zm.998.038c.018-.22.017-.417 0-.66l-.498.034.284.41a8.183 8.183 0 0 0 2.2-2.267l.97-1.48-1.6.755c.17-.08.3-.02.34.03a.914.914 0 0 1-.13-.292c-.1-.297-.13-.64-.1-.766l.36-1.254-1.1.695c-.69.438-1.51.764-2.41.963l.48.15a4.574 4.574 0 0 0-3.38-1.484 4.616 4.616 0 0 0-4.61 4.613c0 .29.02.51.08.984l.01.02.5-.06.03-.5c-3.17-.18-6.1-1.7-8.08-4.15l-.48-.56-.36.64c-.39.69-.62 1.48-.65 2.28.04 1.61.81 3.04 2.06 3.88l.3-.92c-.55-.02-1.11-.17-1.6-.45l-.59-.34-.14.67c-.02.08-.02.16 0 .24-.01 2.12 1.55 4.01 3.69 4.46l.1-.49-.1-.49c-.33.07-.67.12-1.03.14-.18-.02-.43-.05-.64-.07l-.76-.09.23.73c.57 1.84 2.29 3.14 4.28 3.21l-.28-.89a8.252 8.252 0 0 1-4.85 1.66c-.12-.01-.26-.02-.56-.05l-.17-.01-.18-.01L2.53 21l1.694 1.07a12.233 12.233 0 0 0 6.58 1.917c7.156 0 12.2-5.73 12.18-12.18l-.002.04z"></path></svg></span></button></li><li class="u-textAlignCenter u-marginVertical10"><button class="button button--large button--dark button--chromeless is-touchIconBlackPulse u-baseColor--buttonDark button--withIcon button--withSvgIcon" title="Share on Facebook" aria-label="Share on Facebook" data-action="share-on-facebook" data-action-source="post_share_widget"><span class="svgIcon svgIcon--facebook svgIcon--29px"><svg class="svgIcon-use" width="29" height="29" viewBox="0 0 29 29"><path d="M16.39 23.61v-5.808h1.846a.55.55 0 0 0 .546-.48l.36-2.797a.551.551 0 0 0-.547-.62H16.39V12.67c0-.67.12-.813.828-.813h1.474a.55.55 0 0 0 .55-.55V8.803a.55.55 0 0 0-.477-.545c-.436-.06-1.36-.116-2.22-.116-2.5 0-4.13 1.62-4.13 4.248v1.513H10.56a.551.551 0 0 0-.55.55v2.797c0 .304.248.55.55.55h1.855v5.76c-4.172-.96-7.215-4.7-7.215-9.1 0-5.17 4.17-9.36 9.31-9.36 5.14 0 9.31 4.19 9.31 9.36 0 4.48-3.155 8.27-7.43 9.15M14.51 4C8.76 4 4.1 8.684 4.1 14.46c0 5.162 3.75 9.523 8.778 10.32a.55.55 0 0 0 .637-.543v-6.985a.551.551 0 0 0-.55-.55H11.11v-1.697h1.855a.55.55 0 0 0 .55-.55v-2.063c0-2.02 1.136-3.148 3.03-3.148.567 0 1.156.027 1.597.06v1.453h-.924c-1.363 0-1.93.675-1.93 1.912v1.78c0 .3.247.55.55.55h2.132l-.218 1.69H15.84c-.305 0-.55.24-.55.55v7.02c0 .33.293.59.623.54 5.135-.7 9.007-5.11 9.007-10.36C24.92 8.68 20.26 4 14.51 4"></path></svg></span></button></li><li class="u-textAlignCenter u-marginVertical10"><button class="button button--large button--dark button--chromeless is-touchIconFadeInPulse u-baseColor--buttonDark button--withIcon button--withSvgIcon button--bookmark js-bookmarkButton" title="Bookmark this story to read later" aria-label="Bookmark this story to read later" data-action="sign-up-prompt" data-sign-in-action="add-to-bookmarks" data-requires-token="true" data-redirect="https://medium.com/_/bookmark/p/819b65f074d8" data-action-source="post_share_widget-----819b65f074d8---------------------bookmark_sidebar"><span class="button-defaultState"><span class="svgIcon svgIcon--bookmark svgIcon--29px"><svg class="svgIcon-use" width="29" height="29" viewBox="0 0 29 29"><path d="M19.385 4h-9.77A2.623 2.623 0 0 0 7 6.615V23.01a1.022 1.022 0 0 0 1.595.847l5.905-4.004 5.905 4.004A1.022 1.022 0 0 0 22 23.011V6.62A2.625 2.625 0 0 0 19.385 4zM21 23l-5.91-3.955-.148-.107a.751.751 0 0 0-.884 0l-.147.107L8 23V6.615C8 5.725 8.725 5 9.615 5h9.77C20.275 5 21 5.725 21 6.615V23z" fill-rule="evenodd"></path></svg></span></span><span class="button-activeState"><span class="svgIcon svgIcon--bookmarkFilled svgIcon--29px"><svg class="svgIcon-use" width="29" height="29" viewBox="0 0 29 29"><path d="M19.385 4h-9.77A2.623 2.623 0 0 0 7 6.615V23.01a1.022 1.022 0 0 0 1.595.847l5.905-4.004 5.905 4.004A1.022 1.022 0 0 0 22 23.011V6.62A2.625 2.625 0 0 0 19.385 4z" fill-rule="evenodd"></path></svg></span></span></button></li></ul></div></aside><div class="u-fixed u-bottom0 u-sizeFullWidth u-backgroundWhite u-boxShadowTop u-borderBox u-paddingTop10 u-paddingBottom10 u-zIndexMetabar u-xs-paddingLeft10 u-xs-paddingRight10 js-stickyFooter"><div class="u-maxWidth700 u-marginAuto u-flexCenter"><div class="u-fontSize16 u-flex1 u-flexCenter"><div class="u-flex0 u-inlineBlock u-paddingRight20 u-xs-paddingRight10"><a class="link u-baseColor--link avatar avatar--roundedRectangle" href="https://blog.insightdatascience.com/" title="Go to Insight Data" aria-label="Go to Insight Data" data-collection-slug="insight-data"><img src="./Reinforcement Learning from scratch – Insight Data_files/1_bVN8Kd_RsjRN8JuKIc6U0w(1).png" class="avatar-image avatar-image--smaller" alt="Insight Data"></a></div><div class="u-flex1 u-inlineBlock"><div class="u-xs-hide">Never miss a story from<strong> Insight Data</strong>, when you sign up for Medium. <a class="link u-baseColor--link link--accent u-accentColor--textNormal u-accentColor--textDarken" href="https://medium.com/@Medium/personalize-your-medium-experience-with-users-publications-tags-26a41ab1ee0c#.hx4zuv3mg" data-action-source="sticky_footer">Learn more</a></div><div class="u-xs-show">Never miss a story from<strong> Insight Data</strong></div></div></div><div class="u-marginLeft50 u-xs-marginAuto"><button class="button button--primary button--dark is-active u-noUserSelect button--withChrome u-accentColor--buttonDark u-uiTextSemibold u-textUppercase u-fontSize12 button--followCollection js-followCollectionButton" data-action="sign-up-prompt" data-sign-in-action="toggle-subscribe-collection" data-requires-token="true" data-redirect="https://medium.com/_/subscribe/collection/insight-data" data-action-source="sticky_footer----d02e65779d7b----------------------follow_metabar"><span class="button-label  button-defaultState js-buttonLabel">Get updates</span><span class="button-label button-activeState">Get updates</span></button></div></div></div><style class="js-collectionStyle">
.u-accentColor--borderLight {border-color: #5F83E3 !important;}
.u-accentColor--borderNormal {border-color: #5F83E3 !important;}
.u-accentColor--borderDark {border-color: #5471BD !important;}
.u-accentColor--iconLight .svgIcon,.u-accentColor--iconLight.svgIcon {fill: #5F83E3 !important;}
.u-accentColor--iconNormal .svgIcon,.u-accentColor--iconNormal.svgIcon {fill: #5F83E3 !important;}
.u-accentColor--iconDark .svgIcon,.u-accentColor--iconDark.svgIcon {fill: #5471BD !important;}
.u-accentColor--textNormal {color: #5471BD !important;}
.u-accentColor--hoverTextNormal:hover {color: #5471BD !important;}
.u-accentColor--textNormal.u-accentColor--textDarken:hover {color: #4E68AA !important;}
.u-accentColor--textDark {color: #4E68AA !important;}
.u-accentColor--backgroundLight {background-color: #5F83E3 !important;}
.u-accentColor--backgroundNormal {background-color: #5F83E3 !important;}
.u-accentColor--backgroundDark {background-color: #5471BD !important;}
.u-accentColor--buttonDark {border-color: #5471BD !important; color: #4E68AA !important;}
.u-accentColor--buttonDark:hover {border-color: #4E68AA !important;}
.u-accentColor--buttonDark .icon:before,.u-accentColor--buttonDark .svgIcon{color: #5471BD !important; fill: #5471BD !important;}
.u-accentColor--buttonNormal:not(.clapButton--largePill) {border-color: #5F83E3 !important; color: #5471BD !important;}
.u-accentColor--buttonNormal:hover {border-color: #5471BD !important;}
.u-accentColor--buttonNormal .icon:before,.u-accentColor--buttonNormal .svgIcon{color: #5F83E3 !important; fill: #5F83E3 !important;}
.u-accentColor--buttonNormal.button--filled .icon:before,.u-accentColor--buttonNormal.button--filled .svgIcon{color: rgba(255, 255, 255, 1) !important; fill: rgba(255, 255, 255, 1) !important;}
.u-accentColor--buttonDark.button--filled,.u-accentColor--buttonDark.button--withChrome.is-active,.u-accentColor--fillWhenActive.is-active {background-color: #5471BD !important; border-color: #5471BD !important; color: rgba(255, 255, 255, 1) !important; fill: rgba(255, 255, 255, 1) !important;}
.u-accentColor--buttonNormal.button--filled:not(.clapButton--largePill),.u-accentColor--buttonNormal.button--withChrome.is-active:not(.clapButton--largePill) {background-color: #5F83E3 !important; border-color: #5F83E3 !important; color: rgba(255, 255, 255, 1) !important; fill: rgba(255, 255, 255, 1) !important;}
.postArticle.is-withAccentColors .markup--user,.postArticle.is-withAccentColors .markup--query {color: #5471BD !important;}.u-tintBgColor {background-color: rgba(87, 122, 218, 1) !important;}.u-tintBgColor .u-fadeLeft:before {background-image: linear-gradient(to right, rgba(87, 122, 218, 1) 0%, rgba(87, 122, 218, 0) 100%) !important;}.u-tintBgColor .u-fadeRight:after {background-image: linear-gradient(to right, rgba(87, 122, 218, 0) 0%, rgba(87, 122, 218, 1) 100%) !important;}
.u-tintSpectrum .u-baseColor--borderLight {border-color: #ACC1F8 !important;}
.u-tintSpectrum .u-baseColor--borderNormal {border-color: #CBDBFF !important;}
.u-tintSpectrum .u-baseColor--borderDark {border-color: #EAF3FF !important;}
.u-tintSpectrum .u-baseColor--iconLight .svgIcon,.u-tintSpectrum .u-baseColor--iconLight.svgIcon {fill: #ACC1F8 !important;}
.u-tintSpectrum .u-baseColor--iconNormal .svgIcon,.u-tintSpectrum .u-baseColor--iconNormal.svgIcon {fill: #CBDBFF !important;}
.u-tintSpectrum .u-baseColor--iconDark .svgIcon,.u-tintSpectrum .u-baseColor--iconDark.svgIcon {fill: #EAF3FF !important;}
.u-tintSpectrum .u-baseColor--textNormal {color: #CBDBFF !important;}
.u-tintSpectrum .u-baseColor--textNormal.u-baseColor--textDarken:hover {color: #F9FFFF !important;}
.u-tintSpectrum .u-baseColor--textDark {color: #F9FFFF !important;}
.u-tintSpectrum .u-baseColor--textDarker {color: #F9FFFF !important;}
.u-tintSpectrum .u-baseColor--backgroundLight {background-color: #ACC1F8 !important;}
.u-tintSpectrum .u-baseColor--backgroundNormal {background-color: #CBDBFF !important;}
.u-tintSpectrum .u-baseColor--backgroundDark {background-color: #EAF3FF !important;}
.u-tintSpectrum .u-baseColor--buttonLight {border-color: #ACC1F8 !important; color: #ACC1F8 !important;}
.u-tintSpectrum .u-baseColor--buttonLight:hover {border-color: #ACC1F8 !important;}
.u-tintSpectrum .u-baseColor--buttonLight .icon:before,.u-tintSpectrum .u-baseColor--buttonLight .svgIcon {color: #ACC1F8 !important; fill: #ACC1F8 !important;}
.u-tintSpectrum .u-baseColor--buttonDark {border-color: #EAF3FF !important; color: #F9FFFF !important;}
.u-tintSpectrum .u-baseColor--buttonDark:hover {border-color: #F9FFFF !important;}
.u-tintSpectrum .u-baseColor--buttonDark .icon:before,.u-tintSpectrum .u-baseColor--buttonDark .svgIcon {color: #EAF3FF !important; fill: #EAF3FF !important;}
.u-tintSpectrum .u-baseColor--buttonNormal {border-color: #CBDBFF !important; color: #CBDBFF !important;}
.u-tintSpectrum .u-baseColor--buttonNormal:hover {border-color: #EAF3FF !important;}
.u-tintSpectrum .u-baseColor--buttonNormal .icon:before,.u-tintSpectrum .u-baseColor--buttonNormal .svgIcon {color: #CBDBFF !important; fill: #CBDBFF !important;}
.u-tintSpectrum .u-baseColor--buttonDark.button--filled,.u-tintSpectrum .u-baseColor--buttonDark.button--withChrome.is-active {background-color: #EAF3FF !important; border-color: #EAF3FF !important; color: rgba(87, 122, 218, 1) !important; fill: rgba(87, 122, 218, 1) !important;}
.u-tintSpectrum .u-baseColor--buttonNormal.button--filled,.u-tintSpectrum .u-baseColor--buttonNormal.button--withChrome.is-active {background-color: #CBDBFF !important; border-color: #CBDBFF !important; color: rgba(87, 122, 218, 1) !important; fill: rgba(87, 122, 218, 1) !important;}
.u-tintSpectrum .u-baseColor--link {color: #CBDBFF !important;}
.u-tintSpectrum .u-baseColor--link.link--darkenOnHover:hover {color: #F9FFFF !important;}
.u-tintSpectrum .u-baseColor--link.link--darken:hover,.u-tintSpectrum .u-baseColor--link.link--darken:focus,.u-tintSpectrum .u-baseColor--link.link--darken:active {color: #F9FFFF !important;}
.u-tintSpectrum .u-baseColor--link.link--dark {color: #F9FFFF !important;}
.u-tintSpectrum .u-baseColor--link.link--dark.link--darken:hover,.u-tintSpectrum .u-baseColor--link.link--dark.link--darken:focus,.u-tintSpectrum .u-baseColor--link.link--dark.link--darken:active {color: #F9FFFF !important;}
.u-tintSpectrum .u-baseColor--link.link--darker {color: #F9FFFF !important;}
.u-tintSpectrum .u-baseColor--placeholderNormal ::-webkit-input-placeholder {color: #ACC1F8;}
.u-tintSpectrum .u-baseColor--placeholderNormal ::-moz-placeholder {color: #ACC1F8;}
.u-tintSpectrum .u-baseColor--placeholderNormal :-ms-input-placeholder {color: #ACC1F8;}
.u-tintSpectrum .svgIcon--logoNew path:nth-child(1) {stroke: none !important; fill: #7A98E7 !important;}
.u-tintSpectrum .svgIcon--logoNew path:nth-child(2) {stroke: none !important; fill: #8BA6ED !important;}
.u-tintSpectrum .svgIcon--logoNew path:nth-child(3) {stroke: none !important; fill: #ACC1F8 !important;}
.u-tintSpectrum .svgIcon--logoNew path:nth-child(4) {stroke: none !important; fill: #CBDBFF !important;}
.u-tintSpectrum .svgIcon--logoWordmark {stroke: none !important; fill: #F9FFFF !important;}
.u-tintSpectrum .svgIcon--logoMonogram {stroke: none !important; fill: #F9FFFF !important;}
.u-tintSpectrum  .ui-h1,.u-tintSpectrum  .ui-h2,.u-tintSpectrum  .ui-h3,.u-tintSpectrum  .ui-h4,.u-tintSpectrum  .ui-brand1,.u-tintSpectrum  .ui-brand2,.u-tintSpectrum  .ui-captionStrong {color: #F9FFFF !important; fill: #F9FFFF !important;}
.u-tintSpectrum  .ui-body,.u-tintSpectrum  .ui-caps {color: #F9FFFF !important; fill: #F9FFFF !important;}
.u-tintSpectrum  .ui-summary,.u-tintSpectrum  .ui-caption {color: #ACC1F8 !important; fill: #ACC1F8 !important;}
.u-tintSpectrum .u-accentColor--borderLight {border-color: #ACC1F8 !important;}
.u-tintSpectrum .u-accentColor--borderNormal {border-color: #CBDBFF !important;}
.u-tintSpectrum .u-accentColor--borderDark {border-color: #EAF3FF !important;}
.u-tintSpectrum .u-accentColor--iconLight .svgIcon,.u-tintSpectrum .u-accentColor--iconLight.svgIcon {fill: #ACC1F8 !important;}
.u-tintSpectrum .u-accentColor--iconNormal .svgIcon,.u-tintSpectrum .u-accentColor--iconNormal.svgIcon {fill: #CBDBFF !important;}
.u-tintSpectrum .u-accentColor--iconDark .svgIcon,.u-tintSpectrum .u-accentColor--iconDark.svgIcon {fill: #EAF3FF !important;}
.u-tintSpectrum .u-accentColor--textNormal {color: #CBDBFF !important;}
.u-tintSpectrum .u-accentColor--hoverTextNormal:hover {color: #CBDBFF !important;}
.u-tintSpectrum .u-accentColor--textNormal.u-accentColor--textDarken:hover {color: #F9FFFF !important;}
.u-tintSpectrum .u-accentColor--textDark {color: #F9FFFF !important;}
.u-tintSpectrum .u-accentColor--backgroundLight {background-color: #ACC1F8 !important;}
.u-tintSpectrum .u-accentColor--backgroundNormal {background-color: #CBDBFF !important;}
.u-tintSpectrum .u-accentColor--backgroundDark {background-color: #EAF3FF !important;}
.u-tintSpectrum .u-accentColor--buttonDark {border-color: #EAF3FF !important; color: #F9FFFF !important;}
.u-tintSpectrum .u-accentColor--buttonDark:hover {border-color: #F9FFFF !important;}
.u-tintSpectrum .u-accentColor--buttonDark .icon:before,.u-tintSpectrum .u-accentColor--buttonDark .svgIcon{color: #EAF3FF !important; fill: #EAF3FF !important;}
.u-tintSpectrum .u-accentColor--buttonNormal:not(.clapButton--largePill) {border-color: #CBDBFF !important; color: #CBDBFF !important;}
.u-tintSpectrum .u-accentColor--buttonNormal:hover {border-color: #EAF3FF !important;}
.u-tintSpectrum .u-accentColor--buttonNormal .icon:before,.u-tintSpectrum .u-accentColor--buttonNormal .svgIcon{color: #CBDBFF !important; fill: #CBDBFF !important;}
.u-tintSpectrum .u-accentColor--buttonNormal.button--filled .icon:before,.u-tintSpectrum .u-accentColor--buttonNormal.button--filled .svgIcon{color: rgba(87, 122, 218, 1) !important; fill: rgba(87, 122, 218, 1) !important;}
.u-tintSpectrum .u-accentColor--buttonDark.button--filled,.u-tintSpectrum .u-accentColor--buttonDark.button--withChrome.is-active,.u-tintSpectrum .u-accentColor--fillWhenActive.is-active {background-color: #EAF3FF !important; border-color: #EAF3FF !important; color: rgba(87, 122, 218, 1) !important; fill: rgba(87, 122, 218, 1) !important;}
.u-tintSpectrum .u-accentColor--buttonNormal.button--filled:not(.clapButton--largePill),.u-tintSpectrum .u-accentColor--buttonNormal.button--withChrome.is-active:not(.clapButton--largePill) {background-color: #CBDBFF !important; border-color: #CBDBFF !important; color: rgba(87, 122, 218, 1) !important; fill: rgba(87, 122, 218, 1) !important;}
.u-tintSpectrum .postArticle.is-withAccentColors .markup--user,.u-tintSpectrum .postArticle.is-withAccentColors .markup--query {color: #CBDBFF !important;}
.u-accentColor--highlightFaint {background-color: rgba(231, 241, 255, 1) !important;}
.u-accentColor--highlightStrong.is-active .svgIcon {fill: rgba(194, 224, 255, 1) !important;}
.postArticle.is-withAccentColors .markup--quote.is-other {background-color: rgba(231, 241, 255, 1) !important;}
body.is-withMagicUnderlines .postArticle.is-withAccentColors .markup--quote.is-other {background-color: transparent !important; background-image: linear-gradient(to bottom, rgba(231, 241, 255, 1), rgba(231, 241, 255, 1));}
.postArticle.is-withAccentColors .markup--quote.is-me {background-color: rgba(211, 232, 255, 1) !important;}
body.is-withMagicUnderlines .postArticle.is-withAccentColors .markup--quote.is-me {background-color: transparent !important; background-image: linear-gradient(to bottom, rgba(211, 232, 255, 1), rgba(211, 232, 255, 1));}
.postArticle.is-withAccentColors .markup--quote.is-targeted {background-color: rgba(194, 224, 255, 1) !important;}
body.is-withMagicUnderlines .postArticle.is-withAccentColors .markup--quote.is-targeted {background-color: transparent !important; background-image: linear-gradient(to bottom, rgba(194, 224, 255, 1), rgba(194, 224, 255, 1));}
.postArticle.is-withAccentColors .markup--quote.is-selected {background-color: rgba(194, 224, 255, 1) !important;}
body.is-withMagicUnderlines .postArticle.is-withAccentColors .markup--quote.is-selected {background-color: transparent !important; background-image: linear-gradient(to bottom, rgba(194, 224, 255, 1), rgba(194, 224, 255, 1));}
.postArticle.is-withAccentColors .markup--highlight {background-color: rgba(194, 224, 255, 1) !important;}
body.is-withMagicUnderlines .postArticle.is-withAccentColors .markup--highlight {background-color: transparent !important; background-image: linear-gradient(to bottom, rgba(194, 224, 255, 1), rgba(194, 224, 255, 1));}.u-baseColor--iconNormal.avatar-halo {fill: rgba(0, 0, 0, 0.4980392156862745) !important;}</style><style class="js-collectionStyleConstant">.u-imageBgColor {background-color: rgba(0, 0, 0, 0.24705882352941178);}
.u-imageSpectrum .u-baseColor--borderLight {border-color: rgba(255, 255, 255, 0.6980392156862745) !important;}
.u-imageSpectrum .u-baseColor--borderNormal {border-color: rgba(255, 255, 255, 0.8980392156862745) !important;}
.u-imageSpectrum .u-baseColor--borderDark {border-color: rgba(255, 255, 255, 0.9490196078431372) !important;}
.u-imageSpectrum .u-baseColor--iconLight .svgIcon,.u-imageSpectrum .u-baseColor--iconLight.svgIcon {fill: rgba(255, 255, 255, 0.8) !important;}
.u-imageSpectrum .u-baseColor--iconNormal .svgIcon,.u-imageSpectrum .u-baseColor--iconNormal.svgIcon {fill: rgba(255, 255, 255, 0.9490196078431372) !important;}
.u-imageSpectrum .u-baseColor--iconDark .svgIcon,.u-imageSpectrum .u-baseColor--iconDark.svgIcon {fill: rgba(255, 255, 255, 1) !important;}
.u-imageSpectrum .u-baseColor--textNormal {color: rgba(255, 255, 255, 0.9490196078431372) !important;}
.u-imageSpectrum .u-baseColor--textNormal.u-baseColor--textDarken:hover {color: rgba(255, 255, 255, 1) !important;}
.u-imageSpectrum .u-baseColor--textDark {color: rgba(255, 255, 255, 1) !important;}
.u-imageSpectrum .u-baseColor--textDarker {color: rgba(255, 255, 255, 1) !important;}
.u-imageSpectrum .u-baseColor--backgroundLight {background-color: rgba(255, 255, 255, 0.8980392156862745) !important;}
.u-imageSpectrum .u-baseColor--backgroundNormal {background-color: rgba(255, 255, 255, 0.9490196078431372) !important;}
.u-imageSpectrum .u-baseColor--backgroundDark {background-color: rgba(255, 255, 255, 1) !important;}
.u-imageSpectrum .u-baseColor--buttonLight {border-color: rgba(255, 255, 255, 0.6980392156862745) !important; color: rgba(255, 255, 255, 0.8) !important;}
.u-imageSpectrum .u-baseColor--buttonLight:hover {border-color: rgba(255, 255, 255, 0.6980392156862745) !important;}
.u-imageSpectrum .u-baseColor--buttonLight .icon:before,.u-imageSpectrum .u-baseColor--buttonLight .svgIcon {color: rgba(255, 255, 255, 0.8) !important; fill: rgba(255, 255, 255, 0.8) !important;}
.u-imageSpectrum .u-baseColor--buttonDark {border-color: rgba(255, 255, 255, 0.9490196078431372) !important; color: rgba(255, 255, 255, 1) !important;}
.u-imageSpectrum .u-baseColor--buttonDark:hover {border-color: rgba(255, 255, 255, 1) !important;}
.u-imageSpectrum .u-baseColor--buttonDark .icon:before,.u-imageSpectrum .u-baseColor--buttonDark .svgIcon {color: rgba(255, 255, 255, 1) !important; fill: rgba(255, 255, 255, 1) !important;}
.u-imageSpectrum .u-baseColor--buttonNormal {border-color: rgba(255, 255, 255, 0.8980392156862745) !important; color: rgba(255, 255, 255, 0.9490196078431372) !important;}
.u-imageSpectrum .u-baseColor--buttonNormal:hover {border-color: rgba(255, 255, 255, 0.9490196078431372) !important;}
.u-imageSpectrum .u-baseColor--buttonNormal .icon:before,.u-imageSpectrum .u-baseColor--buttonNormal .svgIcon {color: rgba(255, 255, 255, 0.9490196078431372) !important; fill: rgba(255, 255, 255, 0.9490196078431372) !important;}
.u-imageSpectrum .u-baseColor--buttonDark.button--filled,.u-imageSpectrum .u-baseColor--buttonDark.button--withChrome.is-active {background-color: rgba(255, 255, 255, 1) !important; border-color: rgba(255, 255, 255, 1) !important; color: rgba(0, 0, 0, 0.24705882352941178) !important; fill: rgba(0, 0, 0, 0.24705882352941178) !important;}
.u-imageSpectrum .u-baseColor--buttonNormal.button--filled,.u-imageSpectrum .u-baseColor--buttonNormal.button--withChrome.is-active {background-color: rgba(255, 255, 255, 0.9490196078431372) !important; border-color: rgba(255, 255, 255, 0.9490196078431372) !important; color: rgba(0, 0, 0, 0.24705882352941178) !important; fill: rgba(0, 0, 0, 0.24705882352941178) !important;}
.u-imageSpectrum .u-baseColor--link {color: rgba(255, 255, 255, 0.9490196078431372) !important;}
.u-imageSpectrum .u-baseColor--link.link--darkenOnHover:hover {color: rgba(255, 255, 255, 1) !important;}
.u-imageSpectrum .u-baseColor--link.link--darken:hover,.u-imageSpectrum .u-baseColor--link.link--darken:focus,.u-imageSpectrum .u-baseColor--link.link--darken:active {color: rgba(255, 255, 255, 1) !important;}
.u-imageSpectrum .u-baseColor--link.link--dark {color: rgba(255, 255, 255, 1) !important;}
.u-imageSpectrum .u-baseColor--link.link--dark.link--darken:hover,.u-imageSpectrum .u-baseColor--link.link--dark.link--darken:focus,.u-imageSpectrum .u-baseColor--link.link--dark.link--darken:active {color: rgba(255, 255, 255, 1) !important;}
.u-imageSpectrum .u-baseColor--link.link--darker {color: rgba(255, 255, 255, 1) !important;}
.u-imageSpectrum .u-baseColor--placeholderNormal ::-webkit-input-placeholder {color: rgba(255, 255, 255, 0.8);}
.u-imageSpectrum .u-baseColor--placeholderNormal ::-moz-placeholder {color: rgba(255, 255, 255, 0.8);}
.u-imageSpectrum .u-baseColor--placeholderNormal :-ms-input-placeholder {color: rgba(255, 255, 255, 0.8);}
.u-imageSpectrum .svgIcon--logoNew path:nth-child(1) {stroke: none !important; fill: rgba(255, 255, 255, 0.4) !important;}
.u-imageSpectrum .svgIcon--logoNew path:nth-child(2) {stroke: none !important; fill: rgba(255, 255, 255, 0.4980392156862745) !important;}
.u-imageSpectrum .svgIcon--logoNew path:nth-child(3) {stroke: none !important; fill: rgba(255, 255, 255, 0.6980392156862745) !important;}
.u-imageSpectrum .svgIcon--logoNew path:nth-child(4) {stroke: none !important; fill: rgba(255, 255, 255, 0.8980392156862745) !important;}
.u-imageSpectrum .svgIcon--logoWordmark {stroke: none !important; fill: rgba(255, 255, 255, 1) !important;}
.u-imageSpectrum .svgIcon--logoMonogram {stroke: none !important; fill: rgba(255, 255, 255, 1) !important;}
.u-imageSpectrum  .ui-h1,.u-imageSpectrum  .ui-h2,.u-imageSpectrum  .ui-h3,.u-imageSpectrum  .ui-h4,.u-imageSpectrum  .ui-brand1,.u-imageSpectrum  .ui-brand2,.u-imageSpectrum  .ui-captionStrong {color: rgba(255, 255, 255, 1) !important; fill: rgba(255, 255, 255, 1) !important;}
.u-imageSpectrum  .ui-body,.u-imageSpectrum  .ui-caps {color: rgba(255, 255, 255, 1) !important; fill: rgba(255, 255, 255, 1) !important;}
.u-imageSpectrum  .ui-summary,.u-imageSpectrum  .ui-caption {color: rgba(255, 255, 255, 0.8) !important; fill: rgba(255, 255, 255, 0.8) !important;}
.u-imageSpectrum .u-accentColor--borderLight {border-color: rgba(255, 255, 255, 0.6980392156862745) !important;}
.u-imageSpectrum .u-accentColor--borderNormal {border-color: rgba(255, 255, 255, 0.8980392156862745) !important;}
.u-imageSpectrum .u-accentColor--borderDark {border-color: rgba(255, 255, 255, 0.9490196078431372) !important;}
.u-imageSpectrum .u-accentColor--iconLight .svgIcon,.u-imageSpectrum .u-accentColor--iconLight.svgIcon {fill: rgba(255, 255, 255, 0.8) !important;}
.u-imageSpectrum .u-accentColor--iconNormal .svgIcon,.u-imageSpectrum .u-accentColor--iconNormal.svgIcon {fill: rgba(255, 255, 255, 0.9490196078431372) !important;}
.u-imageSpectrum .u-accentColor--iconDark .svgIcon,.u-imageSpectrum .u-accentColor--iconDark.svgIcon {fill: rgba(255, 255, 255, 1) !important;}
.u-imageSpectrum .u-accentColor--textNormal {color: rgba(255, 255, 255, 0.9490196078431372) !important;}
.u-imageSpectrum .u-accentColor--hoverTextNormal:hover {color: rgba(255, 255, 255, 0.9490196078431372) !important;}
.u-imageSpectrum .u-accentColor--textNormal.u-accentColor--textDarken:hover {color: rgba(255, 255, 255, 1) !important;}
.u-imageSpectrum .u-accentColor--textDark {color: rgba(255, 255, 255, 1) !important;}
.u-imageSpectrum .u-accentColor--backgroundLight {background-color: rgba(255, 255, 255, 0.8980392156862745) !important;}
.u-imageSpectrum .u-accentColor--backgroundNormal {background-color: rgba(255, 255, 255, 0.9490196078431372) !important;}
.u-imageSpectrum .u-accentColor--backgroundDark {background-color: rgba(255, 255, 255, 1) !important;}
.u-imageSpectrum .u-accentColor--buttonDark {border-color: rgba(255, 255, 255, 0.9490196078431372) !important; color: rgba(255, 255, 255, 1) !important;}
.u-imageSpectrum .u-accentColor--buttonDark:hover {border-color: rgba(255, 255, 255, 1) !important;}
.u-imageSpectrum .u-accentColor--buttonDark .icon:before,.u-imageSpectrum .u-accentColor--buttonDark .svgIcon{color: rgba(255, 255, 255, 1) !important; fill: rgba(255, 255, 255, 1) !important;}
.u-imageSpectrum .u-accentColor--buttonNormal:not(.clapButton--largePill) {border-color: rgba(255, 255, 255, 0.8980392156862745) !important; color: rgba(255, 255, 255, 0.9490196078431372) !important;}
.u-imageSpectrum .u-accentColor--buttonNormal:hover {border-color: rgba(255, 255, 255, 0.9490196078431372) !important;}
.u-imageSpectrum .u-accentColor--buttonNormal .icon:before,.u-imageSpectrum .u-accentColor--buttonNormal .svgIcon{color: rgba(255, 255, 255, 0.9490196078431372) !important; fill: rgba(255, 255, 255, 0.9490196078431372) !important;}
.u-imageSpectrum .u-accentColor--buttonNormal.button--filled .icon:before,.u-imageSpectrum .u-accentColor--buttonNormal.button--filled .svgIcon{color: rgba(0, 0, 0, 0.24705882352941178) !important; fill: rgba(0, 0, 0, 0.24705882352941178) !important;}
.u-imageSpectrum .u-accentColor--buttonDark.button--filled,.u-imageSpectrum .u-accentColor--buttonDark.button--withChrome.is-active,.u-imageSpectrum .u-accentColor--fillWhenActive.is-active {background-color: rgba(255, 255, 255, 1) !important; border-color: rgba(255, 255, 255, 1) !important; color: rgba(0, 0, 0, 0.24705882352941178) !important; fill: rgba(0, 0, 0, 0.24705882352941178) !important;}
.u-imageSpectrum .u-accentColor--buttonNormal.button--filled:not(.clapButton--largePill),.u-imageSpectrum .u-accentColor--buttonNormal.button--withChrome.is-active:not(.clapButton--largePill) {background-color: rgba(255, 255, 255, 0.9490196078431372) !important; border-color: rgba(255, 255, 255, 0.9490196078431372) !important; color: rgba(0, 0, 0, 0.24705882352941178) !important; fill: rgba(0, 0, 0, 0.24705882352941178) !important;}
.u-imageSpectrum .postArticle.is-withAccentColors .markup--user,.u-imageSpectrum .postArticle.is-withAccentColors .markup--query {color: rgba(255, 255, 255, 0.9490196078431372) !important;}
.u-imageSpectrum .u-accentColor--highlightFaint {background-color: rgba(255, 255, 255, 0.2) !important;}
.u-imageSpectrum .u-accentColor--highlightStrong.is-active .svgIcon {fill: rgba(255, 255, 255, 0.6) !important;}
.postArticle.is-withAccentColors .u-imageSpectrum .markup--quote.is-other {background-color: rgba(255, 255, 255, 0.2) !important;}
body.is-withMagicUnderlines .postArticle.is-withAccentColors .u-imageSpectrum .markup--quote.is-other {background-color: transparent !important; background-image: linear-gradient(to bottom, rgba(255, 255, 255, 0.2), rgba(255, 255, 255, 0.2));}
.postArticle.is-withAccentColors .u-imageSpectrum .markup--quote.is-me {background-color: rgba(255, 255, 255, 0.4) !important;}
body.is-withMagicUnderlines .postArticle.is-withAccentColors .u-imageSpectrum .markup--quote.is-me {background-color: transparent !important; background-image: linear-gradient(to bottom, rgba(255, 255, 255, 0.4), rgba(255, 255, 255, 0.4));}
.postArticle.is-withAccentColors .u-imageSpectrum .markup--quote.is-targeted {background-color: rgba(255, 255, 255, 0.6) !important;}
body.is-withMagicUnderlines .postArticle.is-withAccentColors .u-imageSpectrum .markup--quote.is-targeted {background-color: transparent !important; background-image: linear-gradient(to bottom, rgba(255, 255, 255, 0.6), rgba(255, 255, 255, 0.6));}
.postArticle.is-withAccentColors .u-imageSpectrum .markup--quote.is-selected {background-color: rgba(255, 255, 255, 0.6) !important;}
body.is-withMagicUnderlines .postArticle.is-withAccentColors .u-imageSpectrum .markup--quote.is-selected {background-color: transparent !important; background-image: linear-gradient(to bottom, rgba(255, 255, 255, 0.6), rgba(255, 255, 255, 0.6));}
.postArticle.is-withAccentColors .u-imageSpectrum .markup--highlight {background-color: rgba(255, 255, 255, 0.6) !important;}
body.is-withMagicUnderlines .postArticle.is-withAccentColors .u-imageSpectrum .markup--highlight {background-color: transparent !important; background-image: linear-gradient(to bottom, rgba(255, 255, 255, 0.6), rgba(255, 255, 255, 0.6));}.u-resetSpectrum .u-tintBgColor {background-color: rgba(255, 255, 255, 1) !important;}.u-resetSpectrum .u-tintBgColor .u-fadeLeft:before {background-image: linear-gradient(to right, rgba(255, 255, 255, 1) 0%, rgba(255, 255, 255, 0) 100%) !important;}.u-resetSpectrum .u-tintBgColor .u-fadeRight:after {background-image: linear-gradient(to right, rgba(255, 255, 255, 0) 0%, rgba(255, 255, 255, 1) 100%) !important;}
.u-resetSpectrum .u-baseColor--borderLight {border-color: rgba(0, 0, 0, 0.2980392156862745) !important;}
.u-resetSpectrum .u-baseColor--borderNormal {border-color: rgba(0, 0, 0, 0.4980392156862745) !important;}
.u-resetSpectrum .u-baseColor--borderDark {border-color: rgba(0, 0, 0, 0.6) !important;}
.u-resetSpectrum .u-baseColor--iconLight .svgIcon,.u-resetSpectrum .u-baseColor--iconLight.svgIcon {fill: rgba(0, 0, 0, 0.2980392156862745) !important;}
.u-resetSpectrum .u-baseColor--iconNormal .svgIcon,.u-resetSpectrum .u-baseColor--iconNormal.svgIcon {fill: rgba(0, 0, 0, 0.4980392156862745) !important;}
.u-resetSpectrum .u-baseColor--iconDark .svgIcon,.u-resetSpectrum .u-baseColor--iconDark.svgIcon {fill: rgba(0, 0, 0, 0.6) !important;}
.u-resetSpectrum .u-baseColor--textNormal {color: rgba(0, 0, 0, 0.4980392156862745) !important;}
.u-resetSpectrum .u-baseColor--textNormal.u-baseColor--textDarken:hover {color: rgba(0, 0, 0, 0.6) !important;}
.u-resetSpectrum .u-baseColor--textDark {color: rgba(0, 0, 0, 0.6) !important;}
.u-resetSpectrum .u-baseColor--textDarker {color: rgba(0, 0, 0, 0.8) !important;}
.u-resetSpectrum .u-baseColor--backgroundLight {background-color: rgba(0, 0, 0, 0.09803921568627451) !important;}
.u-resetSpectrum .u-baseColor--backgroundNormal {background-color: rgba(0, 0, 0, 0.2) !important;}
.u-resetSpectrum .u-baseColor--backgroundDark {background-color: rgba(0, 0, 0, 0.2980392156862745) !important;}
.u-resetSpectrum .u-baseColor--buttonLight {border-color: rgba(0, 0, 0, 0.2980392156862745) !important; color: rgba(0, 0, 0, 0.2980392156862745) !important;}
.u-resetSpectrum .u-baseColor--buttonLight:hover {border-color: rgba(0, 0, 0, 0.2980392156862745) !important;}
.u-resetSpectrum .u-baseColor--buttonLight .icon:before,.u-resetSpectrum .u-baseColor--buttonLight .svgIcon {color: rgba(0, 0, 0, 0.2980392156862745) !important; fill: rgba(0, 0, 0, 0.2980392156862745) !important;}
.u-resetSpectrum .u-baseColor--buttonDark {border-color: rgba(0, 0, 0, 0.6) !important; color: rgba(0, 0, 0, 0.6) !important;}
.u-resetSpectrum .u-baseColor--buttonDark:hover {border-color: rgba(0, 0, 0, 0.8) !important;}
.u-resetSpectrum .u-baseColor--buttonDark .icon:before,.u-resetSpectrum .u-baseColor--buttonDark .svgIcon {color: rgba(0, 0, 0, 0.6) !important; fill: rgba(0, 0, 0, 0.6) !important;}
.u-resetSpectrum .u-baseColor--buttonNormal {border-color: rgba(0, 0, 0, 0.4980392156862745) !important; color: rgba(0, 0, 0, 0.4980392156862745) !important;}
.u-resetSpectrum .u-baseColor--buttonNormal:hover {border-color: rgba(0, 0, 0, 0.6) !important;}
.u-resetSpectrum .u-baseColor--buttonNormal .icon:before,.u-resetSpectrum .u-baseColor--buttonNormal .svgIcon {color: rgba(0, 0, 0, 0.4980392156862745) !important; fill: rgba(0, 0, 0, 0.4980392156862745) !important;}
.u-resetSpectrum .u-baseColor--buttonDark.button--filled,.u-resetSpectrum .u-baseColor--buttonDark.button--withChrome.is-active {background-color: rgba(0, 0, 0, 0.2980392156862745) !important; border-color: rgba(0, 0, 0, 0.2980392156862745) !important; color: rgba(255, 255, 255, 1) !important; fill: rgba(255, 255, 255, 1) !important;}
.u-resetSpectrum .u-baseColor--buttonNormal.button--filled,.u-resetSpectrum .u-baseColor--buttonNormal.button--withChrome.is-active {background-color: rgba(0, 0, 0, 0.2) !important; border-color: rgba(0, 0, 0, 0.2) !important; color: rgba(255, 255, 255, 1) !important; fill: rgba(255, 255, 255, 1) !important;}
.u-resetSpectrum .u-baseColor--link {color: rgba(0, 0, 0, 0.4980392156862745) !important;}
.u-resetSpectrum .u-baseColor--link.link--darkenOnHover:hover {color: rgba(0, 0, 0, 0.6) !important;}
.u-resetSpectrum .u-baseColor--link.link--darken:hover,.u-resetSpectrum .u-baseColor--link.link--darken:focus,.u-resetSpectrum .u-baseColor--link.link--darken:active {color: rgba(0, 0, 0, 0.6) !important;}
.u-resetSpectrum .u-baseColor--link.link--dark {color: rgba(0, 0, 0, 0.6) !important;}
.u-resetSpectrum .u-baseColor--link.link--dark.link--darken:hover,.u-resetSpectrum .u-baseColor--link.link--dark.link--darken:focus,.u-resetSpectrum .u-baseColor--link.link--dark.link--darken:active {color: rgba(0, 0, 0, 0.8) !important;}
.u-resetSpectrum .u-baseColor--link.link--darker {color: rgba(0, 0, 0, 0.8) !important;}
.u-resetSpectrum .u-baseColor--placeholderNormal ::-webkit-input-placeholder {color: rgba(0, 0, 0, 0.2980392156862745);}
.u-resetSpectrum .u-baseColor--placeholderNormal ::-moz-placeholder {color: rgba(0, 0, 0, 0.2980392156862745);}
.u-resetSpectrum .u-baseColor--placeholderNormal :-ms-input-placeholder {color: rgba(0, 0, 0, 0.2980392156862745);}
.u-resetSpectrum .svgIcon--logoNew path:nth-child(1) {stroke: none !important; fill: rgba(0, 0, 0, 0.2) !important;}
.u-resetSpectrum .svgIcon--logoNew path:nth-child(2) {stroke: none !important; fill: rgba(0, 0, 0, 0.2980392156862745) !important;}
.u-resetSpectrum .svgIcon--logoNew path:nth-child(3) {stroke: none !important; fill: rgba(0, 0, 0, 0.4) !important;}
.u-resetSpectrum .svgIcon--logoNew path:nth-child(4) {stroke: none !important; fill: rgba(0, 0, 0, 0.4980392156862745) !important;}
.u-resetSpectrum .svgIcon--logoWordmark {stroke: none !important; fill: rgba(0, 0, 0, 0.6) !important;}
.u-resetSpectrum .svgIcon--logoMonogram {stroke: none !important; fill: rgba(0, 0, 0, 0.6) !important;}
.u-resetSpectrum  .ui-h1,.u-resetSpectrum  .ui-h2,.u-resetSpectrum  .ui-h3,.u-resetSpectrum  .ui-h4,.u-resetSpectrum  .ui-brand1,.u-resetSpectrum  .ui-brand2,.u-resetSpectrum  .ui-captionStrong {color: rgba(0, 0, 0, 0.8) !important; fill: rgba(0, 0, 0, 0.8) !important;}
.u-resetSpectrum  .ui-body,.u-resetSpectrum  .ui-caps {color: rgba(0, 0, 0, 0.6) !important; fill: rgba(0, 0, 0, 0.6) !important;}
.u-resetSpectrum  .ui-summary,.u-resetSpectrum  .ui-caption {color: rgba(0, 0, 0, 0.2980392156862745) !important; fill: rgba(0, 0, 0, 0.2980392156862745) !important;}
.u-resetSpectrum .u-accentColor--borderLight {border-color: rgba(2, 184, 117, 1) !important;}
.u-resetSpectrum .u-accentColor--borderNormal {border-color: rgba(2, 184, 117, 1) !important;}
.u-resetSpectrum .u-accentColor--borderDark {border-color: rgba(0, 171, 107, 1) !important;}
.u-resetSpectrum .u-accentColor--iconLight .svgIcon,.u-resetSpectrum .u-accentColor--iconLight.svgIcon {fill: rgba(2, 184, 117, 1) !important;}
.u-resetSpectrum .u-accentColor--iconNormal .svgIcon,.u-resetSpectrum .u-accentColor--iconNormal.svgIcon {fill: rgba(0, 171, 107, 1) !important;}
.u-resetSpectrum .u-accentColor--iconDark .svgIcon,.u-resetSpectrum .u-accentColor--iconDark.svgIcon {fill: rgba(28, 153, 99, 1) !important;}
.u-resetSpectrum .u-accentColor--textNormal {color: rgba(0, 171, 107, 1) !important;}
.u-resetSpectrum .u-accentColor--hoverTextNormal:hover {color: rgba(0, 171, 107, 1) !important;}
.u-resetSpectrum .u-accentColor--textNormal.u-accentColor--textDarken:hover {color: rgba(28, 153, 99, 1) !important;}
.u-resetSpectrum .u-accentColor--textDark {color: rgba(28, 153, 99, 1) !important;}
.u-resetSpectrum .u-accentColor--backgroundLight {background-color: rgba(2, 184, 117, 1) !important;}
.u-resetSpectrum .u-accentColor--backgroundNormal {background-color: rgba(0, 171, 107, 1) !important;}
.u-resetSpectrum .u-accentColor--backgroundDark {background-color: rgba(28, 153, 99, 1) !important;}
.u-resetSpectrum .u-accentColor--buttonDark {border-color: rgba(0, 171, 107, 1) !important; color: rgba(28, 153, 99, 1) !important;}
.u-resetSpectrum .u-accentColor--buttonDark:hover {border-color: rgba(28, 153, 99, 1) !important;}
.u-resetSpectrum .u-accentColor--buttonDark .icon:before,.u-resetSpectrum .u-accentColor--buttonDark .svgIcon{color: rgba(28, 153, 99, 1) !important; fill: rgba(28, 153, 99, 1) !important;}
.u-resetSpectrum .u-accentColor--buttonNormal:not(.clapButton--largePill) {border-color: rgba(2, 184, 117, 1) !important; color: rgba(0, 171, 107, 1) !important;}
.u-resetSpectrum .u-accentColor--buttonNormal:hover {border-color: rgba(0, 171, 107, 1) !important;}
.u-resetSpectrum .u-accentColor--buttonNormal .icon:before,.u-resetSpectrum .u-accentColor--buttonNormal .svgIcon{color: rgba(0, 171, 107, 1) !important; fill: rgba(0, 171, 107, 1) !important;}
.u-resetSpectrum .u-accentColor--buttonNormal.button--filled .icon:before,.u-resetSpectrum .u-accentColor--buttonNormal.button--filled .svgIcon{color: rgba(255, 255, 255, 1) !important; fill: rgba(255, 255, 255, 1) !important;}
.u-resetSpectrum .u-accentColor--buttonDark.button--filled,.u-resetSpectrum .u-accentColor--buttonDark.button--withChrome.is-active,.u-resetSpectrum .u-accentColor--fillWhenActive.is-active {background-color: rgba(28, 153, 99, 1) !important; border-color: rgba(28, 153, 99, 1) !important; color: rgba(255, 255, 255, 1) !important; fill: rgba(255, 255, 255, 1) !important;}
.u-resetSpectrum .u-accentColor--buttonNormal.button--filled:not(.clapButton--largePill),.u-resetSpectrum .u-accentColor--buttonNormal.button--withChrome.is-active:not(.clapButton--largePill) {background-color: rgba(0, 171, 107, 1) !important; border-color: rgba(0, 171, 107, 1) !important; color: rgba(255, 255, 255, 1) !important; fill: rgba(255, 255, 255, 1) !important;}
.u-resetSpectrum .postArticle.is-withAccentColors .markup--user,.u-resetSpectrum .postArticle.is-withAccentColors .markup--query {color: rgba(0, 171, 107, 1) !important;}</style><div class="highlightMenu" data-action-scope="_actionscope_3"><div class="highlightMenu-inner"><div class="buttonSet"><button class="button button--chromeless u-baseColor--buttonNormal button--withIcon button--withSvgIcon button--highlightMenu u-accentColor--highlightStrong js-highlightMenuQuoteButton" data-action="sign-up-prompt" data-sign-in-action="quote" data-requires-token="true" data-redirect="https://blog.insightdatascience.com/reinforcement-learning-from-scratch-819b65f074d8" data-skip-onboarding="true" data-redirect-type="quote" data-action-source="quote_menu--------------------------highlight_text"><span class="svgIcon svgIcon--highlighter svgIcon--25px"><svg class="svgIcon-use" width="25" height="25" viewBox="0 0 25 25"><path d="M13.7 15.964l5.204-9.387-4.726-2.62-5.204 9.387 4.726 2.62zm-.493.885l-1.313 2.37-1.252.54-.702 1.263-3.796-.865 1.228-2.213-.202-1.35 1.314-2.37 4.722 2.616z" fill-rule="evenodd"></path></svg></span></button><button class="button button--chromeless u-baseColor--buttonNormal button--withIcon button--withSvgIcon button--highlightMenu" data-action="sign-up-prompt" data-sign-in-action="quote-respond" data-redirect="https://blog.insightdatascience.com/reinforcement-learning-from-scratch-819b65f074d8" data-skip-onboarding="true" data-action-source="quote_menu--------------------------respond_text"><span class="svgIcon svgIcon--responseFilled svgIcon--25px"><svg class="svgIcon-use" width="25" height="25" viewBox="0 0 25 25"><path d="M19.074 21.117c-1.244 0-2.432-.37-3.532-1.096a7.792 7.792 0 0 1-.703-.52c-.77.21-1.57.32-2.38.32-4.67 0-8.46-3.5-8.46-7.8C4 7.7 7.79 4.2 12.46 4.2c4.662 0 8.457 3.5 8.457 7.803 0 2.058-.85 3.984-2.403 5.448.023.17.06.35.118.55.192.69.537 1.38 1.026 2.04.15.21.172.48.058.7a.686.686 0 0 1-.613.38h-.03z" fill-rule="evenodd"></path></svg></span></button><button class="button button--chromeless u-baseColor--buttonNormal button--withIcon button--withSvgIcon button--highlightMenu" data-action="twitter" data-action-source="quote_menu" data-skip-onboarding="true"><span class="svgIcon svgIcon--twitterFilled svgIcon--25px"><svg class="svgIcon-use" width="25" height="25" viewBox="0 0 25 25"><path d="M21.725 5.338c-.744.47-1.605.804-2.513 1.006a3.978 3.978 0 0 0-2.942-1.293c-2.22 0-4.02 1.81-4.02 4.02 0 .32.034.63.07.94-3.31-.18-6.27-1.78-8.255-4.23a4.544 4.544 0 0 0-.574 2.01c.04 1.43.74 2.66 1.8 3.38-.63-.01-1.25-.19-1.79-.5v.08c0 1.93 1.38 3.56 3.23 3.95-.34.07-.7.12-1.07.14-.25-.02-.5-.04-.72-.07.49 1.58 1.97 2.74 3.74 2.8a8.49 8.49 0 0 1-5.02 1.72c-.3-.03-.62-.04-.93-.07A11.447 11.447 0 0 0 8.88 21c7.386 0 11.43-6.13 11.414-11.414.015-.21.01-.38 0-.578a7.604 7.604 0 0 0 2.01-2.08 7.27 7.27 0 0 1-2.297.645 3.856 3.856 0 0 0 1.72-2.23"></path></svg></span></button><div class="buttonSet-separator"></div><button class="button button--chromeless u-baseColor--buttonNormal button--withIcon button--withSvgIcon button--highlightMenu" data-action="sign-up-prompt" data-sign-in-action="highlight" data-redirect="https://blog.insightdatascience.com/reinforcement-learning-from-scratch-819b65f074d8" data-skip-onboarding="true" data-action-source="quote_menu--------------------------privatenote_text"><span class="svgIcon svgIcon--privatenoteFilled svgIcon--25px"><svg class="svgIcon-use" width="25" height="25" viewBox="0 0 25 25"><g fill-rule="evenodd"><path d="M17.662 4.552H7.346A4.36 4.36 0 0 0 3 8.898v5.685c0 2.168 1.614 3.962 3.697 4.28v2.77c0 .303.35.476.59.29l3.904-2.994h6.48c2.39 0 4.35-1.96 4.35-4.35V8.9c0-2.39-1.95-4.346-4.34-4.346zM16 14.31a.99.99 0 0 1-1.003.99h-4.994C9.45 15.3 9 14.85 9 14.31v-3.02a.99.99 0 0 1 1-.99v-.782a2.5 2.5 0 0 1 2.5-2.51c1.38 0 2.5 1.13 2.5 2.51v.782c.552.002 1 .452 1 .99v3.02z"></path><path d="M14 9.81c0-.832-.674-1.68-1.5-1.68-.833 0-1.5.84-1.5 1.68v.49h3v-.49z"></path></g></svg></span></button></div></div><div class="highlightMenu-arrowClip"><span class="highlightMenu-arrow"></span></div></div></div></div></div><div class="loadingBar"></div><script>// <![CDATA[
window["obvInit"] = function (opt_embedded) {window["obvInit"]["embedded"] = opt_embedded; window["obvInit"]["ready"] = true;}
// ]]></script><script>// <![CDATA[
var GLOBALS = {"audioUrl":"https://d1fcbxp97j4nb2.cloudfront.net","baseUrl":"https://blog.insightdatascience.com","buildLabel":"34384-06880fc","currentUser":{"userId":"lo_6eca48311aab","isVerified":false,"subscriberEmail":"","hasPastMemberships":false,"isEnrolledInHightower":false,"isEligibleForHightower":false,"hightowerLastLockedAt":0,"isWriterProgramEnrolled":false,"isWriterProgramInvited":false},"currentUserHasUnverifiedEmail":false,"isAuthenticated":false,"isCurrentUserVerified":false,"language":"en-us","miroUrl":"https://cdn-images-1.medium.com","moduleUrls":{"base":"https://cdn-static-1.medium.com/_/fp/gen-js/main-base.bundle.OMufPCKOxcdmn6e8fEgNwA.js","common-async":"https://cdn-static-1.medium.com/_/fp/gen-js/main-common-async.bundle.WKmfPf9Nj8xCneCN6TKlEA.js","hightower":"https://cdn-static-1.medium.com/_/fp/gen-js/main-hightower.bundle.J1LdPcKQQAJX5xpUr9JlHw.js","home-screens":"https://cdn-static-1.medium.com/_/fp/gen-js/main-home-screens.bundle.uFpbgBPVWU56lFaZxMKGmA.js","misc-screens":"https://cdn-static-1.medium.com/_/fp/gen-js/main-misc-screens.bundle.lmjI44rCYNw7APIuFkgCKw.js","notes":"https://cdn-static-1.medium.com/_/fp/gen-js/main-notes.bundle.LUI7G9sM3rPgZyAJHfZQig.js","payments":"https://cdn-static-1.medium.com/_/fp/gen-js/main-payments.bundle.ghA0udvsSqbDfvX-ckuD6A.js","posters":"https://cdn-static-1.medium.com/_/fp/gen-js/main-posters.bundle.57QRNU1BfrSMdM-WpNe7Sg.js","power-readers":"https://cdn-static-1.medium.com/_/fp/gen-js/main-power-readers.bundle.lwckzszqYwk2NVI0fozq9w.js","pubs":"https://cdn-static-1.medium.com/_/fp/gen-js/main-pubs.bundle.a77_gnc2_l0h4MDX_wWs2A.js","stats":"https://cdn-static-1.medium.com/_/fp/gen-js/main-stats.bundle.cCr1yik17VVu8kO_biEXoA.js"},"previewConfig":{"weightThreshold":1,"weightImageParagraph":0.51,"weightIframeParagraph":0.8,"weightTextParagraph":0.08,"weightEmptyParagraph":0,"weightP":0.003,"weightH":0.005,"weightBq":0.003,"minPTextLength":60,"truncateBoundaryChars":20,"detectTitle":true,"detectTitleLevThreshold":0.15},"productName":"Medium","supportsEdit":true,"termsUrl":"//medium.com/policy/9db0094a1e0f","textshotHost":"textshot.medium.com","transactionId":"1532089555182:1b4f0c8b2dfa","useragent":{"browser":"chrome","family":"chrome","os":"","version":65,"supportsDesktopEdit":true,"supportsInteract":true,"supportsView":true,"isMobile":false,"isTablet":false,"isNative":false,"supportsFileAPI":true,"isTier1":true,"clientVersion":"","unknownParagraphsBad":false,"clientChannel":"","supportsRealScrollEvents":true,"supportsVhUnits":true,"ruinsViewportSections":false,"supportsHtml5Video":true,"supportsMagicUnderlines":true,"isWebView":false,"isFacebookWebView":false,"supportsProgressiveMedia":true,"supportsPromotedPosts":true,"isBot":false,"isNativeIphone":false,"supportsCssVariables":true,"supportsVideoSections":true,"emojiSupportLevel":1,"isSearchBot":false,"isSyndicationBot":false,"supportsScrollableMetabar":true},"variants":{"allow_access":true,"allow_signup":true,"allow_test_auth":"disallow","signin_services":"twitter,facebook,google,email,google-fastidv","signup_services":"twitter,facebook,google,email,google-fastidv","android_rating_prompt_recommend_threshold":5,"google_sign_in_android":true,"reengagement_notification_duration":3,"browsable_stream_config_bucket":"curated-topics","enable_dedicated_series_tab_api_ios":true,"enable_post_import":true,"available_monthly_plan":"60e220181034","available_annual_plan":"2c754bcc2995","disable_ios_resume_reading_toast":true,"is_not_medium_subscriber":true,"disable_followed_tag_fan_out":true,"glyph_font_set":"m2","enable_branding":true,"enable_branding_fonts":true,"enable_sequence_carousel":true,"enable_multirecommends":true,"enable_post_monger_v2":true,"enable_post_monger_v3":true,"enable_fastrak_beta":true,"enable_fastrak_lock_tiered_post_in_pub":true,"enable_user_post_metering":true,"enable_direct_upsell_expanded_in_meter":true,"max_premium_content_per_user_under_metering":3,"tag_intercom_user_on_metering_count":3,"enable_automated_mission_control_triggers":true,"enable_topic_writer_onboarding":true,"enable_strong_graph_chp_reorder":true,"enable_top_stories_for_you":true,"enable_ios_member_post_labeling":true,"enable_lite_profile":true,"enable_li_search_collection":true,"enable_homepage_remodel":true,"enable_signin_wall_custom_domain":true,"app_download_email_template":"control","enable_topic_lifecycle_email":true,"enable_marketing_emails":true,"enable_curation_post_locking":true,"ios_hide_avatars_on_home":true,"raise_editors_picks_digest":"control","android_disable_author_avatars":true,"enable_quality_pool_filters":true,"enable_truncated_rss_for_tags_and_topics":true,"enable_ios_related_reads_api_change":true,"enable_ios_related_reads_ui_large":true,"enable_ios_responses_collapsed":true,"enable_hightower_friend_link":true,"enable_rex_service_homefeed":true,"enable_parsely":true,"enable_curation_master_feed":true,"enable_july_meter_email_test":true,"enable_app_metered_out_promo":true,"enable_send_editors_picks_to_all_users":true,"accelerate_membership_headline_test":"coffee-headline"},"xsrfToken":"","iosAppId":"828256236","supportEmail":"yourfriends@medium.com","fp":{"/icons/monogram-mask.svg":"https://cdn-static-1.medium.com/_/fp/icons/monogram-mask.KPLCSFEZviQN0jQ7veN2RQ.svg","/icons/favicon-dev-editor.ico":"https://cdn-static-1.medium.com/_/fp/icons/favicon-dev-editor.YKKRxBO8EMvIqhyCwIiJeQ.ico","/icons/favicon-hatch-editor.ico":"https://cdn-static-1.medium.com/_/fp/icons/favicon-hatch-editor.BuEyHIqlyh2s_XEk4Rl32Q.ico","/icons/favicon-medium-editor.ico":"https://cdn-static-1.medium.com/_/fp/icons/favicon-medium-editor.PiakrZWB7Yb80quUVQWM6g.ico"},"authBaseUrl":"https://medium.com","imageUploadSizeMb":25,"isAuthDomainRequest":false,"domainCollectionSlug":"insight-data","algoliaApiEndpoint":"https://MQ57UUUQZ2-dsn.algolia.net","algoliaAppId":"MQ57UUUQZ2","algoliaSearchOnlyApiKey":"394474ced050e3911ae2249ecc774921","iosAppStoreUrl":"https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8","iosAppLinkBaseUrl":"medium:","algoliaIndexPrefix":"medium_","androidPlayStoreUrl":"https://play.google.com/store/apps/details?id=com.medium.reader","googleClientId":"216296035834-k1k6qe060s2tp2a2jam4ljdcms00sttg.apps.googleusercontent.com","androidPackage":"com.medium.reader","androidPlayStoreMarketScheme":"market://details?id=com.medium.reader","googleAuthUri":"https://accounts.google.com/o/oauth2/auth","androidScheme":"medium","layoutData":{"useDynamicScripts":false,"googleAnalyticsTrackingCode":"UA-24232453-2","jsShivUrl":"https://cdn-static-1.medium.com/_/fp/js/shiv.RI2ePTZ5gFmMgLzG5bEVAA.js","useDynamicCss":false,"faviconUrl":"https://cdn-static-1.medium.com/_/fp/icons/favicon-rebrand-medium.3Y6xpZ-0FSdWDnPM3hSBIA.ico","faviconImageId":"1*8I-HPL0bfoIzGied-dzOvA.png","fontSets":[{"id":8,"url":"https://glyph.medium.com/css/e/sr/latin/e/ssr/latin/e/ssb/latin/m2.css"},{"id":11,"url":"https://glyph.medium.com/css/m2.css"},{"id":9,"url":"https://glyph.medium.com/css/mkt.css"},{"id":10,"url":"https://glyph.medium.com/css/elv8.css"}],"editorFaviconUrl":"https://cdn-static-1.medium.com/_/fp/icons/favicon-rebrand-medium-editor.3Y6xpZ-0FSdWDnPM3hSBIA.ico","glyphUrl":"https://glyph.medium.com"},"authBaseUrlRev":"moc.muidem//:sptth","isDnt":false,"stripePublishableKey":"pk_live_7FReX44VnNIInZwrIIx6ghjl","archiveUploadSizeMb":100,"paymentData":{"currencies":{"1":{"label":"US Dollar","external":"usd"}},"countries":{"1":{"label":"United States of America","external":"US"}},"accountTypes":{"1":{"label":"Individual","external":"individual"},"2":{"label":"Company","external":"company"}}},"previewConfig2":{"weightThreshold":1,"weightImageParagraph":0.05,"raiseImage":true,"enforceHeaderHierarchy":true,"isImageInsetRight":true},"isAmp":false,"iosScheme":"medium","isSwBoot":false,"lightstep":{"accessToken":"ce5be895bef60919541332990ac9fef2","carrier":"{\"ot-tracer-spanid\":\"3ace4ade5fc83cb2\",\"ot-tracer-traceid\":\"6ed10cb74693f6a8\",\"ot-tracer-sampled\":\"true\"}","host":"collector-medium.lightstep.com"},"facebook":{"key":"542599432471018","namespace":"medium-com","scope":{"default":["public_profile","email","user_friends"],"connect":["public_profile","email","user_friends"],"login":["public_profile","email","user_friends"],"share":["public_profile","email","user_friends","publish_actions"]}},"editorsPicksTopicId":"3985d2a191c5","popularOnMediumTopicId":"9d34e48ecf94","memberContentTopicId":"13d7efd82fb2","audioContentTopicId":"3792abbd134","brandedSequenceId":"7d337ddf1941","isDoNotAuth":false,"goldfinchUrl":"https://goldfinch.medium.com","buggle":{"url":"https://buggle.medium.com","videoUrl":"https://cdn-videos-1.medium.com","audioUrl":"https://cdn-audio-1.medium.com"},"referrerType":3,"isMeteredOut":false,"meterConfig":{"maxUnlockCount":3,"windowLength":"MONTHLY"},"partnerProgramEmail":"partnerprogram@medium.com","userResearchPrompts":[{"promptId":"lo_post_page_4","type":0,"url":"www.calendly.com"},{"promptId":"lo_home_page","type":1,"url":"www.calendly.com"},{"promptId":"lo_profile_page","type":2,"url":"www.calendly.com"}],"recaptchaKey":"6LdAokEUAAAAAC7seICd4vtC8chDb3jIXDQulyUJ","paypalClientMode":"production","signinWallCustomDomainCollectionIds":["3a8144eabfe3","336d898217ee","61061eb0c96b","138adf9c44c","819cc2aaeee0"],"countryCode":"ET","bypassMeter":false}
// ]]></script><script charset="UTF-8" src="./Reinforcement Learning from scratch – Insight Data_files/main-base.bundle.OMufPCKOxcdmn6e8fEgNwA.js" async=""></script><script>// <![CDATA[
window["obvInit"]({"value":{"id":"819b65f074d8","versionId":"26af880d9996","creatorId":"45cca2d4999f","creator":{"userId":"45cca2d4999f","name":"Emmanuel Ameisen","username":"emmanuelameisen","createdAt":1404198608737,"lastPostCreatedAt":1531602421598,"imageId":"1*u2FiBL9mzFPx7pj87aWxgw.jpeg","backgroundImageId":"","bio":"AI Lead at Insight AI @EmmanuelAmeisen","twitterScreenName":"EmmanuelAmeisen","socialStats":{"userId":"45cca2d4999f","usersFollowedCount":8,"usersFollowedByCount":2324,"type":"SocialStats"},"social":{"userId":"lo_6eca48311aab","targetUserId":"45cca2d4999f","type":"Social"},"facebookAccountId":"10203282016947013","allowNotes":1,"isNsfw":false,"isWriterProgramInvited":false,"isPartnerProgramEnrolled":false,"isWriterProgramEnrolled":false,"type":"User"},"homeCollection":{"id":"d02e65779d7b","name":"Insight Data","slug":"insight-data","tags":["INSIGHT DATA SCIENCE","INSIGHT DATA ENGINEERING","INSIGHT HEALTH DATA","EDUCATION","INSIGHT AI"],"creatorId":"7b169ef2b4c1","description":"Insight Fellows Program - Your bridge to a career in data","shortDescription":"Insight Fellows Program - Your bridge to a career in data","image":{"imageId":"1*bVN8Kd_RsjRN8JuKIc6U0w.png","filter":"","backgroundSize":"","originalWidth":65,"originalHeight":65,"strategy":"resample","height":0,"width":0},"metadata":{"followerCount":9446,"activeAt":1531953426184},"virtuals":{"permissions":{"canPublish":false,"canPublishAll":false,"canRepublish":false,"canRemove":false,"canManageAll":false,"canSubmit":false,"canEditPosts":false,"canAddWriters":false,"canViewStats":false,"canSendNewsletter":false,"canViewLockedPosts":false,"canViewCloaked":false,"canEditOwnPosts":false,"canBeAssignedAuthor":false,"canEnrollInHightower":false,"canLockPostsForMediumMembers":false,"canLockOwnPostsForMediumMembers":false},"isSubscribed":false,"isNewsletterSubscribed":false,"memberOfMembershipPlanId":"","isEnrolledInHightower":false,"isEligibleForHightower":false},"logo":{"imageId":"1*QBd0FwuD-7reNUpsp4YFjg.png","filter":"","backgroundSize":"","originalWidth":1830,"originalHeight":720,"strategy":"resample","height":0,"width":0},"twitterUsername":"InsightDataSci","facebookPageName":"InsightDataScience","publicEmail":"info@insightdatascience.com","collectionMastheadId":"d30edced0fdd","domain":"blog.insightdatascience.com","sections":[{"type":2,"collectionHeaderMetadata":{"title":"INSIGHT","description":"Your bridge to careers in data","backgroundImage":{"id":"1*TfKznWfrEX5jqKlgf6eivw.jpeg","originalWidth":2118,"originalHeight":541},"logoImage":{"id":"1*QuEQPja8VMt33UcBCupujg@2x.png","originalWidth":1036,"originalHeight":1047,"alt":"Insight Data"},"alignment":2,"layout":5}},{"type":1,"postListMetadata":{"source":1,"layout":5,"number":25,"postIds":[]}}],"tintColor":"#FF577ADA","lightText":true,"favicon":{"imageId":"1*LH1Ab6OAbS03JhOUvBlg9A.png","filter":"","backgroundSize":"","originalWidth":1036,"originalHeight":1047,"strategy":"resample","height":0,"width":0},"colorPalette":{"defaultBackgroundSpectrum":{"colorPoints":[{"color":"#FF5F83E3","point":0},{"color":"#FF5A7AD0","point":0.1},{"color":"#FF5471BD","point":0.2},{"color":"#FF4E68AA","point":0.3},{"color":"#FF485E97","point":0.4},{"color":"#FF415485","point":0.5},{"color":"#FF3A4A72","point":0.6},{"color":"#FF323F60","point":0.7},{"color":"#FF29334D","point":0.8},{"color":"#FF20273B","point":0.9},{"color":"#FF151A28","point":1}],"backgroundColor":"#FFFFFFFF"},"tintBackgroundSpectrum":{"colorPoints":[{"color":"#FF577ADA","point":0},{"color":"#FF698AE0","point":0.1},{"color":"#FF7A98E7","point":0.2},{"color":"#FF8BA6ED","point":0.3},{"color":"#FF9CB4F3","point":0.4},{"color":"#FFACC1F8","point":0.5},{"color":"#FFBCCEFE","point":0.6},{"color":"#FFCBDBFF","point":0.7},{"color":"#FFDBE7FF","point":0.8},{"color":"#FFEAF3FF","point":0.9},{"color":"#FFF9FFFF","point":1}],"backgroundColor":"#FF577ADA"},"highlightSpectrum":{"colorPoints":[{"color":"#FFEBF3FF","point":0},{"color":"#FFE7F1FF","point":0.1},{"color":"#FFE3EFFF","point":0.2},{"color":"#FFDFEEFF","point":0.3},{"color":"#FFDBECFF","point":0.4},{"color":"#FFD7EAFF","point":0.5},{"color":"#FFD3E8FF","point":0.6},{"color":"#FFCFE6FF","point":0.7},{"color":"#FFCBE4FF","point":0.8},{"color":"#FFC7E2FF","point":0.9},{"color":"#FFC2E0FF","point":1}],"backgroundColor":"#FFFFFFFF"}},"navItems":[{"type":1,"title":"About Insight","tagSlug":"about-insight","url":"https://blog.insightdatascience.com/tagged/about-insight","source":"tagSlug"},{"type":1,"title":"Data Science","tagSlug":"insight-data-science","url":"https://blog.insightdatascience.com/tagged/insight-data-science","source":"tagSlug"},{"type":1,"title":"Data Engineering","tagSlug":"insight-data-engineering","url":"https://blog.insightdatascience.com/tagged/insight-data-engineering","source":"tagSlug"},{"type":1,"title":"Health Data","tagSlug":"insight-health-data","url":"https://blog.insightdatascience.com/tagged/insight-health-data","source":"tagSlug"},{"type":1,"title":"AI","tagSlug":"insight-ai","url":"https://blog.insightdatascience.com/tagged/insight-ai","source":"tagSlug"},{"type":1,"title":"Data PM","tagSlug":"insight-data-pm","url":"https://blog.insightdatascience.com/tagged/insight-data-pm","source":"tagSlug"},{"type":1,"title":"DevOps","tagSlug":"insight-devops","url":"https://blog.insightdatascience.com/tagged/insight-devops","source":"tagSlug"}],"colorBehavior":2,"instantArticlesState":0,"acceleratedMobilePagesState":0,"googleAnalyticsId":"UA-29720873-1","ampLogo":{"imageId":"","filter":"","backgroundSize":"","originalWidth":0,"originalHeight":0,"strategy":"resample","height":0,"width":0},"header":{"title":"INSIGHT","description":"Your bridge to careers in data","backgroundImage":{"id":"1*TfKznWfrEX5jqKlgf6eivw.jpeg","originalWidth":2118,"originalHeight":541},"logoImage":{"id":"1*QuEQPja8VMt33UcBCupujg@2x.png","originalWidth":1036,"originalHeight":1047,"alt":"Insight Data"},"alignment":2,"layout":5},"type":"Collection"},"homeCollectionId":"d02e65779d7b","title":"Reinforcement Learning from scratch","detectedLanguage":"en","latestVersion":"26af880d9996","latestPublishedVersion":"26af880d9996","hasUnpublishedEdits":false,"latestRev":2449,"createdAt":1523425374976,"updatedAt":1529574668238,"acceptedAt":0,"firstPublishedAt":1528387366751,"latestPublishedAt":1528395854769,"vote":false,"experimentalCss":"","displayAuthor":"","content":{"subtitle":"Inspired by a great tutorial at O’Reilly AI","bodyModel":{"paragraphs":[{"name":"10a5","type":3,"text":"Reinforcement Learning from scratch","markups":[]},{"name":"aafa","type":13,"text":"Inspired by a great tutorial at O’Reilly AI","markups":[]},{"name":"f9ad","type":4,"text":"A movie about one of the most famous applications of Deep RL","markups":[],"layout":1,"metadata":{"id":"1*sf4ZeTwBq1O61U4W49NBdQ.png","originalWidth":1200,"originalHeight":630,"isFeatured":true}},{"name":"dbe8","type":1,"text":"Want to learn about applied Artificial Intelligence from leading practitioners in Silicon Valley, New York, or Toronto? Learn more about the Insight Artificial Intelligence Fellows Program.","markups":[{"type":3,"start":141,"end":188,"href":"http://insightdata.ai?utm_source=deep_rl&utm_medium=blog&utm_content=top","title":"","rel":"noopener","anchorType":0},{"type":1,"start":0,"end":119},{"type":2,"start":0,"end":120}]},{"name":"26ad","type":1,"text":"Are you a company working in AI and would like to get involved in the Insight AI Fellows Program? Feel free to get in touch.","markups":[{"type":3,"start":111,"end":123,"href":"http://insightdatascience.com/partnerships?utm_source=deep_rl&utm_medium=blog&utm_content=top","title":"","rel":"noopener","anchorType":0},{"type":1,"start":0,"end":97},{"type":2,"start":0,"end":124}]},{"name":"1da2","type":1,"text":"Recently, I gave a talk at the O’Reilly AI conference in Beijing about some of the interesting lessons we’ve learned in the world of NLP. While there, I was lucky enough to attend a tutorial on Deep Reinforcement Learning (Deep RL) from scratch by Unity Technologies. I thought that the session, led by Arthur Juliani, was extremely informative and wanted to share some big takeaways below.","markups":[{"type":3,"start":95,"end":102,"href":"https://blog.insightdatascience.com/how-to-solve-90-of-nlp-problems-a-step-by-step-guide-fda605278e4e","title":"","rel":"","anchorType":0},{"type":3,"start":303,"end":317,"anchorType":2,"userId":"18dfe63fa7f0"}]},{"name":"3c9c","type":1,"text":"In our conversations with companies, we’ve seen a rise of interesting Deep RL applications, tools and results. In parallel, the inner workings and applications of Deep RL, such as AlphaGo pictured above, can often seem esoteric and hard to understand. In this post, I will give an overview of core aspects of the field that can be understood by anyone.","markups":[{"type":1,"start":331,"end":351}]},{"name":"141f","type":1,"text":"Many of the visuals are from the slides of the talk, and some are new. The explanations and opinions are mine. If anything is unclear, reach out to me here!","markups":[{"type":3,"start":151,"end":155,"href":"https://twitter.com/EmmanuelAmeisen","title":"","rel":"","anchorType":0}]},{"name":"33c2","type":3,"text":"The rise of Deep Reinforcement Learning","markups":[]},{"name":"68be","type":1,"text":"Deep RL is a field that has seen vast amounts of research interest, including learning to play Atari games, beating pro players at Dota 2, and defeating Go champions. Contrary to many classical Deep Learning problems that often focus on perception (does this image contain a stop sign?), Deep RL adds the dimension of actions that influence the environment (what is the goal, and how do I get there?). In dialog systems for example, classical Deep Learning aims to learn the right response for a given query. On the other hand, Deep Reinforcement Learning focuses on the right sequences of sentences that will lead to a positive outcome, for example a happy customer.","markups":[{"type":3,"start":108,"end":115,"href":"https://blog.openai.com/dota-2/","title":"","rel":"noopener","anchorType":0},{"type":3,"start":143,"end":152,"href":"https://deepmind.com/research/alphago/","title":"","rel":"","anchorType":0},{"type":1,"start":237,"end":247},{"type":1,"start":318,"end":325}]},{"name":"91d7","type":1,"text":"This makes Deep RL particularly attractive for tasks that require planning and adaptation, such as manufacturing or self-driving. However, industry applications have trailed behind the rapidly advancing results coming out of the research community. A major reason is that Deep RL often requires an agent to experiment millions of times before learning anything useful. The best way to do this rapidly is by using a simulation environment. This tutorial will be using Unity to create environments to train agents in.","markups":[{"type":3,"start":467,"end":472,"href":"https://unity3d.com/unity","title":"","rel":"","anchorType":0},{"type":1,"start":415,"end":437}]},{"name":"8ebc","type":1,"text":"For this workshop led by Arthur Juliani and Leon Chen, their goal was to get every participants to successfully train multiple Deep RL algorithms in 4 hours. A tall order! Below, is a comprehensive overview of many of the main algorithms that power Deep RL today. For a more complete set of tutorials, Arthur Juliani wrote an 8-part series starting here.","markups":[{"type":3,"start":25,"end":39,"href":"https://www.linkedin.com/in/arthur-juliani-50a38a21/","title":"","rel":"noopener","anchorType":0},{"type":3,"start":44,"end":53,"href":"https://www.linkedin.com/in/zhongyuechen/","title":"","rel":"noopener","anchorType":0},{"type":3,"start":302,"end":316,"anchorType":2,"userId":"18dfe63fa7f0"},{"type":3,"start":349,"end":353,"href":"https://medium.com/emergent-future/simple-reinforcement-learning-with-tensorflow-part-0-q-learning-with-tables-and-neural-networks-d195264329d0","title":"","rel":"","anchorType":0},{"type":1,"start":184,"end":206}]},{"name":"99db","type":13,"text":"From slot machines to video games, an overview of RL","markups":[]},{"name":"fcee","type":1,"text":"Deep RL can be used to best the top human players at Go, but to understand how that’s done, you first need to understand a few simple concepts, starting with much easier problems.","markups":[{"type":1,"start":127,"end":142}]},{"name":"9391","type":1,"text":"1/It all starts with slot machines","markups":[{"type":1,"start":0,"end":34}]},{"name":"dec4","type":4,"text":"As a first toy problem, can we learn which of these chests has the biggest chance of containing a reward","markups":[],"layout":1,"metadata":{"id":"1*2A9ZhECO8zbQiJUFI3abNA.png","originalWidth":1924,"originalHeight":1088}},{"name":"b7bd","type":1,"text":"Let’s imagine you are faced with 4 chests that you can pick from at each turn. Each of them have a different average payout, and your goal is to maximize the total payout you receive after a fixed number of turns. This is a classic problem called Multi-armed bandits and is where we will start. The crux of the problem is to balance exploration, which helps us learn about which states are good, and exploitation, where we now use what we know to pick the best slot machine.","markups":[{"type":3,"start":247,"end":266,"href":"https://en.wikipedia.org/wiki/Multi-armed_bandit","title":"","rel":"","anchorType":0},{"type":1,"start":333,"end":344},{"type":1,"start":400,"end":412}]},{"name":"75cf","type":1,"text":"Here, we will utilize a value function that maps our actions to an estimated reward, called the Q function. First, we’ll initialize all Q values at equal values. Then, we’ll update the Q value of each action (picking each chest) based on how good the payout was after choosing this action. This allows us to learn a good value function. We will approximate our Q function using a neural network (starting with a very shallow one) that learns a probability distribution (by using a softmax) over the 4 potential chests.","markups":[{"type":3,"start":96,"end":106,"href":"https://en.wikipedia.org/wiki/Q-learning","title":"","rel":"","anchorType":0},{"type":3,"start":481,"end":488,"href":"https://en.wikipedia.org/wiki/Softmax_function","title":"","rel":"","anchorType":0},{"type":1,"start":24,"end":38},{"type":1,"start":308,"end":335}]},{"name":"bfdc","type":1,"text":"While the value function tells us how good we estimate each action to be, the policy is the function that determines which actions we end up taking. Intuitively, we might want to use a policy that picks the action with the highest Q value. This performs poorly in practice, as our Q estimates will be very wrong at the start before we gather enough experience through trial and error. This is why we need to add a mechanism to our policy to encourage exploration. One way to do that is to use epsilon greedy, which consists of taking a random action with probability epsilon. We start with epsilon being close to 1, always choosing random actions, and lower epsilon as we go along and learn more about which chests are good. Eventually, we learn which chests are best.","markups":[{"type":3,"start":493,"end":507,"href":"https://en.wikipedia.org/wiki/Multi-armed_bandit#Semi-uniform_strategies","title":"","rel":"","anchorType":0},{"type":1,"start":78,"end":84},{"type":1,"start":117,"end":147},{"type":1,"start":349,"end":383},{"type":1,"start":441,"end":462},{"type":1,"start":536,"end":549}]},{"name":"63a8","type":1,"text":"In practice, we might want to take a more subtle approach than either taking the action we think is the best, or a random action. A popular method is Boltzmann Exploration, which adjust probabilities based on our current estimate of how good each chest is, adding in a randomness factor.","markups":[]},{"name":"00c9","type":1,"text":"2/Adding different states","markups":[{"type":1,"start":0,"end":25}]},{"name":"be8a","type":4,"text":"Here, different background colors mean different average chest rewards","markups":[],"layout":1,"metadata":{"id":"1*TSPMNQ4SF0r2ypRP8GFtGA.png","originalWidth":2208,"originalHeight":1064}},{"name":"3589","type":1,"text":"The previous example was a world in which we were always in the same state, waiting to pick from the same 4 chests in front of us. Most real-word problems consist of many different states. That is what we will add to our environment next. Now, the background behind chests alternates between 3 colors at each turn, changing the average values of the chests. This means we need to learn a Q function that depends not only on the action (the chest we pick), but the state (what the color of the background is). This version of the problem is called Contextual Multi-armed Bandits.","markups":[{"type":1,"start":315,"end":342},{"type":1,"start":428,"end":434},{"type":1,"start":464,"end":469}]},{"name":"8f0a","type":1,"text":"Surprisingly, we can use the same approach as before. The only thing we need to add is an extra dense layer to our neural network, that will take in as input a vector representing the current state of the world.","markups":[{"type":1,"start":14,"end":52}]},{"name":"f3a9","type":1,"text":"3/Learning about the consequences of our actions","markups":[{"type":1,"start":0,"end":48}]},{"name":"88e9","type":4,"text":"Here, we are the blue square trying to learn how to get to the green square without touching the red ones","markups":[],"layout":1,"metadata":{"id":"1*2JOhvWzYAOQ5MMX4e3fxlg.png","originalWidth":1606,"originalHeight":1556}},{"name":"55d2","type":1,"text":"There is another key factor that makes our current problem simpler than mosts. In most environments, such as in the maze depicted above, the actions that we take have an impact on the state of the world. If we move up on this grid, we might receive a reward or we might receive nothing, but the next turn we will be in a different state. This is where we finally introduce a need for planning.","markups":[{"type":1,"start":141,"end":202},{"type":1,"start":384,"end":392}]},{"name":"5e6e","type":1,"text":"First, we will define our Q function as the immediate reward in our current state, plus the discounted reward we are expecting by taking all of our future actions. This solution works if our Q estimate of states is accurate, so how can we learn a good estimate?","markups":[{"type":1,"start":44,"end":60},{"type":1,"start":103,"end":126}]},{"name":"3bac","type":1,"text":"We will use a method called Temporal Difference (TD) learning to learn a good Q function. The idea is to only look at a limited number of steps in the future. TD(1) for example, only uses the next 2 states to evaluate the reward.","markups":[{"type":1,"start":28,"end":61}]},{"name":"1ab0","type":1,"text":"Surprisingly, we can use TD(0), which looks at the current state, and our estimate of the reward the next turn, and get great results. The structure of the network is the same, but we need to go through one forward step before receiving the error. We then use this error to back propagate gradients, like in traditional Deep Learning, and update our value estimates.","markups":[{"type":3,"start":274,"end":288,"href":"https://en.wikipedia.org/wiki/Backpropagation","title":"","rel":"","anchorType":0}]},{"name":"f7de","type":1,"text":"3+/Introducing Monte Carlo","markups":[{"type":1,"start":0,"end":26}]},{"name":"43dc","type":1,"text":"Another method to estimate the eventual success of our actions is Monte Carlo Estimates. This consists of playing out the entire episode with our current policy until we reach an end (success by reaching a green block or failure by reaching a red block in the image above) and use that result to update our value estimates for each traversed state. This allows us to propagate values efficiently in one batch at the end of an episode, instead of every time we make a move. The cost is that we are introducing noise to our estimates, since we attribute very distant rewards to them.","markups":[{"type":1,"start":118,"end":136},{"type":1,"start":323,"end":347},{"type":1,"start":367,"end":395}]},{"name":"732d","type":1,"text":"4/The world is rarely discrete","markups":[{"type":1,"start":0,"end":30}]},{"name":"9939","type":4,"text":"","markups":[],"layout":1,"metadata":{"id":"1*ZgPdKglJ8ioqzVF-4c3Nqg.png","originalWidth":1784,"originalHeight":1012}},{"name":"7e93","type":1,"text":"The previous methods were using neural networks to approximate our value estimates by mapping from a discrete number of states and actions to a value. In the maze for example, there were 49 states (squares) and 4 actions (move in each adjacent direction). In this environment, we are trying to learn how to balance a ball on a 2 dimensional paddle, by deciding at each time step whether we want to tilt the paddle left or right. Here, the state space becomes continuous (the angle of the paddle, and the position of the ball). The good news is, we can still use Neural Networks to approximate this function!","markups":[{"type":1,"start":101,"end":138},{"type":1,"start":435,"end":469}]},{"name":"5220","type":1,"text":"A note about off-policy vs on-policy learning: The methods we used previously, are off-policy methods, meaning we can generate data with any strategy(using epsilon greedy for example) and learn from it. On-policy methods can only learn from actions that were taken following our policy (remember, a policy is the method we use to determine which actions to take). This constrains our learning process, as we have to have an exploration strategy that is built in to the policy itself, but allows us to tie results directly to our reasoning, and enables us to learn more efficiently.","markups":[{"type":1,"start":13,"end":45},{"type":1,"start":132,"end":149},{"type":1,"start":236,"end":285},{"type":1,"start":501,"end":538}]},{"name":"2962","type":1,"text":"The approach we will use here is called Policy Gradients, and is an on-policy method. Previously, we were first learning a value function Q for each action in each state and then building a policy on top. In Vanilla Policy Gradient, we still use Monte Carlo Estimates, but we learn our policy directly through a loss function that increases the probability of choosing rewarding actions. Since we are learning on policy, we cannot use methods such as epsilon greedy (which includes random choices), to get our agent to explore the environment. The way that we encourage exploration is by using a method called entropy regularization, which pushes our probability estimates to be wider, and thus will encourage us to make riskier choices to explore the space.","markups":[{"type":1,"start":40,"end":56},{"type":1,"start":208,"end":231},{"type":1,"start":276,"end":301},{"type":1,"start":331,"end":386},{"type":1,"start":610,"end":632},{"type":1,"start":716,"end":736}]},{"name":"db1e","type":1,"text":"4+/Leveraging deep learning for representations","markups":[{"type":1,"start":0,"end":47}]},{"name":"a27a","type":1,"text":"In practice, many state of the art RL methods require learning both a policy and value estimates. The way we do this with deep learning is by having both be two separate outputs of the same backbone neural network, which will make it easier for our neural network to learn good representations.","markups":[{"type":1,"start":63,"end":96}]},{"name":"ec98","type":1,"text":"One method to do this is Advantage Actor Critic (A2C). We learn our policy directly with policy gradients (defined above), and learn a value function using something called Advantage. Instead of updating our value function based on rewards, we update it based on our advantage, which measures how much better or worse an action was than our previous value function estimated it to be. This helps make learning more stable compared to simple Q Learning and Vanilla Policy Gradients.","markups":[{"type":1,"start":25,"end":47},{"type":1,"start":173,"end":184}]},{"name":"2cb2","type":1,"text":"5/Learning directly from the screen","markups":[{"type":1,"start":0,"end":35}]},{"name":"4d92","type":4,"text":"The inputs to the model are the pixels in the image above!","markups":[],"layout":1,"metadata":{"id":"1*mz7YKHaKS590RlBpKyuy-A.png","originalWidth":1562,"originalHeight":1280}},{"name":"c100","type":1,"text":"There is an additional advantage to using Deep Learning for these methods, which is that Deep Neural Networks excel at perceptive tasks. When a human plays a game, the information received is not a list of states, but an image (usually of a screen, or a board, or the surrounding environment).","markups":[{"type":1,"start":119,"end":135}]},{"name":"0680","type":1,"text":"Image-based Learning combines a Convolutional Neural Network (CNN) with RL. In this environment, we pass in a raw image instead of features, and add a 2 layer CNN to our architecture without changing anything else! We can even inspect activations to see what the network picks up on to determine value, and policy. In the example below, we can see that the network uses the current score and distant obstacles to estimate the value of the current state, while focusing on nearby obstacles for determining actions. Neat!","markups":[{"type":1,"start":21,"end":74},{"type":1,"start":110,"end":119},{"type":1,"start":227,"end":246},{"type":1,"start":374,"end":409},{"type":1,"start":439,"end":452},{"type":1,"start":472,"end":488},{"type":1,"start":505,"end":512}]},{"name":"67ad","type":4,"text":"Inspecting a CNN’s activations to see what is important to the value estimate (left) and the policy estimate (right).","markups":[],"layout":1,"metadata":{"id":"1*QrXNFXqOYRQ7msBlq6RaEg.png","originalWidth":1354,"originalHeight":880}},{"name":"adcc","type":1,"text":"As a side note, while toying around with the provided implementation, I’ve found that visual learning is very sensitive to hyperparameters. Changing the discount rate slightly for example, completely prevented the neural network from learning even on a toy application. This is a widely known problem, but it is interesting to see it first hand.","markups":[{"type":3,"start":293,"end":300,"href":"https://www.alexirpan.com/2018/02/14/rl-hard.html","title":"","rel":"","anchorType":0}]},{"name":"42d7","type":1,"text":"6/Nuanced actions","markups":[{"type":1,"start":0,"end":17}]},{"name":"52e7","type":4,"text":"","markups":[],"layout":1,"metadata":{"id":"1*ZpXpbubGccgLQ6ppRmrVDQ.png","originalWidth":1642,"originalHeight":912}},{"name":"0484","type":1,"text":"So far, we’ve played with environments with continuous and discrete state spaces. However, every environment we studied had a discrete action space: we could move in one of four directions, or tilt the paddle to the left or right. Ideally, for applications such as self-driving cars, we would like to learn continuous actions, such as turning the steering wheel between 0 and 360 degrees. In this environment called 3D ball world, we can choose to tilt the paddle to any value on each of its axes. This gives us more control as to how we perform actions, but makes the action space much larger.","markups":[{"type":1,"start":68,"end":80},{"type":1,"start":135,"end":147},{"type":1,"start":335,"end":361},{"type":1,"start":512,"end":524},{"type":1,"start":559,"end":593}]},{"name":"1104","type":1,"text":"We can approach this by approximating our potential choices with Gaussian distributions. We learn a probability distribution over potential actions by learning the mean and variance of a Gaussian distribution, and our policy we sample from that distribution. Simple, in theory :).","markups":[]},{"name":"fcd8","type":1,"text":"7/Next steps for the brave","markups":[{"type":1,"start":0,"end":26}]},{"name":"9cac","type":1,"text":"There are a few concepts that separate the algorithms described above from state of the art approaches. It’s interesting to see that conceptually, the best robotics and game-playing algorithms are not that far away from the ones we just explored:","markups":[]},{"name":"1916","type":9,"text":"Parallelizing: A3C is one of the most common approaches out there. It adds an asynchronous step to actor critic, allowing the algorithm to run in a parallelized way. This allows it to solve more interesting problems in a reasonable amount of time. Evolutionary methods can be parallelized even more, and are showing very encouraging performance.","markups":[{"type":3,"start":321,"end":332,"href":"https://eng.uber.com/deep-neuroevolution/","title":"","rel":"","anchorType":0},{"type":1,"start":0,"end":13}]},{"name":"599f","type":9,"text":"Curriculum Learning: in many cases, it is extremely unlikely to get to any reward by acting randomly. This makes the exploration phase extremely tricky, as we will never learn anything valuable. In that case we can simplify the problem and solve a trivial version first, then use the basic model on increasingly more complex environments.","markups":[{"type":1,"start":0,"end":19}]},{"name":"e87f","type":9,"text":"Memory: Using LSTMs, for example, we can remember what happened in the past, and make decisions in a sequential way within a game playing session.","markups":[{"type":1,"start":0,"end":6}]},{"name":"1f8a","type":9,"text":"Model based RL: Various approach exist for algorithms to build a model of the world while they learn, so that they can infer rules about how the world works, on top of simply performing actions with high rewards. AlphaZero combines an explicit model with planning. This is a paper I found particularly exciting in the space.","markups":[{"type":3,"start":265,"end":269,"href":"http://worldmodels.github.io","title":"","rel":"","anchorType":0},{"type":1,"start":0,"end":14}]},{"name":"a292","type":1,"text":"That’s it for this overview, I hope this has been informative and fun! If you are looking to dive deeper into the theory of RL, give Arthur’s posts a read, or diving deeper by following David Silver’s UCL course. If you are looking to learn more about the projects we do at Insight, or how we work with companies, please check us out below, or reach out to me here.","markups":[{"type":3,"start":150,"end":154,"href":"https://medium.com/emergent-future/simple-reinforcement-learning-with-tensorflow-part-0-q-learning-with-tables-and-neural-networks-d195264329d0","title":"","rel":"","anchorType":0},{"type":3,"start":205,"end":211,"href":"http://www0.cs.ucl.ac.uk/staff/d.silver/web/Teaching.html","title":"","rel":"","anchorType":0},{"type":3,"start":360,"end":364,"href":"https://twitter.com/EmmanuelAmeisen","title":"","rel":"","anchorType":0}]},{"name":"e9bd","type":1,"text":"Want to learn about applied Artificial Intelligence from leading practitioners in Silicon Valley, New York, or Toronto? Learn more about the Insight Artificial Intelligence Fellows Program.","markups":[{"type":3,"start":141,"end":188,"href":"http://insightdata.ai?utm_source=deep_rl&utm_medium=blog&utm_content=top","title":"","rel":"","anchorType":0},{"type":1,"start":0,"end":119},{"type":2,"start":0,"end":120}]},{"name":"748c","type":1,"text":"Are you a company working in AI and would like to get involved in the Insight AI Fellows Program? Feel free to get in touch.","markups":[{"type":3,"start":111,"end":123,"href":"http://insightdatascience.com/partnerships?utm_source=deep_rl&utm_medium=blog&utm_content=top","title":"","rel":"","anchorType":0},{"type":1,"start":0,"end":97},{"type":2,"start":0,"end":124}]}],"sections":[{"name":"8df0","startIndex":0},{"name":"978c","startIndex":5},{"name":"5524","startIndex":57}]},"postDisplay":{"coverless":true}},"virtuals":{"statusForCollection":"APPROVED","allowNotes":true,"previewImage":{"imageId":"1*sf4ZeTwBq1O61U4W49NBdQ.png","filter":"","backgroundSize":"","originalWidth":1200,"originalHeight":630,"strategy":"resample","height":0,"width":0},"wordCount":2573,"imageCount":8,"readingTime":10.842767295597485,"subtitle":"Inspired by a great tutorial at O’Reilly AI","publishedInCount":1,"usersBySocialRecommends":[],"noIndex":false,"recommends":447,"socialRecommends":[],"isBookmarked":false,"tags":[{"slug":"machine-learning","name":"Machine Learning","postCount":40805,"virtuals":{"isFollowing":false},"metadata":{"followerCount":23708,"postCount":40805,"coverImage":{"id":"1*CtR2lIHDkhB9M8Jt4irSyg.gif","originalWidth":1000,"originalHeight":287,"isFeatured":true}},"type":"Tag"},{"slug":"insight-ai","name":"Insight Ai","postCount":41,"virtuals":{"isFollowing":false},"metadata":{"followerCount":20,"postCount":41,"coverImage":{"id":"1*J8-5VgoWtMsIJhyHAuljSw.png","originalWidth":5000,"originalHeight":3328,"backgroundSize":"","filter":"","isFeatured":true,"externalSrc":"","focusPercentX":-1,"focusPercentY":-1,"alt":"","repairedAt":0}},"type":"Tag"},{"slug":"deep-learning","name":"Deep Learning","postCount":9732,"virtuals":{"isFollowing":false},"metadata":{"followerCount":9981,"postCount":9732,"coverImage":{"id":"1*BdhP4VebJ6_o_QIzjnzofQ.png","originalWidth":702,"originalHeight":575}},"type":"Tag"},{"slug":"artificial-intelligence","name":"Artificial Intelligence","postCount":55612,"virtuals":{"isFollowing":false},"metadata":{"followerCount":672520,"postCount":55612,"coverImage":{"id":"1*gAn_BSffVBcwCIR6bDgK1g.jpeg"}},"type":"Tag"},{"slug":"research","name":"Research","postCount":14866,"virtuals":{"isFollowing":false},"metadata":{"followerCount":841,"postCount":14866,"coverImage":{"id":"1*7EilaJubfekxjtnk3bAQiw.jpeg","originalWidth":3840,"originalHeight":5760,"isFeatured":true,"focusPercentX":33,"focusPercentY":25}},"type":"Tag"}],"socialRecommendsCount":0,"responsesCreatedCount":8,"links":{"entries":[{"url":"https://eng.uber.com/deep-neuroevolution/","alts":[],"httpStatus":200},{"url":"https://unity3d.com/unity","alts":[],"httpStatus":200},{"url":"http://worldmodels.github.io","alts":[],"httpStatus":200},{"url":"https://www.linkedin.com/in/arthur-juliani-50a38a21/","alts":[],"httpStatus":999},{"url":"https://en.wikipedia.org/wiki/Multi-armed_bandit","alts":[],"httpStatus":200},{"url":"http://insightdatascience.com/partnerships?utm_source=deep_rl&utm_medium=blog&utm_content=top","alts":[],"httpStatus":200},{"url":"https://en.wikipedia.org/wiki/Q-learning","alts":[],"httpStatus":200},{"url":"https://www.alexirpan.com/2018/02/14/rl-hard.html","alts":[],"httpStatus":200},{"url":"https://en.wikipedia.org/wiki/Softmax_function","alts":[],"httpStatus":200},{"url":"https://twitter.com/EmmanuelAmeisen","alts":[{"type":2,"url":"twitter://user?screen_name=EmmanuelAmeisen"},{"type":3,"url":"twitter://user?screen_name=EmmanuelAmeisen"}],"httpStatus":200},{"url":"https://blog.openai.com/dota-2/","alts":[],"httpStatus":200},{"url":"http://www0.cs.ucl.ac.uk/staff/d.silver/web/Teaching.html","alts":[],"httpStatus":200},{"url":"https://www.linkedin.com/in/zhongyuechen/","alts":[],"httpStatus":999},{"url":"https://deepmind.com/research/alphago/","alts":[{"type":1,"url":"https://cdn.ampproject.org/c/s/deepmind.com/research/alphago/?amp=1"}],"httpStatus":200},{"url":"https://medium.com/emergent-future/simple-reinforcement-learning-with-tensorflow-part-0-q-learning-with-tables-and-neural-networks-d195264329d0","alts":[{"type":2,"url":"medium://p/d195264329d0"},{"type":3,"url":"medium://p/d195264329d0"}],"httpStatus":200},{"url":"http://insightdata.ai?utm_source=deep_rl&utm_medium=blog&utm_content=top","alts":[],"httpStatus":200},{"url":"https://en.wikipedia.org/wiki/Multi-armed_bandit#Semi-uniform_strategies","alts":[],"httpStatus":200},{"url":"https://en.wikipedia.org/wiki/Backpropagation","alts":[],"httpStatus":200},{"url":"https://blog.insightdatascience.com/how-to-solve-90-of-nlp-problems-a-step-by-step-guide-fda605278e4e","alts":[{"type":2,"url":"medium://p/fda605278e4e"},{"type":3,"url":"medium://p/fda605278e4e"}],"httpStatus":200}],"version":"0.3","generatedAt":1528395856537},"isLockedPreviewOnly":false,"takeoverId":"","metaDescription":"","totalClapCount":2559,"sectionCount":3,"readingList":0,"topics":[{"topicId":"1af65db9c2f8","slug":"artificial-intelligence","createdAt":1487916832419,"deletedAt":0,"image":{"id":"1*A28aHchbaA8zNVXraBq0Ug@2x.jpeg","originalWidth":4866,"originalHeight":3244},"name":"Artificial intelligence","description":"Born to be bot.","briefCatalogId":"e811a1868896","relatedTopics":[],"visibility":1,"relatedTags":[],"type":"Topic"}]},"coverless":true,"slug":"reinforcement-learning-from-scratch","translationSourcePostId":"","translationSourceCreatorId":"","isApprovedTranslation":false,"inResponseToPostId":"","inResponseToRemovedAt":0,"isTitleSynthesized":true,"allowResponses":true,"importedUrl":"","importedPublishedAt":0,"visibility":0,"uniqueSlug":"reinforcement-learning-from-scratch-819b65f074d8","previewContent":{"bodyModel":{"paragraphs":[{"name":"previewImage","type":4,"text":"","layout":10,"metadata":{"id":"1*sf4ZeTwBq1O61U4W49NBdQ.png","originalWidth":1200,"originalHeight":630,"isFeatured":true}},{"name":"10a5","type":3,"text":"Reinforcement Learning from scratch","markups":[],"alignment":1},{"name":"aafa","type":13,"text":"Inspired by a great tutorial at O’Reilly AI","markups":[],"alignment":1}],"sections":[{"startIndex":0}]},"isFullContent":false},"license":0,"inResponseToMediaResourceId":"","canonicalUrl":"https://blog.insightdatascience.com/reinforcement-learning-from-scratch-819b65f074d8","approvedHomeCollectionId":"d02e65779d7b","approvedHomeCollection":{"id":"d02e65779d7b","name":"Insight Data","slug":"insight-data","tags":["INSIGHT DATA SCIENCE","INSIGHT DATA ENGINEERING","INSIGHT HEALTH DATA","EDUCATION","INSIGHT AI"],"creatorId":"7b169ef2b4c1","description":"Insight Fellows Program - Your bridge to a career in data","shortDescription":"Insight Fellows Program - Your bridge to a career in data","image":{"imageId":"1*bVN8Kd_RsjRN8JuKIc6U0w.png","filter":"","backgroundSize":"","originalWidth":65,"originalHeight":65,"strategy":"resample","height":0,"width":0},"metadata":{"followerCount":9446,"activeAt":1531953426184},"virtuals":{"permissions":{"canPublish":false,"canPublishAll":false,"canRepublish":false,"canRemove":false,"canManageAll":false,"canSubmit":false,"canEditPosts":false,"canAddWriters":false,"canViewStats":false,"canSendNewsletter":false,"canViewLockedPosts":false,"canViewCloaked":false,"canEditOwnPosts":false,"canBeAssignedAuthor":false,"canEnrollInHightower":false,"canLockPostsForMediumMembers":false,"canLockOwnPostsForMediumMembers":false},"isSubscribed":false,"isNewsletterSubscribed":false,"memberOfMembershipPlanId":"","isEnrolledInHightower":false,"isEligibleForHightower":false},"logo":{"imageId":"1*QBd0FwuD-7reNUpsp4YFjg.png","filter":"","backgroundSize":"","originalWidth":1830,"originalHeight":720,"strategy":"resample","height":0,"width":0},"twitterUsername":"InsightDataSci","facebookPageName":"InsightDataScience","publicEmail":"info@insightdatascience.com","collectionMastheadId":"d30edced0fdd","domain":"blog.insightdatascience.com","sections":[{"type":2,"collectionHeaderMetadata":{"title":"INSIGHT","description":"Your bridge to careers in data","backgroundImage":{"id":"1*TfKznWfrEX5jqKlgf6eivw.jpeg","originalWidth":2118,"originalHeight":541},"logoImage":{"id":"1*QuEQPja8VMt33UcBCupujg@2x.png","originalWidth":1036,"originalHeight":1047,"alt":"Insight Data"},"alignment":2,"layout":5}},{"type":1,"postListMetadata":{"source":1,"layout":5,"number":25,"postIds":[]}}],"tintColor":"#FF577ADA","lightText":true,"favicon":{"imageId":"1*LH1Ab6OAbS03JhOUvBlg9A.png","filter":"","backgroundSize":"","originalWidth":1036,"originalHeight":1047,"strategy":"resample","height":0,"width":0},"colorPalette":{"defaultBackgroundSpectrum":{"colorPoints":[{"color":"#FF5F83E3","point":0},{"color":"#FF5A7AD0","point":0.1},{"color":"#FF5471BD","point":0.2},{"color":"#FF4E68AA","point":0.3},{"color":"#FF485E97","point":0.4},{"color":"#FF415485","point":0.5},{"color":"#FF3A4A72","point":0.6},{"color":"#FF323F60","point":0.7},{"color":"#FF29334D","point":0.8},{"color":"#FF20273B","point":0.9},{"color":"#FF151A28","point":1}],"backgroundColor":"#FFFFFFFF"},"tintBackgroundSpectrum":{"colorPoints":[{"color":"#FF577ADA","point":0},{"color":"#FF698AE0","point":0.1},{"color":"#FF7A98E7","point":0.2},{"color":"#FF8BA6ED","point":0.3},{"color":"#FF9CB4F3","point":0.4},{"color":"#FFACC1F8","point":0.5},{"color":"#FFBCCEFE","point":0.6},{"color":"#FFCBDBFF","point":0.7},{"color":"#FFDBE7FF","point":0.8},{"color":"#FFEAF3FF","point":0.9},{"color":"#FFF9FFFF","point":1}],"backgroundColor":"#FF577ADA"},"highlightSpectrum":{"colorPoints":[{"color":"#FFEBF3FF","point":0},{"color":"#FFE7F1FF","point":0.1},{"color":"#FFE3EFFF","point":0.2},{"color":"#FFDFEEFF","point":0.3},{"color":"#FFDBECFF","point":0.4},{"color":"#FFD7EAFF","point":0.5},{"color":"#FFD3E8FF","point":0.6},{"color":"#FFCFE6FF","point":0.7},{"color":"#FFCBE4FF","point":0.8},{"color":"#FFC7E2FF","point":0.9},{"color":"#FFC2E0FF","point":1}],"backgroundColor":"#FFFFFFFF"}},"navItems":[{"type":1,"title":"About Insight","tagSlug":"about-insight","url":"https://blog.insightdatascience.com/tagged/about-insight","source":"tagSlug"},{"type":1,"title":"Data Science","tagSlug":"insight-data-science","url":"https://blog.insightdatascience.com/tagged/insight-data-science","source":"tagSlug"},{"type":1,"title":"Data Engineering","tagSlug":"insight-data-engineering","url":"https://blog.insightdatascience.com/tagged/insight-data-engineering","source":"tagSlug"},{"type":1,"title":"Health Data","tagSlug":"insight-health-data","url":"https://blog.insightdatascience.com/tagged/insight-health-data","source":"tagSlug"},{"type":1,"title":"AI","tagSlug":"insight-ai","url":"https://blog.insightdatascience.com/tagged/insight-ai","source":"tagSlug"},{"type":1,"title":"Data PM","tagSlug":"insight-data-pm","url":"https://blog.insightdatascience.com/tagged/insight-data-pm","source":"tagSlug"},{"type":1,"title":"DevOps","tagSlug":"insight-devops","url":"https://blog.insightdatascience.com/tagged/insight-devops","source":"tagSlug"}],"colorBehavior":2,"instantArticlesState":0,"acceleratedMobilePagesState":0,"googleAnalyticsId":"UA-29720873-1","ampLogo":{"imageId":"","filter":"","backgroundSize":"","originalWidth":0,"originalHeight":0,"strategy":"resample","height":0,"width":0},"header":{"title":"INSIGHT","description":"Your bridge to careers in data","backgroundImage":{"id":"1*TfKznWfrEX5jqKlgf6eivw.jpeg","originalWidth":2118,"originalHeight":541},"logoImage":{"id":"1*QuEQPja8VMt33UcBCupujg@2x.png","originalWidth":1036,"originalHeight":1047,"alt":"Insight Data"},"alignment":2,"layout":5},"type":"Collection"},"newsletterId":"","webCanonicalUrl":"https://blog.insightdatascience.com/reinforcement-learning-from-scratch-819b65f074d8","mediumUrl":"https://blog.insightdatascience.com/reinforcement-learning-from-scratch-819b65f074d8","migrationId":"","notifyFollowers":true,"notifyTwitter":false,"isSponsored":false,"isRequestToPubDisabled":false,"notifyFacebook":false,"responseHiddenOnParentPostAt":0,"isSeries":false,"isSubscriptionLocked":false,"seriesLastAppendedAt":0,"audioVersionDurationSec":0,"sequenceId":"","isNsfw":false,"isEligibleForRevenue":false,"isBlockedFromHightower":false,"deletedAt":0,"lockedPostSource":0,"hightowerMinimumGuaranteeStartsAt":0,"hightowerMinimumGuaranteeEndsAt":0,"featureLockRequestAcceptedAt":0,"featureLockRequestMinimumGuaranteeAmount":0,"isElevate":false,"mongerRequestType":1,"layerCake":3,"type":"Post"},"mentionedUsers":[{"userId":"18dfe63fa7f0","name":"Arthur Juliani","username":"awjuliani","createdAt":1442794917372,"lastPostCreatedAt":1531731900622,"imageId":"1*kLlWemBAJPjdMTEh5hDtUg.jpeg","backgroundImageId":"","bio":"Deep Learning @Unity3D","twitterScreenName":"awjuliani","facebookAccountId":"","allowNotes":1,"mediumMemberAt":0,"isPartnerProgramEnrolled":true,"type":"User"}],"collaborators":[{"user":{"userId":"180b8130f02d","name":"Geneviève Smith","username":"genevieve_56490","createdAt":1475694834063,"lastPostCreatedAt":1524673882072,"imageId":"1*Idk-aW3w-UrhIxmChc6OWA.jpeg","backgroundImageId":"","bio":"","twitterScreenName":"","facebookAccountId":"","allowNotes":1,"mediumMemberAt":0,"isPartnerProgramEnrolled":false,"type":"User"},"state":"visible"},{"user":{"userId":"53978067b293","name":"Ben Regner","username":"ben_71772","createdAt":1475022210427,"lastPostCreatedAt":1475022386319,"imageId":"0*jr3WfcybGB3KKjdg.","backgroundImageId":"","bio":"","twitterScreenName":"","facebookAccountId":"","allowNotes":1,"mediumMemberAt":0,"isPartnerProgramEnrolled":false,"type":"User"},"state":"visible"},{"user":{"userId":"da71795f0a67","name":"Andy Mullenix","username":"nerdoid","createdAt":1390939141327,"lastPostCreatedAt":0,"imageId":"0*kFD9EzS8XhVCoZMN.jpg","backgroundImageId":"","bio":"","twitterScreenName":"nerdoid","facebookAccountId":"","allowNotes":1,"mediumMemberAt":0,"isPartnerProgramEnrolled":false,"type":"User"},"state":"visible"},{"user":{"userId":"ab3a129da53d","name":"Mari Kong","username":"mkong","createdAt":1516334323613,"lastPostCreatedAt":1527488823396,"imageId":"0*WQsyhNJQuNTZxEOM.","backgroundImageId":"","bio":"","twitterScreenName":"","facebookAccountId":"","allowNotes":1,"mediumMemberAt":0,"isPartnerProgramEnrolled":false,"type":"User"},"state":"visible"}],"collectionUserRelations":[],"mode":null,"references":{"User":{"45cca2d4999f":{"userId":"45cca2d4999f","name":"Emmanuel Ameisen","username":"emmanuelameisen","createdAt":1404198608737,"lastPostCreatedAt":1531602421598,"imageId":"1*u2FiBL9mzFPx7pj87aWxgw.jpeg","backgroundImageId":"","bio":"AI Lead at Insight AI @EmmanuelAmeisen","twitterScreenName":"EmmanuelAmeisen","socialStats":{"userId":"45cca2d4999f","usersFollowedCount":8,"usersFollowedByCount":2324,"type":"SocialStats"},"social":{"userId":"lo_6eca48311aab","targetUserId":"45cca2d4999f","type":"Social"},"facebookAccountId":"10203282016947013","allowNotes":1,"isNsfw":false,"isWriterProgramInvited":false,"isPartnerProgramEnrolled":false,"isWriterProgramEnrolled":false,"type":"User"}},"Collection":{"d02e65779d7b":{"id":"d02e65779d7b","name":"Insight Data","slug":"insight-data","tags":["INSIGHT DATA SCIENCE","INSIGHT DATA ENGINEERING","INSIGHT HEALTH DATA","EDUCATION","INSIGHT AI"],"creatorId":"7b169ef2b4c1","description":"Insight Fellows Program - Your bridge to a career in data","shortDescription":"Insight Fellows Program - Your bridge to a career in data","image":{"imageId":"1*bVN8Kd_RsjRN8JuKIc6U0w.png","filter":"","backgroundSize":"","originalWidth":65,"originalHeight":65,"strategy":"resample","height":0,"width":0},"metadata":{"followerCount":9446,"activeAt":1531953426184},"virtuals":{"permissions":{"canPublish":false,"canPublishAll":false,"canRepublish":false,"canRemove":false,"canManageAll":false,"canSubmit":false,"canEditPosts":false,"canAddWriters":false,"canViewStats":false,"canSendNewsletter":false,"canViewLockedPosts":false,"canViewCloaked":false,"canEditOwnPosts":false,"canBeAssignedAuthor":false,"canEnrollInHightower":false,"canLockPostsForMediumMembers":false,"canLockOwnPostsForMediumMembers":false},"isSubscribed":false,"isNewsletterSubscribed":false,"memberOfMembershipPlanId":"","isEnrolledInHightower":false,"isEligibleForHightower":false},"logo":{"imageId":"1*QBd0FwuD-7reNUpsp4YFjg.png","filter":"","backgroundSize":"","originalWidth":1830,"originalHeight":720,"strategy":"resample","height":0,"width":0},"twitterUsername":"InsightDataSci","facebookPageName":"InsightDataScience","publicEmail":"info@insightdatascience.com","collectionMastheadId":"d30edced0fdd","domain":"blog.insightdatascience.com","sections":[{"type":2,"collectionHeaderMetadata":{"title":"INSIGHT","description":"Your bridge to careers in data","backgroundImage":{"id":"1*TfKznWfrEX5jqKlgf6eivw.jpeg","originalWidth":2118,"originalHeight":541},"logoImage":{"id":"1*QuEQPja8VMt33UcBCupujg@2x.png","originalWidth":1036,"originalHeight":1047,"alt":"Insight Data"},"alignment":2,"layout":5}},{"type":1,"postListMetadata":{"source":1,"layout":5,"number":25,"postIds":[]}}],"tintColor":"#FF577ADA","lightText":true,"favicon":{"imageId":"1*LH1Ab6OAbS03JhOUvBlg9A.png","filter":"","backgroundSize":"","originalWidth":1036,"originalHeight":1047,"strategy":"resample","height":0,"width":0},"colorPalette":{"defaultBackgroundSpectrum":{"colorPoints":[{"color":"#FF5F83E3","point":0},{"color":"#FF5A7AD0","point":0.1},{"color":"#FF5471BD","point":0.2},{"color":"#FF4E68AA","point":0.3},{"color":"#FF485E97","point":0.4},{"color":"#FF415485","point":0.5},{"color":"#FF3A4A72","point":0.6},{"color":"#FF323F60","point":0.7},{"color":"#FF29334D","point":0.8},{"color":"#FF20273B","point":0.9},{"color":"#FF151A28","point":1}],"backgroundColor":"#FFFFFFFF"},"tintBackgroundSpectrum":{"colorPoints":[{"color":"#FF577ADA","point":0},{"color":"#FF698AE0","point":0.1},{"color":"#FF7A98E7","point":0.2},{"color":"#FF8BA6ED","point":0.3},{"color":"#FF9CB4F3","point":0.4},{"color":"#FFACC1F8","point":0.5},{"color":"#FFBCCEFE","point":0.6},{"color":"#FFCBDBFF","point":0.7},{"color":"#FFDBE7FF","point":0.8},{"color":"#FFEAF3FF","point":0.9},{"color":"#FFF9FFFF","point":1}],"backgroundColor":"#FF577ADA"},"highlightSpectrum":{"colorPoints":[{"color":"#FFEBF3FF","point":0},{"color":"#FFE7F1FF","point":0.1},{"color":"#FFE3EFFF","point":0.2},{"color":"#FFDFEEFF","point":0.3},{"color":"#FFDBECFF","point":0.4},{"color":"#FFD7EAFF","point":0.5},{"color":"#FFD3E8FF","point":0.6},{"color":"#FFCFE6FF","point":0.7},{"color":"#FFCBE4FF","point":0.8},{"color":"#FFC7E2FF","point":0.9},{"color":"#FFC2E0FF","point":1}],"backgroundColor":"#FFFFFFFF"}},"navItems":[{"type":1,"title":"About Insight","tagSlug":"about-insight","url":"https://blog.insightdatascience.com/tagged/about-insight","source":"tagSlug"},{"type":1,"title":"Data Science","tagSlug":"insight-data-science","url":"https://blog.insightdatascience.com/tagged/insight-data-science","source":"tagSlug"},{"type":1,"title":"Data Engineering","tagSlug":"insight-data-engineering","url":"https://blog.insightdatascience.com/tagged/insight-data-engineering","source":"tagSlug"},{"type":1,"title":"Health Data","tagSlug":"insight-health-data","url":"https://blog.insightdatascience.com/tagged/insight-health-data","source":"tagSlug"},{"type":1,"title":"AI","tagSlug":"insight-ai","url":"https://blog.insightdatascience.com/tagged/insight-ai","source":"tagSlug"},{"type":1,"title":"Data PM","tagSlug":"insight-data-pm","url":"https://blog.insightdatascience.com/tagged/insight-data-pm","source":"tagSlug"},{"type":1,"title":"DevOps","tagSlug":"insight-devops","url":"https://blog.insightdatascience.com/tagged/insight-devops","source":"tagSlug"}],"colorBehavior":2,"instantArticlesState":0,"acceleratedMobilePagesState":0,"googleAnalyticsId":"UA-29720873-1","ampLogo":{"imageId":"","filter":"","backgroundSize":"","originalWidth":0,"originalHeight":0,"strategy":"resample","height":0,"width":0},"header":{"title":"INSIGHT","description":"Your bridge to careers in data","backgroundImage":{"id":"1*TfKznWfrEX5jqKlgf6eivw.jpeg","originalWidth":2118,"originalHeight":541},"logoImage":{"id":"1*QuEQPja8VMt33UcBCupujg@2x.png","originalWidth":1036,"originalHeight":1047,"alt":"Insight Data"},"alignment":2,"layout":5},"type":"Collection"}},"Social":{"45cca2d4999f":{"userId":"lo_6eca48311aab","targetUserId":"45cca2d4999f","type":"Social"}},"SocialStats":{"45cca2d4999f":{"userId":"45cca2d4999f","usersFollowedCount":8,"usersFollowedByCount":2324,"type":"SocialStats"}}}})
// ]]></script><!-- START Parse.ly Include: Standard --><div id="parsely-root" style="display: none"><span id="parsely-cfg" data-parsely-site="medium.com"></span><script id="parsely-script" async="" src="./Reinforcement Learning from scratch – Insight Data_files/p.js"></script></div><script>(function(s, p, d) {var h = d.location.protocol, i = p + "-" + s, e = d.getElementById(i), r = d.getElementById(p + "-root"), u = h === "https:" ? "d1z2jf7jlzjs58.cloudfront.net" : "static." + p + ".com"; if (e) return; e = d.createElement(s); e.id = i; e.async = true; e.src = h + "//" + u + "/p.js"; r.appendChild(e);})("script", "parsely", document);</script><!-- END Parse.ly Include: Standard --><div class="surface-scrollOverlay"></div><script charset="UTF-8" src="./Reinforcement Learning from scratch – Insight Data_files/main-common-async.bundle.WKmfPf9Nj8xCneCN6TKlEA.js"></script><script charset="UTF-8" src="./Reinforcement Learning from scratch – Insight Data_files/main-notes.bundle.LUI7G9sM3rPgZyAJHfZQig.js"></script></body></html>